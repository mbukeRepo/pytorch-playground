{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb50a573-e7d2-45b7-9503-0b79c9483cb9",
   "metadata": {},
   "source": [
    "## Computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b43be-371b-48e3-b692-c4aa01add78e",
   "metadata": {},
   "source": [
    "This book will explore computer vision and convolutional neural networks with pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2c1072-7e92-44bc-bd57-4e16086fed0a",
   "metadata": {},
   "source": [
    "### 0. Computer vision libraries for pytorch\n",
    "* `torchvision` - base domain library for pytorch computer vision\n",
    "* `torchvision.datasets` - get datasets and data loading functions for computer vision.\n",
    "* `torchvision.models` - pre-trained models for computer vision\n",
    "* `torchvision.transforms` - functions for manipulating your vision data\n",
    "to be suitable for use with a ML model\n",
    "* `torchvision.utils.data.Dataset` - base dataset class for PyTorch\n",
    "* `torchvision.utils.data.DataLoader` - creates a Python iterable over a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b597be2a-897c-4a64-add4-13c247ba444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "0.15.2+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "# torch vision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36355c9-2bdd-4f20-876f-69a34b5991c2",
   "metadata": {},
   "source": [
    "### 1. Getting data ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c98fe-de3b-4e7e-bba7-83c891212310",
   "metadata": {},
   "source": [
    "The dataset we'll be using is FashionMNIST from torchvision.datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2173085-862e-4ace-a7f5-3eca95cd824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a504df7a-3853-4479-8a15-4cc411d7cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root = \"data\", # where to download to\n",
    "    train = True, \n",
    "    download = True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d32517-ea9f-4ce8-b521-0c7e015ed72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train= False,\n",
    "    download = True,\n",
    "    transform= ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5abb2c-f4e4-47a0-85c6-4f9c5298abf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data, train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e6102bf-b662-4ea4-b0f5-8e56d15c2958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0118, 0.0039, 0.0000, 0.0000, 0.0275,\n",
       "           0.0000, 0.1451, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0078, 0.0000,\n",
       "           0.1059, 0.3294, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.4667, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "           0.3451, 0.5608, 0.4314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863,\n",
       "           0.3647, 0.4157, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.2078,\n",
       "           0.5059, 0.4706, 0.5765, 0.6863, 0.6157, 0.6510, 0.5294, 0.6039,\n",
       "           0.6588, 0.5490, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0431, 0.5373,\n",
       "           0.5098, 0.5020, 0.6275, 0.6902, 0.6235, 0.6549, 0.6980, 0.5843,\n",
       "           0.5922, 0.5647, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "           0.0078, 0.0039, 0.0000, 0.0118, 0.0000, 0.0000, 0.4510, 0.4471,\n",
       "           0.4157, 0.5373, 0.6588, 0.6000, 0.6118, 0.6471, 0.6549, 0.5608,\n",
       "           0.6157, 0.6196, 0.0431, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0118, 0.0000, 0.0000, 0.3490, 0.5451, 0.3529,\n",
       "           0.3686, 0.6000, 0.5843, 0.5137, 0.5922, 0.6627, 0.6745, 0.5608,\n",
       "           0.6235, 0.6627, 0.1882, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0157,\n",
       "           0.0039, 0.0000, 0.0000, 0.0000, 0.3843, 0.5333, 0.4314, 0.4275,\n",
       "           0.4314, 0.6353, 0.5294, 0.5647, 0.5843, 0.6235, 0.6549, 0.5647,\n",
       "           0.6196, 0.6627, 0.4667, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0078, 0.0078, 0.0039, 0.0078, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.1020, 0.4235, 0.4588, 0.3882, 0.4353, 0.4588,\n",
       "           0.5333, 0.6118, 0.5255, 0.6039, 0.6039, 0.6118, 0.6275, 0.5529,\n",
       "           0.5765, 0.6118, 0.6980, 0.0000],\n",
       "          [0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824,\n",
       "           0.2078, 0.3608, 0.4588, 0.4353, 0.4039, 0.4510, 0.5059, 0.5255,\n",
       "           0.5608, 0.6039, 0.6471, 0.6667, 0.6039, 0.5922, 0.6039, 0.5608,\n",
       "           0.5412, 0.5882, 0.6471, 0.1686],\n",
       "          [0.0000, 0.0000, 0.0902, 0.2118, 0.2549, 0.2980, 0.3333, 0.4627,\n",
       "           0.5020, 0.4824, 0.4353, 0.4431, 0.4627, 0.4980, 0.4902, 0.5451,\n",
       "           0.5216, 0.5333, 0.6275, 0.5490, 0.6078, 0.6314, 0.5647, 0.6078,\n",
       "           0.6745, 0.6314, 0.7412, 0.2431],\n",
       "          [0.0000, 0.2667, 0.3686, 0.3529, 0.4353, 0.4471, 0.4353, 0.4471,\n",
       "           0.4510, 0.4980, 0.5294, 0.5333, 0.5608, 0.4941, 0.4980, 0.5922,\n",
       "           0.6039, 0.5608, 0.5804, 0.4902, 0.6353, 0.6353, 0.5647, 0.5412,\n",
       "           0.6000, 0.6353, 0.7686, 0.2275],\n",
       "          [0.2745, 0.6627, 0.5059, 0.4078, 0.3843, 0.3922, 0.3686, 0.3804,\n",
       "           0.3843, 0.4000, 0.4235, 0.4157, 0.4667, 0.4706, 0.5059, 0.5843,\n",
       "           0.6118, 0.6549, 0.7451, 0.7451, 0.7686, 0.7765, 0.7765, 0.7333,\n",
       "           0.7725, 0.7412, 0.7216, 0.1412],\n",
       "          [0.0627, 0.4941, 0.6706, 0.7373, 0.7373, 0.7216, 0.6706, 0.6000,\n",
       "           0.5294, 0.4706, 0.4941, 0.4980, 0.5725, 0.7255, 0.7647, 0.8196,\n",
       "           0.8157, 1.0000, 0.8196, 0.6941, 0.9608, 0.9882, 0.9843, 0.9843,\n",
       "           0.9686, 0.8627, 0.8078, 0.1922],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0471, 0.2627, 0.4157, 0.6431, 0.7255,\n",
       "           0.7804, 0.8235, 0.8275, 0.8235, 0.8157, 0.7451, 0.5882, 0.3216,\n",
       "           0.0314, 0.0000, 0.0000, 0.0000, 0.6980, 0.8157, 0.7373, 0.6863,\n",
       "           0.6353, 0.6196, 0.5922, 0.0431],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first training example\n",
    "image, label = test_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13510e18-5987-4457-bb61-e29fe1f344c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classnames = train_data.classes\n",
    "classnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98aa8073-dcb6-4bf9-8449-d697655df5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classname_to_idx = train_data.class_to_idx\n",
    "classname_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc7db5e-dcc7-403b-988f-60f30aaecc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ed21fb-438b-49a1-ab5b-6d314026b000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classnames[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7f79fc8-6233-4acf-971f-dcfb4441f8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0118, 0.0039, 0.0000, 0.0000, 0.0275,\n",
       "          0.0000, 0.1451, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0078, 0.0000,\n",
       "          0.1059, 0.3294, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.4667, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "          0.3451, 0.5608, 0.4314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0863,\n",
       "          0.3647, 0.4157, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0000, 0.2078,\n",
       "          0.5059, 0.4706, 0.5765, 0.6863, 0.6157, 0.6510, 0.5294, 0.6039,\n",
       "          0.6588, 0.5490, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0431, 0.5373,\n",
       "          0.5098, 0.5020, 0.6275, 0.6902, 0.6235, 0.6549, 0.6980, 0.5843,\n",
       "          0.5922, 0.5647, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "          0.0078, 0.0039, 0.0000, 0.0118, 0.0000, 0.0000, 0.4510, 0.4471,\n",
       "          0.4157, 0.5373, 0.6588, 0.6000, 0.6118, 0.6471, 0.6549, 0.5608,\n",
       "          0.6157, 0.6196, 0.0431, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0118, 0.0000, 0.0000, 0.3490, 0.5451, 0.3529,\n",
       "          0.3686, 0.6000, 0.5843, 0.5137, 0.5922, 0.6627, 0.6745, 0.5608,\n",
       "          0.6235, 0.6627, 0.1882, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0157,\n",
       "          0.0039, 0.0000, 0.0000, 0.0000, 0.3843, 0.5333, 0.4314, 0.4275,\n",
       "          0.4314, 0.6353, 0.5294, 0.5647, 0.5843, 0.6235, 0.6549, 0.5647,\n",
       "          0.6196, 0.6627, 0.4667, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0078, 0.0078, 0.0039, 0.0078, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.1020, 0.4235, 0.4588, 0.3882, 0.4353, 0.4588,\n",
       "          0.5333, 0.6118, 0.5255, 0.6039, 0.6039, 0.6118, 0.6275, 0.5529,\n",
       "          0.5765, 0.6118, 0.6980, 0.0000],\n",
       "         [0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0824,\n",
       "          0.2078, 0.3608, 0.4588, 0.4353, 0.4039, 0.4510, 0.5059, 0.5255,\n",
       "          0.5608, 0.6039, 0.6471, 0.6667, 0.6039, 0.5922, 0.6039, 0.5608,\n",
       "          0.5412, 0.5882, 0.6471, 0.1686],\n",
       "         [0.0000, 0.0000, 0.0902, 0.2118, 0.2549, 0.2980, 0.3333, 0.4627,\n",
       "          0.5020, 0.4824, 0.4353, 0.4431, 0.4627, 0.4980, 0.4902, 0.5451,\n",
       "          0.5216, 0.5333, 0.6275, 0.5490, 0.6078, 0.6314, 0.5647, 0.6078,\n",
       "          0.6745, 0.6314, 0.7412, 0.2431],\n",
       "         [0.0000, 0.2667, 0.3686, 0.3529, 0.4353, 0.4471, 0.4353, 0.4471,\n",
       "          0.4510, 0.4980, 0.5294, 0.5333, 0.5608, 0.4941, 0.4980, 0.5922,\n",
       "          0.6039, 0.5608, 0.5804, 0.4902, 0.6353, 0.6353, 0.5647, 0.5412,\n",
       "          0.6000, 0.6353, 0.7686, 0.2275],\n",
       "         [0.2745, 0.6627, 0.5059, 0.4078, 0.3843, 0.3922, 0.3686, 0.3804,\n",
       "          0.3843, 0.4000, 0.4235, 0.4157, 0.4667, 0.4706, 0.5059, 0.5843,\n",
       "          0.6118, 0.6549, 0.7451, 0.7451, 0.7686, 0.7765, 0.7765, 0.7333,\n",
       "          0.7725, 0.7412, 0.7216, 0.1412],\n",
       "         [0.0627, 0.4941, 0.6706, 0.7373, 0.7373, 0.7216, 0.6706, 0.6000,\n",
       "          0.5294, 0.4706, 0.4941, 0.4980, 0.5725, 0.7255, 0.7647, 0.8196,\n",
       "          0.8157, 1.0000, 0.8196, 0.6941, 0.9608, 0.9882, 0.9843, 0.9843,\n",
       "          0.9686, 0.8627, 0.8078, 0.1922],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0471, 0.2627, 0.4157, 0.6431, 0.7255,\n",
       "          0.7804, 0.8235, 0.8275, 0.8235, 0.8157, 0.7451, 0.5882, 0.3216,\n",
       "          0.0314, 0.0000, 0.0000, 0.0000, 0.6980, 0.8157, 0.7373, 0.6863,\n",
       "          0.6353, 0.6196, 0.5922, 0.0431],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8686cb7-d9f5-43f8-aa6f-f531edcb23e6",
   "metadata": {},
   "source": [
    "**1.2 visualizing our data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12cff0dd-3d8a-4feb-b2dc-e1106c2535de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f99f6441-458d-412c-884e-ea67a1680294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "image, label = train_data[1]\n",
    "print(f\"Image shape: {image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2380ef24-7632-4e23-8e9a-e3412d288319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'T-shirt/top')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAm6UlEQVR4nO3de3SUdX7H8c/kNiSQCyGQCwY2oIKIxLMRIkdAWHIC2a4VYbt4aRfcXVE28VSp1U2PCrS7Tct6rMct4m4voC146xE4WotF3IS1EhWEQ3FrhGxYQkMCUnIFkpB5+gfr7M4mXH4/J/ObhPfrnOcc5pnnO883T57wyTMz+Y7P8zxPAABEWIzrBgAAVyYCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCDBw+PBh+Xw+PfXUU5fcdtWqVfL5fBHoChiYCCAMKj6f77KWyspK162GOH36tFatWnXRvk6dOqW4uDi9+uqrkqS//uu/1pYtWyLTINAP4lw3AITTv/zLv4TcfvHFF7V9+/Ze66+77rp+7+Xxxx/XD37wg8va9vTp01q9erUkafbs2X1u8/bbb8vn86m4uFjS+QD65je/qQULFoSjXSDiCCAMKn/8x38ccru6ulrbt2/vtT4S4uLiFBd38R+xQCCgrq6uy3q8t956S7fccovS0tLC0B3gHk/BAb9j9+7dmjdvnjIyMpSYmKi8vDx95zvf6XPbn/3sZxo/frz8fr+mTp2qjz76KOT+vl4D8vl8Kisr08aNG3X99dfL7/fr+eef18iRIyVJq1evDj5NuGrVqmBdIBDQtm3b9Ad/8AfBx+no6NALL7wQ3H7p0qXB7ffu3auSkhKlpKRo2LBhmjt3rqqrq0N62bBhg3w+n3bu3Kn7779fI0aMUEpKir797W/r1KlTtocQuGxcAQG/cfz4cRUXF2vkyJH6wQ9+oLS0NB0+fFivv/56r203bdqktrY23X///fL5fFqzZo0WLlyoX/3qV4qPj7/oft599129+uqrKisrU0ZGhvLz87Vu3TotX75cd9xxhxYuXChJmjJlSrDmo48+0okTJ/T1r39d0vmnGr/3ve9p2rRpWrZsmSRp/PjxkqRPPvlEM2fOVEpKih599FHFx8frpz/9qWbPnq2qqioVFhaG9FNWVqa0tDStWrVKNTU1WrdunX7961+rsrKSN1Ggf3nAIFZaWupd7mm+efNmT5L30UcfXXCburo6T5I3YsQI7//+7/+C67du3epJ8t54443gupUrV/batyQvJibG++STT0LWnzhxwpPkrVy5ss/9PvHEE97YsWND1g0dOtRbsmRJr20XLFjgJSQkeLW1tcF1DQ0NXnJysjdr1qzguvXr13uSvIKCAq+rqyu4fs2aNZ4kb+vWrRc8DkA48BQc8BtfvLby5ptvqru7+6LbLl68WMOHDw/enjlzpiTpV7/61SX3c+utt2rSpElGvb311lvBp98upqenR//5n/+pBQsWaNy4ccH12dnZuvvuu/Xee++ptbU1pGbZsmUhV23Lly9XXFyc3nrrLaMeAVMEEK447e3tamxsDC4nTpyQdD4YFi1apNWrVysjI0O333671q9fr87Ozl6PMWbMmJDbX4TR5bx2kpeXZ9RvY2OjPv7448sKoBMnTuj06dOaMGFCr/uuu+46BQIB1dfXh6y/5pprQm4PGzZM2dnZOnz4sFGfgCkCCFecp556StnZ2cFl6tSpks6/sP9v//Zv2rVrl8rKyvS///u/+s53vqOCggK1t7eHPEZsbGyfj+1dxifcJyYmGvX7H//xHxoyZIjmzJljVAdEOwIIV5xvf/vb2r59e3DZuHFjyP0333yzfvSjH2n37t3auHGjPvnkE7388sv92tPFXuz/93//d82ZM6dXcPVVM3LkSCUlJammpqbXfZ9++qliYmKUm5sbsv7gwYMht9vb23Xs2DF95StfMfgKAHO8Cw5XnHHjxoW8PvKFU6dOKS0tLeQ/9htvvFGS+nwaLpySkpIkSc3NzSHru7u7tX37dlVUVPSqGTp0aK/tY2NjVVxcrK1bt+rw4cPBEGlqatKmTZs0Y8YMpaSkhNT87Gc/07333ht8HWjdunU6d+6cSkpKwvPFARdAAAG/8cILL+i5557THXfcofHjx6utrU3/8A//oJSUlODbn/tLYmKiJk2apFdeeUXXXnut0tPTNXnyZJ04cUKtra19vv5TUFCgd955R08//bRycnKUl5enwsJC/fCHP9T27ds1Y8YMff/731dcXJx++tOfqrOzU2vWrOn1OF1dXZo7d66+9a1vqaamRs8995xmzJihP/zDP+zXrxkggIDfuPXWW/Xhhx/q5ZdfVlNTk1JTUzVt2jRt3LjR+I0DNv7xH/9RDz74oB5++GF1dXVp5cqV6ujo0KRJkzR27Nhe2z/99NNatmyZHn/8cZ05c0ZLlixRYWGhrr/+ev3iF79QeXm5KioqFAgEVFhYqH/913/t9TdAkvT3f//32rhxo5588kl1d3frrrvu0rPPPsvfAKHf+bzLedUUgBOTJk3SN77xjT6vXL6sDRs26N5779VHH32km266KeyPD1wKV0BAlOrq6tLixYv1rW99y3UrQL8ggIAolZCQoJUrV7puA+g3vA0bAOAErwEBAJzgCggA4AQBBABwIurehBAIBNTQ0KDk5GT+DgEABiDP89TW1qacnBzFxFz4OifqAqihoaHXrCoAwMBTX1+vq6666oL3R10AJScnu24BUeb3Py7gcjz11FNW+9qyZYtxzf79+41rurq6jGsu9RlFfTH93KEvfOMb3zCuqaurM6559tlnjWtaWlqMa+DGpf4/77cAWrt2rX784x+rsbFR+fn5+slPfqJp06Zdso6n3X7L5lgMxjc1XuijDy5m6NChVvtKSEgwrrHpz6YmEAgY11zq48Ev5IvhqCaGDBliXMPP++B2qe9vv7wJ4ZVXXtGKFSu0cuVKffzxx8rPz9e8efN0/Pjx/tgdAGAA6pcAevrpp3Xffffp3nvv1aRJk/T8888rKSlJ//zP/9wfuwMADEBhD6Curi7t2bNHRUVFv91JTIyKioq0a9euXtt3dnaqtbU1ZAEADH5hD6DPP/9cPT09yszMDFmfmZmpxsbGXttXVFQoNTU1uPAOOAC4Mjj/Q9Ty8nK1tLQEl/r6etctAQAiIOzvgsvIyFBsbKyamppC1jc1NSkrK6vX9n6/X36/P9xtAACiXNivgBISElRQUKAdO3YE1wUCAe3YsUPTp08P9+4AAANUv/wd0IoVK7RkyRLddNNNmjZtmp555hl1dHTo3nvv7Y/dAQAGoH4JoMWLF+vEiRN68skn1djYqBtvvFHbtm3r9cYEAMCVK+o+D6i1tVWpqamu27iowTah4MYbb7Squ/POO41rFi1aZFzT09NjXGM7CSExMdG4ZsSIEVb7imafffaZcY3NpIYJEyYY1/z+68uX4+233zaukexGOh04cMBqX4NRS0uLUlJSLni/83fBAQCuTAQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwgmGkUexiQ/wu5MUXXzSumTJlinGNJMXEmP/+0tbWZlxz9uxZ45ru7m7jGslu8Gl8fLxxjc053tHRYVxjMyBUiu7huUOGDDGusRkyK53/fDNTv/jFL4xr/uRP/sS4ZiBgGCkAICoRQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgRJzrBnBhr7/+unHN2LFjjWuOHz9uXCPZTVqOizM/5c6dO2dc4/P5jGsku/5s9vX5558b18TGxhrX2LKZdB4pZ86cMa6xmagu2U0FnzVrlnHNxIkTjWs+/fRT45poE71nGQBgUCOAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwwjjZCCggLjGpvBojZDLm0GcEp2wzGHDBliXDN69GjjmqSkJOMayW4IZ3d3t3GNzTHv6ekxrrEdyhofH29cYzM0tq2tzbjm6NGjxjU2vdmy+T5973vfM6555JFHjGuiDVdAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEw0gjZM6cOcY1fr8/IjWBQMC4RrIbRtrZ2Wlc89hjjxnXNDQ0GNdIdoMuc3JyjGuOHTtmXGMzKLWrq8u4RrI7j4YNG2Zc89WvftW45sEHHzSusRnSK9kNjbX5efrmN79pXMMwUgAALBFAAAAnwh5Aq1atks/nC1kmTpwY7t0AAAa4fnkN6Prrr9c777zz251YfuAZAGDw6pdkiIuLU1ZWVn88NABgkOiX14AOHjyonJwcjRs3Tvfcc4+OHDlywW07OzvV2toasgAABr+wB1BhYaE2bNigbdu2ad26daqrq9PMmTMv+NnvFRUVSk1NDS65ubnhbgkAEIXCHkAlJSX6oz/6I02ZMkXz5s3TW2+9pebmZr366qt9bl9eXq6WlpbgUl9fH+6WAABRqN/fHZCWlqZrr71Whw4d6vN+v99v9UdvAICBrd//Dqi9vV21tbXKzs7u710BAAaQsAfQI488oqqqKh0+fFjvv/++7rjjDsXGxuquu+4K964AAANY2J+CO3r0qO666y6dPHlSI0eO1IwZM1RdXa2RI0eGe1cAgAHM53me57qJ39Xa2qrU1FTXbYRddXW1cc2oUaOMay70bsOLsR1YaTN8sqWlxbjm5ptvNq4pLi42rpGk0aNHG9esX7/euOb+++83rjlw4IBxTWJionGNZDdotqmpybhm3759xjUHDx40rrH5uZCkIUOGGNecO3fOuMZmWszkyZONayTps88+s6qz0dLSopSUlAvezyw4AIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCi3z+QDufl5+cb19h8OmxMjPnvFJH8QMCLDSYMp23btlnVdXR0GNdMmjTJuOaRRx4xrtm8ebNxzW233WZcI0lxceb/NXz88cfGNQUFBcY1NsM+hw4dalwjST09PcY1gUDAuObIkSPGNdOnTzeukSI7jPRSuAICADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAE0zDtjB58mTjmhMnThjX2Ez9jY2NNa7x+XzGNZKUmJhoXHPy5EmrfZmy+R5JUmdnp3FNdna2cc2PfvQj4xqb71N3d7dxje2+bKczm2poaDCuGT16tNW+IjUN+8yZM8Y1M2fONK6RpBdeeMGqrj9wBQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAATjCM1MJjjz1mXGMzuLO9vd24xmZ4ok1vknT27FnjGpsBqzfddJNxzYgRI4xrJCk9Pd24Jj4+3rgmMzPTuMZmsKjN90iSEhISjGvS0tKMaxYvXmxcM3z4cOMam2GfkpSamhqRfdkcb5ufi2jDFRAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOMEwUgvvv/++cU1WVpZxzdVXX21ck5KSYlwzdOhQ4xpJOnjwoHGNzbDU6upq45pAIGBcY1tn8zXFxsYa18TFmf+4+nw+4xrJ7muKiTH/fbatrc245rPPPjOuSUpKMq6R7L5PNsehoaHBuGbLli3GNdGGKyAAgBMEEADACeMA2rlzp2677Tbl5OTI5/P1ugz0PE9PPvmksrOzlZiYqKKiIqunagAAg5txAHV0dCg/P19r167t8/41a9bo2Wef1fPPP68PPvhAQ4cO1bx586w/GAsAMDgZv6pZUlKikpKSPu/zPE/PPPOMHn/8cd1+++2SpBdffFGZmZnasmWL7rzzzi/XLQBg0Ajra0B1dXVqbGxUUVFRcF1qaqoKCwu1a9euPms6OzvV2toasgAABr+wBlBjY6Ok3p93n5mZGbzv91VUVCg1NTW45ObmhrMlAECUcv4uuPLycrW0tASX+vp61y0BACIgrAH0xR9bNjU1haxvamq64B9i+v1+paSkhCwAgMEvrAGUl5enrKws7dixI7iutbVVH3zwgaZPnx7OXQEABjjjd8G1t7fr0KFDwdt1dXXat2+f0tPTNWbMGD300EP64Q9/qGuuuUZ5eXl64oknlJOTowULFoSzbwDAAGccQLt379acOXOCt1esWCFJWrJkiTZs2KBHH31UHR0dWrZsmZqbmzVjxgxt27ZNQ4YMCV/XAIABz+d5nue6id/V2tqq1NRU121EheHDhxvXXHPNNcY1y5cvN66RpFtvvdW4xuZNJjbnQ3Nzs3GNJMXHxxvX2AysjHY2Q0xthnDa/IG6zfnw3//938Y1knTPPfdY1eG8lpaWi76u7/xdcACAKxMBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOGH8cAyLn1KlTxjUffvihcU1nZ6dxjSR97WtfM66xGb6ekJBgXDN06FDjGslusnUgELDalymbCdU2NZLd1+T3+41rurq6jGtsPtrl/fffN65B/+MKCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcYBhphNgMhYyPjzeusRnuaDMgVJJaW1uNa2yGffb09BjX2H5NNmy+t5HsL5rZnA82mpubI7IfKXIDbQfDOcQVEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4wTDSCLEZHNjd3d0PnfRWW1trVWczjDQuzvyUsxmwasvm+xTNw0hterNl832yGbhrw+ZctRUTY/57vc3A3cGAKyAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIJhpFEsUkMNz5w5Y1wj2Q2f9Pv9xjXnzp0zrrEZeipFbrCozX5samzOIcnua+rs7DSuSUpKMq6xOQ425xD6H1dAAAAnCCAAgBPGAbRz507ddtttysnJkc/n05YtW0LuX7p0qXw+X8gyf/78cPULABgkjAOoo6ND+fn5Wrt27QW3mT9/vo4dOxZcXnrppS/VJABg8DF+pbakpEQlJSUX3cbv9ysrK8u6KQDA4NcvrwFVVlZq1KhRmjBhgpYvX66TJ09ecNvOzk61traGLACAwS/sATR//ny9+OKL2rFjh/72b/9WVVVVKikpueDbgysqKpSamhpccnNzw90SACAKhf3vgO68887gv2+44QZNmTJF48ePV2VlpebOndtr+/Lycq1YsSJ4u7W1lRACgCtAv78Ne9y4ccrIyNChQ4f6vN/v9yslJSVkAQAMfv0eQEePHtXJkyeVnZ3d37sCAAwgxk/Btbe3h1zN1NXVad++fUpPT1d6erpWr16tRYsWKSsrS7W1tXr00Ud19dVXa968eWFtHAAwsBkH0O7duzVnzpzg7S9ev1myZInWrVun/fv364UXXlBzc7NycnJUXFysv/qrv7KaAQYAGLyMA2j27NkXHVT49ttvf6mG8Fs2AyFtBAIBqzqbwac2X5NNje0QThs2xy82NrYfOunNZnCnZHf8bL5PNscuUr3ZiuS+BjpmwQEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMCJsH8kN64co0ePNq45deqUcY3N5GjbicQ2k5ZtJ04PNjbHrru727jG5nhHavo4zHAFBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOMIw0itkO1IyUc+fORWQ/CQkJxjU9PT1W+7IZdBmpGpvzwXZQaiAQMK6Jj483runs7DSusTkONr3Zivaf22jCFRAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOMEwUlizGSQZGxtrXGMz9NRmP5LdEE6b4ZM2/XV1dRnX2A7GjIsz/6/BZl+nT582rrGRlpYWkf3ADFdAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEw0hhzWZwZ6T4fD6rOtvhnaZiYsx/97P9mmzYHAeb/mz2YzOcNjEx0bjGVqTOocGAKyAAgBMEEADACaMAqqio0NSpU5WcnKxRo0ZpwYIFqqmpCdnm7NmzKi0t1YgRIzRs2DAtWrRITU1NYW0aADDwGQVQVVWVSktLVV1dre3bt6u7u1vFxcXq6OgIbvPwww/rjTfe0Guvvaaqqio1NDRo4cKFYW8cADCwGb0JYdu2bSG3N2zYoFGjRmnPnj2aNWuWWlpa9E//9E/atGmTvva1r0mS1q9fr+uuu07V1dW6+eabw9c5AGBA+1KvAbW0tEiS0tPTJUl79uxRd3e3ioqKgttMnDhRY8aM0a5du/p8jM7OTrW2toYsAIDBzzqAAoGAHnroId1yyy2aPHmyJKmxsVEJCQm9Pn89MzNTjY2NfT5ORUWFUlNTg0tubq5tSwCAAcQ6gEpLS3XgwAG9/PLLX6qB8vJytbS0BJf6+vov9XgAgIHB6g9Ry8rK9Oabb2rnzp266qqrguuzsrLU1dWl5ubmkKugpqYmZWVl9flYfr9ffr/fpg0AwABmdAXkeZ7Kysq0efNmvfvuu8rLywu5v6CgQPHx8dqxY0dwXU1NjY4cOaLp06eHp2MAwKBgdAVUWlqqTZs2aevWrUpOTg6+rpOamqrExESlpqbqu9/9rlasWKH09HSlpKTowQcf1PTp03kHHAAghFEArVu3TpI0e/bskPXr16/X0qVLJUl/93d/p5iYGC1atEidnZ2aN2+ennvuubA0CwAYPIwC6HKG7A0ZMkRr167V2rVrrZvCwGAzUDNSon0g5GAcRmrzNUVqGGlSUpJxDfpf9P4PAgAY1AggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHDC6hNRERnRPtHZRmxsrOsWLsrmmEdqSnUkj12kzj2bCdo9PT3GNdF+3l2puAICADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcYRhrFbIZcRnKAaVdXl3FNUlJSP3QSPoFAwLjGZtDluXPnjGui/XyIlGgfRjoYj3l/4QoIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJxgGCkiKibG/Hcem+GTNoM7Jbv+IlVjMyjV9jjYsBnCaXMcbERyGCkuH1dAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAnCCAAgBMEEADACQIIAOAEw0ijmM1wx0hqaGgwrrn22muNa86dO2dcYzO407YuPj4+IvuxqbE9h2wGwMbFRea/E5uvKZLDSKP95zaacAUEAHCCAAIAOGEUQBUVFZo6daqSk5M1atQoLViwQDU1NSHbzJ49Wz6fL2R54IEHwto0AGDgMwqgqqoqlZaWqrq6Wtu3b1d3d7eKi4vV0dERst19992nY8eOBZc1a9aEtWkAwMBn9Krhtm3bQm5v2LBBo0aN0p49ezRr1qzg+qSkJGVlZYWnQwDAoPSlXgNqaWmRJKWnp4es37hxozIyMjR58mSVl5fr9OnTF3yMzs5Otba2hiwAgMHP+n2TgUBADz30kG655RZNnjw5uP7uu+/W2LFjlZOTo/379+uxxx5TTU2NXn/99T4fp6KiQqtXr7ZtAwAwQFkHUGlpqQ4cOKD33nsvZP2yZcuC/77hhhuUnZ2tuXPnqra2VuPHj+/1OOXl5VqxYkXwdmtrq3Jzc23bAgAMEFYBVFZWpjfffFM7d+7UVVddddFtCwsLJUmHDh3qM4D8fr/8fr9NGwCAAcwogDzP04MPPqjNmzersrJSeXl5l6zZt2+fJCk7O9uqQQDA4GQUQKWlpdq0aZO2bt2q5ORkNTY2SpJSU1OVmJio2tpabdq0SV//+tc1YsQI7d+/Xw8//LBmzZqlKVOm9MsXAAAYmIwCaN26dZLO/7Hp71q/fr2WLl2qhIQEvfPOO3rmmWfU0dGh3NxcLVq0SI8//njYGgYADA7GT8FdTG5urqqqqr5UQwCAKwPTsGEtLS3NuGbo0KHGNTZTljMyMoxrJCkmxvxP42xqbCZoR5LNNGybidP19fXGNUlJScY1fb0Bqr/YnA+209sHOoaRAgCcIIAAAE4QQAAAJwggAIATBBAAwAkCCADgBAEEAHCCAAIAOEEAAQCcIIAAAE4QQAAAJwggAIATDCONYj6fz7jmUhPLw2nv3r3GNb/85S+Na5qbm41rIjns02b4ZHt7u3GNzffW5hySpHPnzhnX2AzU7OrqMq4ZPny4cc2HH35oXGPrSh0saoMrIACAEwQQAMAJAggA4AQBBABwggACADhBAAEAnCCAAABOEEAAACcIIACAEwQQAMAJAggA4ETUzYKL5CyzaBftx+Ls2bPGNTZzsmz209PTY1xjy2YWXGdnp3ENs+DOszkfuru7jWvw5V3qnPV5Ufa/3NGjR5Wbm+u6DQDAl1RfX6+rrrrqgvdHXQAFAgE1NDQoOTm5129vra2tys3NVX19vVJSUhx16B7H4TyOw3kch/M4DudFw3HwPE9tbW3Kycm56DMEUfcUXExMzEUTU5JSUlKu6BPsCxyH8zgO53EczuM4nOf6OKSmpl5yG96EAABwggACADgxoALI7/dr5cqV8vv9rltxiuNwHsfhPI7DeRyH8wbScYi6NyEAAK4MA+oKCAAweBBAAAAnCCAAgBMEEADACQIIAODEgAmgtWvX6itf+YqGDBmiwsJCffjhh65birhVq1bJ5/OFLBMnTnTdVr/buXOnbrvtNuXk5Mjn82nLli0h93uepyeffFLZ2dlKTExUUVGRDh486KbZfnSp47B06dJe58f8+fPdNNtPKioqNHXqVCUnJ2vUqFFasGCBampqQrY5e/asSktLNWLECA0bNkyLFi1SU1OTo477x+Uch9mzZ/c6Hx544AFHHfdtQATQK6+8ohUrVmjlypX6+OOPlZ+fr3nz5un48eOuW4u466+/XseOHQsu7733nuuW+l1HR4fy8/O1du3aPu9fs2aNnn32WT3//PP64IMPNHToUM2bN89qanI0u9RxkKT58+eHnB8vvfRSBDvsf1VVVSotLVV1dbW2b9+u7u5uFRcXq6OjI7jNww8/rDfeeEOvvfaaqqqq1NDQoIULFzrsOvwu5zhI0n333RdyPqxZs8ZRxxfgDQDTpk3zSktLg7d7enq8nJwcr6KiwmFXkbdy5UovPz/fdRtOSfI2b94cvB0IBLysrCzvxz/+cXBdc3Oz5/f7vZdeeslBh5Hx+8fB8zxvyZIl3u233+6kH1eOHz/uSfKqqqo8zzv/vY+Pj/dee+214Db/8z//40nydu3a5arNfvf7x8HzPO/WW2/1/vRP/9RdU5ch6q+Aurq6tGfPHhUVFQXXxcTEqKioSLt27XLYmRsHDx5UTk6Oxo0bp3vuuUdHjhxx3ZJTdXV1amxsDDk/UlNTVVhYeEWeH5WVlRo1apQmTJig5cuX6+TJk65b6lctLS2SpPT0dEnSnj171N3dHXI+TJw4UWPGjBnU58PvH4cvbNy4URkZGZo8ebLKy8t1+vRpF+1dUNRNw/59n3/+uXp6epSZmRmyPjMzU59++qmjrtwoLCzUhg0bNGHCBB07dkyrV6/WzJkzdeDAASUnJ7tuz4nGxkZJ6vP8+OK+K8X8+fO1cOFC5eXlqba2Vn/xF3+hkpIS7dq1S7Gxsa7bC7tAIKCHHnpIt9xyiyZPnizp/PmQkJCgtLS0kG0H8/nQ13GQpLvvvltjx45VTk6O9u/fr8cee0w1NTV6/fXXHXYbKuoDCL9VUlIS/PeUKVNUWFiosWPH6tVXX9V3v/tdh50hGtx5553Bf99www2aMmWKxo8fr8rKSs2dO9dhZ/2jtLRUBw4cuCJeB72YCx2HZcuWBf99ww03KDs7W3PnzlVtba3Gjx8f6Tb7FPVPwWVkZCg2NrbXu1iampqUlZXlqKvokJaWpmuvvVaHDh1y3YozX5wDnB+9jRs3ThkZGYPy/CgrK9Obb76pn//85yGfH5aVlaWuri41NzeHbD9Yz4cLHYe+FBYWSlJUnQ9RH0AJCQkqKCjQjh07gusCgYB27Nih6dOnO+zMvfb2dtXW1io7O9t1K87k5eUpKysr5PxobW3VBx98cMWfH0ePHtXJkycH1fnheZ7Kysq0efNmvfvuu8rLywu5v6CgQPHx8SHnQ01NjY4cOTKozodLHYe+7Nu3T5Ki63xw/S6Iy/Hyyy97fr/f27Bhg/fLX/7SW7ZsmZeWluY1Nja6bi2i/uzP/syrrKz06urqvP/6r//yioqKvIyMDO/48eOuW+tXbW1t3t69e729e/d6krynn37a27t3r/frX//a8zzP+5u/+RsvLS3N27p1q7d//37v9ttv9/Ly8rwzZ8447jy8LnYc2travEceecTbtWuXV1dX573zzjveV7/6Ve+aa67xzp4967r1sFm+fLmXmprqVVZWeseOHQsup0+fDm7zwAMPeGPGjPHeffddb/fu3d706dO96dOnO+w6/C51HA4dOuT95V/+pbd7926vrq7O27p1qzdu3Dhv1qxZjjsPNSACyPM87yc/+Yk3ZswYLyEhwZs2bZpXXV3tuqWIW7x4sZedne0lJCR4o0eP9hYvXuwdOnTIdVv97uc//7knqdeyZMkSz/POvxX7iSee8DIzMz2/3+/NnTvXq6mpcdt0P7jYcTh9+rRXXFzsjRw50ouPj/fGjh3r3XfffYPul7S+vn5J3vr164PbnDlzxvv+97/vDR8+3EtKSvLuuOMO79ixY+6a7geXOg5HjhzxZs2a5aWnp3t+v9+7+uqrvT//8z/3Wlpa3Db+e/g8IACAE1H/GhAAYHAigAAAThBAAAAnCCAAgBMEEADACQIIAOAEAQQAcIIAAgA4QQABAJwggAAAThBAAAAn/h+7AaIJ0I30agAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "plt.title(classnames[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19667e47-f9f3-4871-a903-243840469372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "    plt.title(classnames[label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745289fe-a893-4af0-b60a-fd7ad2c9c321",
   "metadata": {},
   "source": [
    "**Prepare DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feebf65c-8c2b-4c4b-813c-9babba3d3f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f06ecfb8-d9f1-441a-b0f7-39caeece1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af152fe-aeb5-4709-82dc-b5a104e7e691",
   "metadata": {},
   "source": [
    "**Model 0: Build a baseline model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ae7787-5704-42ce-b8ee-1ef9fbdc975d",
   "metadata": {},
   "source": [
    "when starting to build a series of machine learning modelling experiments, best practice\n",
    "is to start with a base line model.\n",
    "A base line model is a simple model you will try to imporve upon subsequent experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a78e3034-5765-4b19-8f50-7e7a1507595c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data before flattening torch.Size([1, 28, 28])\n",
      "Shape of the data after flattening torch.Size([1, 784])\n",
      "Shape of the data after squeezing the flattened data: torch.Size([784])\n"
     ]
    }
   ],
   "source": [
    "flatten_model = nn.Flatten()\n",
    "image, label = train_data[0]\n",
    "print(f\"Shape of the data before flattening {image.shape}\")\n",
    "x = flatten_model(image)\n",
    "print(f\"Shape of the data after flattening {x.shape}\")\n",
    "print(f\"Shape of the data after squeezing the flattened data: {x.squeeze().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16d0628d-cfcf-4a8e-a645-2a53157079df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FashionMNISTModel(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, out_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape,out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=out_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef5eecd3-15d0-4c25-8cd2-3714895b9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_0 = FashionMNISTModel(input_shape=28 * 28, hidden_units=10, out_shape=len(classnames)).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4c6dabd-5011-4859-a26c-de0318954521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0315,  0.3171,  0.0531, -0.2525,  0.5959,  0.2112,  0.3233,  0.2694,\n",
       "          -0.1004,  0.0157]]),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    dummy_x = torch.rand([1, 1, 28, 28])\n",
    "    y_pred = model_0(dummy_x)\n",
    "\n",
    "y_pred, y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4d150-88cf-4692-a515-f7089d480d12",
   "metadata": {},
   "source": [
    "**Setup loss and optimization function with some evaluation metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea591af5-1aa3-4800-8d95-185a1d062a8b",
   "metadata": {},
   "source": [
    "- We are going to use `CrossEntropyLoss` since the problem is a multi class classification problem\n",
    "- Optimizer - Our optimizer is going to be stochastic gradient descent\n",
    "- Evaluation metrics - accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48bc9d88-6319-492e-9003-4ac7e2a17177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e8da1e9-cf57-4d8b-83ad-5158328f5436",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80e7582f-52e2-4ff2-aac7-c36970d32885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what's inside the training dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b4778b7-63ae-4023-ae32-1b6006c41656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7f95be8-4c43-473e-8cc1-d1ef3440b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57c09eee-fca0-4b33-9db5-bbd426b5f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3488ce6-1f50-4d00-87ff-140afe31c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15f4c827-a6b1-4872-bae3-780052f75e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time on cpu: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "# ....\n",
    "end = timer()\n",
    "print_train_time(start=start, end=end, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7dc000ad-b258-4747-a720-dfbccf7974ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_data, # dataset to turn into iterable\n",
    "    batch_size=BATCH_SIZE, # how many samples per batch? \n",
    "    shuffle=True # shuffle data every epoch?\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9435180-01ae-46b7-88b1-876d4386b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Different approach? the training loop will update the weights after every batch not loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1318e06-7691-4f5d-ab3c-0a3bd414f6bc",
   "metadata": {},
   "source": [
    "### 3.3 Creating a training loop and training a model on batches of data\n",
    "1. Loop through epochs\n",
    "2. Loop through training batches, perform training steps and calculate train loss **per batch**\n",
    "3. Loop through testing batches, perform testing steps, calculate the test loss **per batch**\n",
    "4. Print out what's happening\n",
    "5. Time it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2701208-ca53-4084-95af-e4b07a6730ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer_stack.1.weight',\n",
       "              tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "                      [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
       "                      [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
       "                      ...,\n",
       "                      [-0.0116,  0.0273, -0.0344,  ...,  0.0176,  0.0283, -0.0011],\n",
       "                      [-0.0230,  0.0257,  0.0291,  ..., -0.0187, -0.0087,  0.0001],\n",
       "                      [ 0.0176, -0.0147,  0.0053,  ..., -0.0336, -0.0221,  0.0205]])),\n",
       "             ('layer_stack.1.bias',\n",
       "              tensor([-0.0093,  0.0283, -0.0033,  0.0255,  0.0017,  0.0037, -0.0302, -0.0123,\n",
       "                       0.0018,  0.0163])),\n",
       "             ('layer_stack.2.weight',\n",
       "              tensor([[ 0.0614, -0.0687,  0.0021,  0.2718,  0.2109,  0.1079, -0.2279, -0.1063,\n",
       "                        0.2019,  0.2847],\n",
       "                      [-0.1495,  0.1344, -0.0740,  0.2006, -0.0475, -0.2514, -0.3130, -0.0118,\n",
       "                        0.0932, -0.1864],\n",
       "                      [ 0.2488,  0.1500,  0.1907,  0.1457, -0.3050, -0.0580,  0.1643,  0.1565,\n",
       "                       -0.2877, -0.1792],\n",
       "                      [ 0.2305, -0.2618,  0.2397, -0.0610,  0.0232,  0.1542,  0.0851, -0.2027,\n",
       "                        0.1030, -0.2715],\n",
       "                      [-0.1596, -0.0555, -0.0633,  0.2302, -0.1726,  0.2654,  0.1473,  0.1029,\n",
       "                        0.2252, -0.2160],\n",
       "                      [-0.2725,  0.0118,  0.1559,  0.1596,  0.0132,  0.3024,  0.1124,  0.1366,\n",
       "                       -0.1533,  0.0965],\n",
       "                      [-0.1184, -0.2555, -0.2057, -0.1909, -0.0477, -0.1324,  0.2905,  0.1307,\n",
       "                       -0.2629,  0.0133],\n",
       "                      [ 0.2727, -0.0127,  0.0513,  0.0863, -0.1043, -0.2047, -0.1185, -0.0825,\n",
       "                        0.2488, -0.2571],\n",
       "                      [ 0.0425, -0.1209, -0.0336, -0.0281, -0.1227,  0.0730,  0.0747, -0.1816,\n",
       "                        0.1943,  0.2853],\n",
       "                      [-0.1310,  0.0645, -0.1171,  0.2168, -0.0245, -0.2820,  0.0736,  0.2621,\n",
       "                        0.0012, -0.0810]])),\n",
       "             ('layer_stack.2.bias',\n",
       "              tensor([-0.0087,  0.1791,  0.2712, -0.0791,  0.1685,  0.1762,  0.2825,  0.2266,\n",
       "                      -0.2612, -0.2613]))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c397ee8-4923-46ff-b127-32e1face8815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/prince/anaconda3/envs/penv/lib/python3.11/site-packages (4.66.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a5e2a60-fee2-4e47-8357-76a380a7a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b0f0417-194d-48e5-b882-d7f24408f205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                     | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-----\n",
      "Looked at 0 / 60000 samples\n",
      "Train loss: 0.0011 | Test loss: 2.3284 | Test acc: 17.4022\n",
      "Train loss: 0.0012 | Test loss: 2.2144 | Test acc: 20.0436\n",
      "Train loss: 0.0012 | Test loss: 2.1652 | Test acc: 19.3332\n",
      "Train loss: 0.0012 | Test loss: 2.1313 | Test acc: 21.6273\n",
      "Train loss: 0.0011 | Test loss: 2.0786 | Test acc: 34.0348\n",
      "Train loss: 0.0011 | Test loss: 2.0262 | Test acc: 36.0313\n",
      "Train loss: 0.0011 | Test loss: 1.9818 | Test acc: 37.1758\n",
      "Train loss: 0.0010 | Test loss: 2.0218 | Test acc: 26.1371\n",
      "Train loss: 0.0011 | Test loss: 1.9281 | Test acc: 37.9130\n",
      "Train loss: 0.0010 | Test loss: 1.8839 | Test acc: 42.7030\n",
      "Train loss: 0.0010 | Test loss: 1.8297 | Test acc: 40.8213\n",
      "Train loss: 0.0010 | Test loss: 1.8173 | Test acc: 40.9751\n",
      "Train loss: 0.0010 | Test loss: 1.7728 | Test acc: 43.4516\n",
      "Train loss: 0.0010 | Test loss: 1.7189 | Test acc: 43.9288\n",
      "Train loss: 0.0009 | Test loss: 1.7448 | Test acc: 43.8804\n",
      "Train loss: 0.0009 | Test loss: 1.6457 | Test acc: 51.6178\n",
      "Train loss: 0.0009 | Test loss: 1.5797 | Test acc: 58.8510\n",
      "Train loss: 0.0008 | Test loss: 1.5486 | Test acc: 59.8226\n",
      "Train loss: 0.0008 | Test loss: 1.5687 | Test acc: 43.1324\n",
      "Train loss: 0.0009 | Test loss: 1.5231 | Test acc: 52.0947\n",
      "Train loss: 0.0008 | Test loss: 1.4660 | Test acc: 54.5394\n",
      "Train loss: 0.0007 | Test loss: 1.4264 | Test acc: 57.1830\n",
      "Train loss: 0.0008 | Test loss: 1.3820 | Test acc: 61.0653\n",
      "Train loss: 0.0006 | Test loss: 1.3828 | Test acc: 59.6300\n",
      "Train loss: 0.0007 | Test loss: 1.3755 | Test acc: 58.9066\n",
      "Train loss: 0.0008 | Test loss: 1.2982 | Test acc: 60.9310\n",
      "Train loss: 0.0007 | Test loss: 1.2746 | Test acc: 59.4399\n",
      "Train loss: 0.0007 | Test loss: 1.2581 | Test acc: 58.1771\n",
      "Train loss: 0.0006 | Test loss: 1.2401 | Test acc: 56.3959\n",
      "Train loss: 0.0005 | Test loss: 1.2061 | Test acc: 59.4154\n",
      "Train loss: 0.0007 | Test loss: 1.3097 | Test acc: 51.2581\n",
      "Train loss: 0.0006 | Test loss: 1.1989 | Test acc: 59.7384\n",
      "Train loss: 0.0006 | Test loss: 1.1758 | Test acc: 61.8722\n",
      "Train loss: 0.0006 | Test loss: 1.1165 | Test acc: 64.3251\n",
      "Train loss: 0.0006 | Test loss: 1.1397 | Test acc: 62.7355\n",
      "Train loss: 0.0006 | Test loss: 1.2339 | Test acc: 58.5970\n",
      "Train loss: 0.0007 | Test loss: 1.0878 | Test acc: 62.1680\n",
      "Train loss: 0.0004 | Test loss: 1.1042 | Test acc: 59.5137\n",
      "Train loss: 0.0006 | Test loss: 1.0743 | Test acc: 62.6802\n",
      "Train loss: 0.0006 | Test loss: 1.0741 | Test acc: 60.7733\n",
      "Train loss: 0.0006 | Test loss: 1.0467 | Test acc: 66.6478\n",
      "Train loss: 0.0006 | Test loss: 1.0749 | Test acc: 64.6698\n",
      "Train loss: 0.0005 | Test loss: 1.0713 | Test acc: 61.9079\n",
      "Train loss: 0.0006 | Test loss: 1.0302 | Test acc: 62.7178\n",
      "Train loss: 0.0005 | Test loss: 1.0218 | Test acc: 64.7571\n",
      "Train loss: 0.0005 | Test loss: 1.0345 | Test acc: 62.1278\n",
      "Train loss: 0.0005 | Test loss: 0.9723 | Test acc: 66.0431\n",
      "Train loss: 0.0004 | Test loss: 0.9855 | Test acc: 63.1004\n",
      "Train loss: 0.0006 | Test loss: 0.9854 | Test acc: 64.7683\n",
      "Train loss: 0.0005 | Test loss: 0.9787 | Test acc: 64.9134\n",
      "Train loss: 0.0005 | Test loss: 0.9707 | Test acc: 63.3863\n",
      "Train loss: 0.0005 | Test loss: 0.9419 | Test acc: 66.6961\n",
      "Train loss: 0.0004 | Test loss: 0.9360 | Test acc: 65.2490\n",
      "Train loss: 0.0005 | Test loss: 0.9329 | Test acc: 65.6438\n",
      "Train loss: 0.0007 | Test loss: 0.9374 | Test acc: 66.3639\n",
      "Train loss: 0.0005 | Test loss: 0.9563 | Test acc: 63.9401\n",
      "Train loss: 0.0005 | Test loss: 0.9100 | Test acc: 67.9559\n",
      "Train loss: 0.0004 | Test loss: 0.9332 | Test acc: 66.4312\n",
      "Train loss: 0.0004 | Test loss: 0.9568 | Test acc: 64.2598\n",
      "Train loss: 0.0006 | Test loss: 0.9330 | Test acc: 68.6658\n",
      "Train loss: 0.0005 | Test loss: 0.9268 | Test acc: 65.2553\n",
      "Train loss: 0.0005 | Test loss: 0.9394 | Test acc: 65.1845\n",
      "Train loss: 0.0004 | Test loss: 0.8947 | Test acc: 68.8784\n",
      "Train loss: 0.0004 | Test loss: 0.9098 | Test acc: 67.6522\n",
      "Train loss: 0.0005 | Test loss: 0.8799 | Test acc: 68.0576\n",
      "Train loss: 0.0005 | Test loss: 0.9155 | Test acc: 65.2534\n",
      "Train loss: 0.0005 | Test loss: 0.8836 | Test acc: 68.1598\n",
      "Train loss: 0.0004 | Test loss: 0.9093 | Test acc: 67.7297\n",
      "Train loss: 0.0004 | Test loss: 0.8795 | Test acc: 66.8797\n",
      "Train loss: 0.0005 | Test loss: 0.9041 | Test acc: 67.2364\n",
      "Train loss: 0.0004 | Test loss: 0.9186 | Test acc: 67.2276\n",
      "Train loss: 0.0005 | Test loss: 0.8614 | Test acc: 66.6485\n",
      "Train loss: 0.0003 | Test loss: 0.9289 | Test acc: 65.6383\n",
      "Train loss: 0.0004 | Test loss: 0.8993 | Test acc: 67.2125\n",
      "Train loss: 0.0005 | Test loss: 0.8545 | Test acc: 69.8933\n",
      "Train loss: 0.0006 | Test loss: 0.9870 | Test acc: 65.5887\n",
      "Train loss: 0.0005 | Test loss: 0.8615 | Test acc: 68.1409\n",
      "Train loss: 0.0004 | Test loss: 0.9182 | Test acc: 65.5332\n",
      "Train loss: 0.0006 | Test loss: 0.9579 | Test acc: 64.5065\n",
      "Train loss: 0.0006 | Test loss: 0.8358 | Test acc: 69.6150\n",
      "Train loss: 0.0004 | Test loss: 0.8390 | Test acc: 69.2520\n",
      "Train loss: 0.0005 | Test loss: 0.8431 | Test acc: 70.0296\n",
      "Train loss: 0.0005 | Test loss: 0.8875 | Test acc: 68.6243\n",
      "Train loss: 0.0006 | Test loss: 0.8693 | Test acc: 67.7212\n",
      "Train loss: 0.0004 | Test loss: 0.8230 | Test acc: 69.7052\n",
      "Train loss: 0.0003 | Test loss: 0.8314 | Test acc: 68.9627\n",
      "Train loss: 0.0004 | Test loss: 0.8689 | Test acc: 68.2415\n",
      "Train loss: 0.0005 | Test loss: 0.8424 | Test acc: 70.0163\n",
      "Train loss: 0.0004 | Test loss: 0.8242 | Test acc: 69.8723\n",
      "Train loss: 0.0004 | Test loss: 0.8383 | Test acc: 70.9700\n",
      "Train loss: 0.0005 | Test loss: 0.8026 | Test acc: 71.5926\n",
      "Train loss: 0.0004 | Test loss: 0.8095 | Test acc: 70.8358\n",
      "Train loss: 0.0004 | Test loss: 0.8309 | Test acc: 70.7934\n",
      "Train loss: 0.0005 | Test loss: 0.8056 | Test acc: 72.0812\n",
      "Train loss: 0.0003 | Test loss: 0.8386 | Test acc: 68.0817\n",
      "Train loss: 0.0004 | Test loss: 0.8034 | Test acc: 70.3453\n",
      "Train loss: 0.0003 | Test loss: 0.7842 | Test acc: 71.5606\n",
      "Train loss: 0.0005 | Test loss: 0.8088 | Test acc: 68.2997\n",
      "Train loss: 0.0003 | Test loss: 0.8160 | Test acc: 67.9998\n",
      "Train loss: 0.0004 | Test loss: 0.7899 | Test acc: 71.5132\n",
      "Train loss: 0.0003 | Test loss: 0.8054 | Test acc: 68.5392\n",
      "Train loss: 0.0006 | Test loss: 0.8394 | Test acc: 67.7310\n",
      "Train loss: 0.0004 | Test loss: 0.8689 | Test acc: 68.8566\n",
      "Train loss: 0.0004 | Test loss: 0.7945 | Test acc: 72.8238\n",
      "Train loss: 0.0004 | Test loss: 0.8033 | Test acc: 71.2790\n",
      "Train loss: 0.0003 | Test loss: 0.7682 | Test acc: 72.6219\n",
      "Train loss: 0.0004 | Test loss: 0.8222 | Test acc: 69.9605\n",
      "Train loss: 0.0004 | Test loss: 0.7974 | Test acc: 72.6876\n",
      "Train loss: 0.0005 | Test loss: 0.8311 | Test acc: 68.9822\n",
      "Train loss: 0.0004 | Test loss: 0.8555 | Test acc: 67.5826\n",
      "Train loss: 0.0003 | Test loss: 0.7807 | Test acc: 72.0310\n",
      "Train loss: 0.0005 | Test loss: 0.8067 | Test acc: 69.8687\n",
      "Train loss: 0.0005 | Test loss: 0.8238 | Test acc: 68.6837\n",
      "Train loss: 0.0006 | Test loss: 0.7809 | Test acc: 72.1144\n",
      "Train loss: 0.0005 | Test loss: 0.7564 | Test acc: 74.2320\n",
      "Train loss: 0.0004 | Test loss: 0.7566 | Test acc: 73.9193\n",
      "Train loss: 0.0005 | Test loss: 0.8487 | Test acc: 69.4654\n",
      "Train loss: 0.0004 | Test loss: 0.7628 | Test acc: 70.5195\n",
      "Train loss: 0.0005 | Test loss: 0.7542 | Test acc: 74.4166\n",
      "Train loss: 0.0004 | Test loss: 0.7580 | Test acc: 74.4790\n",
      "Train loss: 0.0005 | Test loss: 0.8108 | Test acc: 71.9632\n",
      "Train loss: 0.0005 | Test loss: 0.8870 | Test acc: 69.0598\n",
      "Train loss: 0.0007 | Test loss: 0.7612 | Test acc: 72.3752\n",
      "Train loss: 0.0003 | Test loss: 0.7672 | Test acc: 71.9764\n",
      "Train loss: 0.0004 | Test loss: 0.7492 | Test acc: 73.7923\n",
      "Train loss: 0.0004 | Test loss: 0.7688 | Test acc: 72.0908\n",
      "Train loss: 0.0004 | Test loss: 0.7659 | Test acc: 71.1169\n",
      "Train loss: 0.0005 | Test loss: 0.7789 | Test acc: 70.9141\n",
      "Train loss: 0.0004 | Test loss: 0.7807 | Test acc: 69.6754\n",
      "Train loss: 0.0003 | Test loss: 0.7364 | Test acc: 73.0561\n",
      "Train loss: 0.0004 | Test loss: 0.7537 | Test acc: 74.1352\n",
      "Train loss: 0.0003 | Test loss: 0.7944 | Test acc: 70.7640\n",
      "Train loss: 0.0004 | Test loss: 0.7295 | Test acc: 74.6270\n",
      "Train loss: 0.0003 | Test loss: 0.7843 | Test acc: 73.3215\n",
      "Train loss: 0.0004 | Test loss: 0.7347 | Test acc: 74.9148\n",
      "Train loss: 0.0004 | Test loss: 0.7145 | Test acc: 74.7501\n",
      "Train loss: 0.0004 | Test loss: 0.7218 | Test acc: 75.3986\n",
      "Train loss: 0.0004 | Test loss: 0.7748 | Test acc: 70.9777\n",
      "Train loss: 0.0004 | Test loss: 0.7390 | Test acc: 73.9887\n",
      "Train loss: 0.0003 | Test loss: 0.7375 | Test acc: 74.0084\n",
      "Train loss: 0.0004 | Test loss: 0.7212 | Test acc: 75.8355\n",
      "Train loss: 0.0003 | Test loss: 0.7750 | Test acc: 72.4567\n",
      "Train loss: 0.0005 | Test loss: 0.7856 | Test acc: 73.3944\n",
      "Train loss: 0.0002 | Test loss: 0.7447 | Test acc: 72.8683\n",
      "Train loss: 0.0004 | Test loss: 0.7409 | Test acc: 73.6753\n",
      "Train loss: 0.0004 | Test loss: 0.8029 | Test acc: 69.0852\n",
      "Train loss: 0.0004 | Test loss: 0.7429 | Test acc: 73.9527\n",
      "Train loss: 0.0003 | Test loss: 0.8264 | Test acc: 70.3541\n",
      "Train loss: 0.0005 | Test loss: 0.7252 | Test acc: 73.7471\n",
      "Train loss: 0.0003 | Test loss: 0.7166 | Test acc: 72.8994\n",
      "Train loss: 0.0003 | Test loss: 0.7527 | Test acc: 71.4989\n",
      "Train loss: 0.0005 | Test loss: 0.7325 | Test acc: 72.7724\n",
      "Train loss: 0.0003 | Test loss: 0.7411 | Test acc: 74.4637\n",
      "Train loss: 0.0003 | Test loss: 0.7370 | Test acc: 72.6421\n",
      "Train loss: 0.0004 | Test loss: 0.8434 | Test acc: 68.2233\n",
      "Train loss: 0.0005 | Test loss: 0.7580 | Test acc: 71.2543\n",
      "Train loss: 0.0002 | Test loss: 0.7636 | Test acc: 71.2939\n",
      "Train loss: 0.0004 | Test loss: 0.7487 | Test acc: 72.4422\n",
      "Train loss: 0.0005 | Test loss: 0.7314 | Test acc: 73.0749\n",
      "Train loss: 0.0004 | Test loss: 0.7250 | Test acc: 74.8141\n",
      "Train loss: 0.0003 | Test loss: 0.6959 | Test acc: 74.9495\n",
      "Train loss: 0.0003 | Test loss: 0.6969 | Test acc: 74.8002\n",
      "Train loss: 0.0004 | Test loss: 0.7824 | Test acc: 71.4251\n",
      "Train loss: 0.0004 | Test loss: 0.7539 | Test acc: 72.8420\n",
      "Train loss: 0.0004 | Test loss: 0.7955 | Test acc: 69.6716\n",
      "Train loss: 0.0005 | Test loss: 0.7273 | Test acc: 73.9247\n",
      "Train loss: 0.0003 | Test loss: 0.7582 | Test acc: 70.9031\n",
      "Train loss: 0.0003 | Test loss: 0.7182 | Test acc: 74.9969\n",
      "Train loss: 0.0004 | Test loss: 0.7127 | Test acc: 74.0815\n",
      "Train loss: 0.0003 | Test loss: 0.7432 | Test acc: 72.1317\n",
      "Train loss: 0.0004 | Test loss: 0.7256 | Test acc: 74.6614\n",
      "Train loss: 0.0003 | Test loss: 0.7034 | Test acc: 76.5564\n",
      "Train loss: 0.0003 | Test loss: 0.6796 | Test acc: 76.0034\n",
      "Train loss: 0.0004 | Test loss: 0.6900 | Test acc: 75.9617\n",
      "Train loss: 0.0004 | Test loss: 0.7154 | Test acc: 73.9547\n",
      "Train loss: 0.0003 | Test loss: 0.7146 | Test acc: 73.0498\n",
      "Train loss: 0.0003 | Test loss: 0.6922 | Test acc: 75.6228\n",
      "Train loss: 0.0004 | Test loss: 0.7522 | Test acc: 74.4928\n",
      "Train loss: 0.0003 | Test loss: 0.6841 | Test acc: 76.6358\n",
      "Train loss: 0.0003 | Test loss: 0.7349 | Test acc: 73.6674\n",
      "Train loss: 0.0003 | Test loss: 0.7350 | Test acc: 73.7977\n",
      "Train loss: 0.0004 | Test loss: 0.6966 | Test acc: 74.2374\n",
      "Train loss: 0.0004 | Test loss: 0.7096 | Test acc: 75.3370\n",
      "Train loss: 0.0004 | Test loss: 0.6836 | Test acc: 76.0095\n",
      "Train loss: 0.0004 | Test loss: 0.6825 | Test acc: 76.0216\n",
      "Train loss: 0.0003 | Test loss: 0.7305 | Test acc: 71.7285\n",
      "Train loss: 0.0003 | Test loss: 0.7091 | Test acc: 75.1593\n",
      "Train loss: 0.0003 | Test loss: 0.6863 | Test acc: 76.1387\n",
      "Train loss: 0.0003 | Test loss: 0.6762 | Test acc: 76.2217\n",
      "Train loss: 0.0003 | Test loss: 0.6769 | Test acc: 76.1021\n",
      "Train loss: 0.0003 | Test loss: 0.6970 | Test acc: 75.6225\n",
      "Train loss: 0.0004 | Test loss: 0.6630 | Test acc: 76.6993\n",
      "Train loss: 0.0003 | Test loss: 0.6719 | Test acc: 76.7626\n",
      "Train loss: 0.0003 | Test loss: 0.6836 | Test acc: 75.6346\n",
      "Train loss: 0.0003 | Test loss: 0.6734 | Test acc: 76.5296\n",
      "Train loss: 0.0003 | Test loss: 0.6498 | Test acc: 77.3811\n",
      "Train loss: 0.0003 | Test loss: 0.6753 | Test acc: 76.3455\n",
      "Train loss: 0.0003 | Test loss: 0.6636 | Test acc: 76.8014\n",
      "Train loss: 0.0004 | Test loss: 0.7191 | Test acc: 74.0872\n",
      "Train loss: 0.0003 | Test loss: 0.6763 | Test acc: 76.6345\n",
      "Train loss: 0.0003 | Test loss: 0.6787 | Test acc: 76.8623\n",
      "Train loss: 0.0004 | Test loss: 0.6837 | Test acc: 76.5834\n",
      "Train loss: 0.0003 | Test loss: 0.7063 | Test acc: 73.8868\n",
      "Train loss: 0.0004 | Test loss: 0.6801 | Test acc: 75.9050\n",
      "Train loss: 0.0003 | Test loss: 0.7118 | Test acc: 75.3523\n",
      "Train loss: 0.0004 | Test loss: 0.6696 | Test acc: 77.2076\n",
      "Train loss: 0.0003 | Test loss: 0.6519 | Test acc: 77.9424\n",
      "Train loss: 0.0003 | Test loss: 0.7527 | Test acc: 71.1056\n",
      "Train loss: 0.0005 | Test loss: 0.6685 | Test acc: 76.4153\n",
      "Train loss: 0.0003 | Test loss: 0.6685 | Test acc: 76.8516\n",
      "Train loss: 0.0003 | Test loss: 0.7054 | Test acc: 73.8278\n",
      "Train loss: 0.0003 | Test loss: 0.6855 | Test acc: 76.1844\n",
      "Train loss: 0.0004 | Test loss: 0.7557 | Test acc: 71.7190\n",
      "Train loss: 0.0003 | Test loss: 0.6969 | Test acc: 74.9695\n",
      "Train loss: 0.0003 | Test loss: 0.7174 | Test acc: 74.2811\n",
      "Train loss: 0.0004 | Test loss: 0.7806 | Test acc: 72.1423\n",
      "Train loss: 0.0003 | Test loss: 0.7399 | Test acc: 73.1338\n",
      "Train loss: 0.0003 | Test loss: 0.6506 | Test acc: 77.3902\n",
      "Train loss: 0.0005 | Test loss: 0.6472 | Test acc: 77.0544\n",
      "Train loss: 0.0003 | Test loss: 0.6576 | Test acc: 77.1032\n",
      "Train loss: 0.0005 | Test loss: 0.6864 | Test acc: 75.7655\n",
      "Train loss: 0.0003 | Test loss: 0.6507 | Test acc: 76.7596\n",
      "Train loss: 0.0004 | Test loss: 0.6537 | Test acc: 77.0224\n",
      "Train loss: 0.0002 | Test loss: 0.7026 | Test acc: 73.8283\n",
      "Train loss: 0.0003 | Test loss: 0.6582 | Test acc: 76.0845\n",
      "Train loss: 0.0004 | Test loss: 0.7226 | Test acc: 74.4743\n",
      "Train loss: 0.0004 | Test loss: 0.6988 | Test acc: 75.7970\n",
      "Train loss: 0.0003 | Test loss: 0.6727 | Test acc: 75.7314\n",
      "Train loss: 0.0004 | Test loss: 0.7443 | Test acc: 72.0371\n",
      "Train loss: 0.0004 | Test loss: 0.6522 | Test acc: 76.5181\n",
      "Train loss: 0.0004 | Test loss: 0.7019 | Test acc: 73.9865\n",
      "Train loss: 0.0005 | Test loss: 0.7010 | Test acc: 75.2064\n",
      "Train loss: 0.0002 | Test loss: 0.6333 | Test acc: 77.6464\n",
      "Train loss: 0.0003 | Test loss: 0.6756 | Test acc: 76.2864\n",
      "Train loss: 0.0003 | Test loss: 0.6678 | Test acc: 76.0924\n",
      "Train loss: 0.0005 | Test loss: 0.7677 | Test acc: 71.0398\n",
      "Train loss: 0.0004 | Test loss: 0.6721 | Test acc: 75.4466\n",
      "Train loss: 0.0003 | Test loss: 0.6633 | Test acc: 76.4691\n",
      "Train loss: 0.0002 | Test loss: 0.6563 | Test acc: 76.5822\n",
      "Train loss: 0.0003 | Test loss: 0.6720 | Test acc: 76.4827\n",
      "Train loss: 0.0004 | Test loss: 0.7253 | Test acc: 75.2943\n",
      "Train loss: 0.0005 | Test loss: 0.6797 | Test acc: 76.7481\n",
      "Train loss: 0.0003 | Test loss: 0.6786 | Test acc: 75.3850\n",
      "Train loss: 0.0004 | Test loss: 0.6740 | Test acc: 76.5188\n",
      "Train loss: 0.0004 | Test loss: 0.6908 | Test acc: 76.5324\n",
      "Train loss: 0.0002 | Test loss: 0.7643 | Test acc: 72.1295\n",
      "Train loss: 0.0003 | Test loss: 0.7795 | Test acc: 72.6046\n",
      "Train loss: 0.0004 | Test loss: 0.7112 | Test acc: 73.3150\n",
      "Train loss: 0.0005 | Test loss: 0.6843 | Test acc: 75.9331\n",
      "Train loss: 0.0003 | Test loss: 0.6641 | Test acc: 76.7102\n",
      "Train loss: 0.0003 | Test loss: 0.6846 | Test acc: 75.8841\n",
      "Train loss: 0.0003 | Test loss: 0.6683 | Test acc: 76.8599\n",
      "Train loss: 0.0003 | Test loss: 0.6475 | Test acc: 77.5818\n",
      "Train loss: 0.0004 | Test loss: 0.6361 | Test acc: 77.6340\n",
      "Train loss: 0.0003 | Test loss: 0.9669 | Test acc: 67.7600\n",
      "Train loss: 0.0004 | Test loss: 0.7319 | Test acc: 74.0084\n",
      "Train loss: 0.0003 | Test loss: 0.7115 | Test acc: 75.0667\n",
      "Train loss: 0.0003 | Test loss: 0.6519 | Test acc: 76.9970\n",
      "Train loss: 0.0003 | Test loss: 0.6709 | Test acc: 76.2843\n",
      "Train loss: 0.0004 | Test loss: 0.8145 | Test acc: 69.6127\n",
      "Train loss: 0.0003 | Test loss: 0.7201 | Test acc: 73.5351\n",
      "Train loss: 0.0003 | Test loss: 0.6521 | Test acc: 76.8424\n",
      "Train loss: 0.0003 | Test loss: 0.7096 | Test acc: 73.7080\n",
      "Train loss: 0.0005 | Test loss: 0.6418 | Test acc: 77.3521\n",
      "Train loss: 0.0003 | Test loss: 0.6942 | Test acc: 74.9476\n",
      "Train loss: 0.0004 | Test loss: 0.6305 | Test acc: 77.5358\n",
      "Train loss: 0.0002 | Test loss: 0.6298 | Test acc: 77.8436\n",
      "Train loss: 0.0003 | Test loss: 0.6280 | Test acc: 77.4652\n",
      "Train loss: 0.0003 | Test loss: 0.6456 | Test acc: 77.7735\n",
      "Train loss: 0.0002 | Test loss: 0.6623 | Test acc: 77.7944\n",
      "Train loss: 0.0003 | Test loss: 0.6398 | Test acc: 77.2354\n",
      "Train loss: 0.0004 | Test loss: 0.6653 | Test acc: 76.9440\n",
      "Train loss: 0.0003 | Test loss: 0.6251 | Test acc: 78.3209\n",
      "Train loss: 0.0006 | Test loss: 0.7921 | Test acc: 74.0521\n",
      "Train loss: 0.0003 | Test loss: 0.6815 | Test acc: 75.4862\n",
      "Train loss: 0.0002 | Test loss: 0.6833 | Test acc: 75.7404\n",
      "Train loss: 0.0003 | Test loss: 0.6563 | Test acc: 77.1190\n",
      "Train loss: 0.0003 | Test loss: 0.6228 | Test acc: 78.8606\n",
      "Train loss: 0.0004 | Test loss: 0.6760 | Test acc: 76.0507\n",
      "Train loss: 0.0003 | Test loss: 0.6509 | Test acc: 76.7206\n",
      "Train loss: 0.0003 | Test loss: 0.6555 | Test acc: 76.4332\n",
      "Train loss: 0.0003 | Test loss: 0.6308 | Test acc: 77.5505\n",
      "Train loss: 0.0003 | Test loss: 0.6391 | Test acc: 77.4343\n",
      "Train loss: 0.0004 | Test loss: 0.6250 | Test acc: 78.8217\n",
      "Train loss: 0.0003 | Test loss: 0.6750 | Test acc: 76.4399\n",
      "Train loss: 0.0003 | Test loss: 0.6432 | Test acc: 77.6404\n",
      "Train loss: 0.0004 | Test loss: 0.6429 | Test acc: 78.0136\n",
      "Train loss: 0.0003 | Test loss: 0.6285 | Test acc: 77.7952\n",
      "Train loss: 0.0002 | Test loss: 0.6164 | Test acc: 79.1823\n",
      "Train loss: 0.0003 | Test loss: 0.6489 | Test acc: 77.6192\n",
      "Train loss: 0.0004 | Test loss: 0.6552 | Test acc: 75.4676\n",
      "Train loss: 0.0003 | Test loss: 0.6667 | Test acc: 75.0914\n",
      "Train loss: 0.0004 | Test loss: 0.6987 | Test acc: 74.3413\n",
      "Train loss: 0.0005 | Test loss: 0.6924 | Test acc: 76.1560\n",
      "Train loss: 0.0002 | Test loss: 0.6912 | Test acc: 75.4729\n",
      "Train loss: 0.0005 | Test loss: 0.6405 | Test acc: 77.7172\n",
      "Train loss: 0.0004 | Test loss: 0.6602 | Test acc: 76.8757\n",
      "Train loss: 0.0004 | Test loss: 0.6677 | Test acc: 76.0943\n",
      "Train loss: 0.0003 | Test loss: 0.6715 | Test acc: 77.4795\n",
      "Train loss: 0.0005 | Test loss: 0.7193 | Test acc: 74.3689\n",
      "Train loss: 0.0004 | Test loss: 0.6648 | Test acc: 78.1330\n",
      "Train loss: 0.0005 | Test loss: 0.6492 | Test acc: 77.0368\n",
      "Train loss: 0.0004 | Test loss: 0.6494 | Test acc: 77.0333\n",
      "Train loss: 0.0004 | Test loss: 0.6253 | Test acc: 77.8719\n",
      "Train loss: 0.0002 | Test loss: 0.6325 | Test acc: 77.2256\n",
      "Train loss: 0.0003 | Test loss: 0.6742 | Test acc: 75.6062\n",
      "Train loss: 0.0004 | Test loss: 0.6503 | Test acc: 76.4995\n",
      "Train loss: 0.0003 | Test loss: 0.6476 | Test acc: 75.9932\n",
      "Train loss: 0.0002 | Test loss: 0.6169 | Test acc: 78.4976\n",
      "Train loss: 0.0003 | Test loss: 0.6658 | Test acc: 76.0495\n",
      "Train loss: 0.0004 | Test loss: 0.6425 | Test acc: 78.1883\n",
      "Train loss: 0.0004 | Test loss: 0.6251 | Test acc: 77.8756\n",
      "Train loss: 0.0003 | Test loss: 0.6272 | Test acc: 78.4237\n",
      "Train loss: 0.0003 | Test loss: 0.6104 | Test acc: 79.0545\n",
      "Train loss: 0.0003 | Test loss: 0.6813 | Test acc: 76.3408\n",
      "Train loss: 0.0003 | Test loss: 0.6886 | Test acc: 75.0842\n",
      "Train loss: 0.0005 | Test loss: 0.7525 | Test acc: 71.7754\n",
      "Train loss: 0.0004 | Test loss: 0.7752 | Test acc: 70.5268\n",
      "Train loss: 0.0005 | Test loss: 0.6315 | Test acc: 77.3719\n",
      "Train loss: 0.0003 | Test loss: 0.6431 | Test acc: 76.6749\n",
      "Train loss: 0.0004 | Test loss: 0.6589 | Test acc: 76.3332\n",
      "Train loss: 0.0004 | Test loss: 0.7944 | Test acc: 70.5514\n",
      "Train loss: 0.0003 | Test loss: 0.6210 | Test acc: 78.3304\n",
      "Train loss: 0.0003 | Test loss: 0.6447 | Test acc: 76.0789\n",
      "Train loss: 0.0003 | Test loss: 0.6133 | Test acc: 78.6876\n",
      "Train loss: 0.0004 | Test loss: 0.7028 | Test acc: 75.0018\n",
      "Train loss: 0.0003 | Test loss: 0.6721 | Test acc: 76.0982\n",
      "Train loss: 0.0003 | Test loss: 0.6324 | Test acc: 77.8290\n",
      "Train loss: 0.0003 | Test loss: 0.6381 | Test acc: 77.0757\n",
      "Train loss: 0.0003 | Test loss: 0.5905 | Test acc: 79.7191\n",
      "Train loss: 0.0005 | Test loss: 0.6171 | Test acc: 78.1501\n",
      "Train loss: 0.0004 | Test loss: 0.6241 | Test acc: 77.8455\n",
      "Train loss: 0.0004 | Test loss: 0.6503 | Test acc: 75.0890\n",
      "Train loss: 0.0004 | Test loss: 0.7347 | Test acc: 73.9919\n",
      "Train loss: 0.0004 | Test loss: 0.6564 | Test acc: 76.8838\n",
      "Train loss: 0.0003 | Test loss: 0.6298 | Test acc: 78.4106\n",
      "Train loss: 0.0004 | Test loss: 0.6359 | Test acc: 78.8448\n",
      "Train loss: 0.0002 | Test loss: 0.6250 | Test acc: 79.2655\n",
      "Train loss: 0.0003 | Test loss: 0.6111 | Test acc: 78.9174\n",
      "Train loss: 0.0002 | Test loss: 0.6042 | Test acc: 79.0161\n",
      "Train loss: 0.0003 | Test loss: 0.6006 | Test acc: 79.7253\n",
      "Train loss: 0.0003 | Test loss: 0.6219 | Test acc: 77.7807\n",
      "Train loss: 0.0004 | Test loss: 0.7090 | Test acc: 72.8224\n",
      "Train loss: 0.0005 | Test loss: 0.6289 | Test acc: 78.1081\n",
      "Train loss: 0.0004 | Test loss: 0.9395 | Test acc: 65.3154\n",
      "Train loss: 0.0005 | Test loss: 0.6601 | Test acc: 76.1472\n",
      "Train loss: 0.0002 | Test loss: 0.6400 | Test acc: 77.0204\n",
      "Train loss: 0.0005 | Test loss: 0.6488 | Test acc: 76.7537\n",
      "Train loss: 0.0004 | Test loss: 0.7626 | Test acc: 70.9820\n",
      "Train loss: 0.0004 | Test loss: 0.6477 | Test acc: 78.2619\n",
      "Train loss: 0.0003 | Test loss: 0.5942 | Test acc: 80.0424\n",
      "Train loss: 0.0002 | Test loss: 0.6470 | Test acc: 78.4107\n",
      "Train loss: 0.0003 | Test loss: 0.6463 | Test acc: 76.7182\n",
      "Train loss: 0.0003 | Test loss: 0.6266 | Test acc: 77.8310\n",
      "Train loss: 0.0003 | Test loss: 0.6393 | Test acc: 77.6448\n",
      "Train loss: 0.0003 | Test loss: 0.6045 | Test acc: 78.9521\n",
      "Train loss: 0.0002 | Test loss: 0.6678 | Test acc: 76.2906\n",
      "Train loss: 0.0003 | Test loss: 0.5988 | Test acc: 79.7965\n",
      "Train loss: 0.0003 | Test loss: 0.6077 | Test acc: 79.1188\n",
      "Train loss: 0.0003 | Test loss: 0.6676 | Test acc: 76.4309\n",
      "Train loss: 0.0003 | Test loss: 0.6103 | Test acc: 79.1180\n",
      "Train loss: 0.0003 | Test loss: 0.6323 | Test acc: 78.6374\n",
      "Train loss: 0.0003 | Test loss: 0.6425 | Test acc: 77.9569\n",
      "Train loss: 0.0004 | Test loss: 0.6015 | Test acc: 78.8832\n",
      "Train loss: 0.0004 | Test loss: 0.6860 | Test acc: 76.1905\n",
      "Train loss: 0.0004 | Test loss: 0.5969 | Test acc: 79.6564\n",
      "Train loss: 0.0004 | Test loss: 0.6423 | Test acc: 77.4210\n",
      "Train loss: 0.0003 | Test loss: 0.6470 | Test acc: 77.9131\n",
      "Train loss: 0.0004 | Test loss: 0.6315 | Test acc: 78.8232\n",
      "Train loss: 0.0004 | Test loss: 0.6472 | Test acc: 77.9775\n",
      "Train loss: 0.0003 | Test loss: 0.7268 | Test acc: 74.8697\n",
      "Train loss: 0.0004 | Test loss: 0.7425 | Test acc: 73.2723\n",
      "Train loss: 0.0004 | Test loss: 0.6469 | Test acc: 77.9198\n",
      "Train loss: 0.0003 | Test loss: 0.6242 | Test acc: 78.3240\n",
      "Train loss: 0.0003 | Test loss: 0.6799 | Test acc: 74.5813\n",
      "Train loss: 0.0004 | Test loss: 0.6717 | Test acc: 75.3281\n",
      "Train loss: 0.0003 | Test loss: 0.6141 | Test acc: 78.5853\n",
      "Train loss: 0.0003 | Test loss: 0.6210 | Test acc: 77.6373\n",
      "Train loss: 0.0004 | Test loss: 0.7053 | Test acc: 74.7888\n",
      "Train loss: 0.0004 | Test loss: 0.6407 | Test acc: 76.6267\n",
      "Train loss: 0.0003 | Test loss: 0.6086 | Test acc: 78.2001\n",
      "Train loss: 0.0002 | Test loss: 0.6044 | Test acc: 79.6129\n",
      "Train loss: 0.0003 | Test loss: 0.6400 | Test acc: 77.7004\n",
      "Train loss: 0.0002 | Test loss: 0.6194 | Test acc: 77.8341\n",
      "Train loss: 0.0003 | Test loss: 0.6209 | Test acc: 78.9428\n",
      "Train loss: 0.0003 | Test loss: 0.6456 | Test acc: 77.5186\n",
      "Train loss: 0.0002 | Test loss: 0.6512 | Test acc: 76.9749\n",
      "Train loss: 0.0002 | Test loss: 0.6286 | Test acc: 78.5506\n",
      "Train loss: 0.0001 | Test loss: 0.6764 | Test acc: 76.6088\n",
      "Train loss: 0.0004 | Test loss: 0.5886 | Test acc: 79.5479\n",
      "Train loss: 0.0003 | Test loss: 0.6112 | Test acc: 78.6088\n",
      "Train loss: 0.0003 | Test loss: 0.6505 | Test acc: 75.7903\n",
      "Train loss: 0.0004 | Test loss: 0.5888 | Test acc: 79.3456\n",
      "Train loss: 0.0002 | Test loss: 0.6029 | Test acc: 79.0574\n",
      "Train loss: 0.0004 | Test loss: 0.6434 | Test acc: 76.6204\n",
      "Train loss: 0.0003 | Test loss: 0.7322 | Test acc: 71.8103\n",
      "Train loss: 0.0003 | Test loss: 0.5950 | Test acc: 78.9435\n",
      "Train loss: 0.0002 | Test loss: 0.5905 | Test acc: 79.3756\n",
      "Train loss: 0.0003 | Test loss: 0.5966 | Test acc: 79.1474\n",
      "Train loss: 0.0003 | Test loss: 0.6592 | Test acc: 76.1814\n",
      "Looked at 12800 / 60000 samples\n",
      "Train loss: 0.0003 | Test loss: 0.7195 | Test acc: 71.5094\n",
      "Train loss: 0.0003 | Test loss: 0.6226 | Test acc: 77.7544\n",
      "Train loss: 0.0003 | Test loss: 0.6165 | Test acc: 79.1721\n",
      "Train loss: 0.0004 | Test loss: 0.6205 | Test acc: 77.9386\n",
      "Train loss: 0.0003 | Test loss: 0.6917 | Test acc: 74.5501\n",
      "Train loss: 0.0002 | Test loss: 0.6059 | Test acc: 78.7326\n",
      "Train loss: 0.0004 | Test loss: 0.6042 | Test acc: 78.8558\n",
      "Train loss: 0.0002 | Test loss: 0.6119 | Test acc: 78.2971\n",
      "Train loss: 0.0004 | Test loss: 0.6730 | Test acc: 75.5497\n",
      "Train loss: 0.0004 | Test loss: 0.6229 | Test acc: 77.7174\n",
      "Train loss: 0.0005 | Test loss: 0.5901 | Test acc: 78.9923\n",
      "Train loss: 0.0003 | Test loss: 0.5737 | Test acc: 80.2244\n",
      "Train loss: 0.0002 | Test loss: 0.5883 | Test acc: 79.2899\n",
      "Train loss: 0.0003 | Test loss: 0.5994 | Test acc: 78.8076\n",
      "Train loss: 0.0004 | Test loss: 0.6055 | Test acc: 78.7861\n",
      "Train loss: 0.0002 | Test loss: 0.6018 | Test acc: 78.4965\n",
      "Train loss: 0.0003 | Test loss: 0.6072 | Test acc: 79.1446\n",
      "Train loss: 0.0004 | Test loss: 0.5960 | Test acc: 78.9969\n",
      "Train loss: 0.0002 | Test loss: 0.5903 | Test acc: 79.5156\n",
      "Train loss: 0.0003 | Test loss: 0.7156 | Test acc: 74.9545\n",
      "Train loss: 0.0004 | Test loss: 0.6097 | Test acc: 78.7339\n",
      "Train loss: 0.0003 | Test loss: 0.6662 | Test acc: 76.0802\n",
      "Train loss: 0.0002 | Test loss: 0.6000 | Test acc: 79.0370\n",
      "Train loss: 0.0003 | Test loss: 0.5917 | Test acc: 79.3360\n",
      "Train loss: 0.0003 | Test loss: 0.6530 | Test acc: 76.5514\n",
      "Train loss: 0.0003 | Test loss: 0.7314 | Test acc: 71.5405\n",
      "Train loss: 0.0003 | Test loss: 0.6188 | Test acc: 77.9941\n",
      "Train loss: 0.0004 | Test loss: 0.6228 | Test acc: 78.2144\n",
      "Train loss: 0.0002 | Test loss: 0.5890 | Test acc: 79.0538\n",
      "Train loss: 0.0003 | Test loss: 0.6090 | Test acc: 79.8852\n",
      "Train loss: 0.0003 | Test loss: 0.5989 | Test acc: 79.5683\n",
      "Train loss: 0.0005 | Test loss: 0.5997 | Test acc: 79.0781\n",
      "Train loss: 0.0002 | Test loss: 0.7674 | Test acc: 73.0062\n",
      "Train loss: 0.0004 | Test loss: 0.5979 | Test acc: 79.1070\n",
      "Train loss: 0.0002 | Test loss: 0.6091 | Test acc: 78.0383\n",
      "Train loss: 0.0003 | Test loss: 0.5742 | Test acc: 80.1515\n",
      "Train loss: 0.0003 | Test loss: 0.6150 | Test acc: 77.4625\n",
      "Train loss: 0.0003 | Test loss: 0.5788 | Test acc: 79.1912\n",
      "Train loss: 0.0005 | Test loss: 0.6199 | Test acc: 78.3680\n",
      "Train loss: 0.0003 | Test loss: 0.5909 | Test acc: 79.8630\n",
      "Train loss: 0.0003 | Test loss: 0.6109 | Test acc: 77.7312\n",
      "Train loss: 0.0003 | Test loss: 0.6456 | Test acc: 78.1936\n",
      "Train loss: 0.0003 | Test loss: 0.6170 | Test acc: 78.3449\n",
      "Train loss: 0.0002 | Test loss: 0.6167 | Test acc: 78.5251\n",
      "Train loss: 0.0003 | Test loss: 0.6666 | Test acc: 76.1694\n",
      "Train loss: 0.0003 | Test loss: 0.6647 | Test acc: 75.8624\n",
      "Train loss: 0.0004 | Test loss: 0.6149 | Test acc: 79.3258\n",
      "Train loss: 0.0004 | Test loss: 0.6387 | Test acc: 77.5298\n",
      "Train loss: 0.0004 | Test loss: 0.5802 | Test acc: 80.1798\n",
      "Train loss: 0.0002 | Test loss: 0.5998 | Test acc: 79.3197\n",
      "Train loss: 0.0003 | Test loss: 0.6083 | Test acc: 79.0673\n",
      "Train loss: 0.0003 | Test loss: 0.5716 | Test acc: 80.1348\n",
      "Train loss: 0.0003 | Test loss: 0.5833 | Test acc: 79.2396\n",
      "Train loss: 0.0003 | Test loss: 0.6021 | Test acc: 77.9289\n",
      "Train loss: 0.0002 | Test loss: 0.6952 | Test acc: 75.5385\n",
      "Train loss: 0.0005 | Test loss: 0.6396 | Test acc: 75.2214\n",
      "Train loss: 0.0003 | Test loss: 0.5926 | Test acc: 78.7946\n",
      "Train loss: 0.0004 | Test loss: 0.5791 | Test acc: 80.2438\n",
      "Train loss: 0.0006 | Test loss: 0.6322 | Test acc: 76.8638\n",
      "Train loss: 0.0003 | Test loss: 0.6239 | Test acc: 77.1126\n",
      "Train loss: 0.0003 | Test loss: 0.5747 | Test acc: 79.9488\n",
      "Train loss: 0.0003 | Test loss: 0.6132 | Test acc: 77.4120\n",
      "Train loss: 0.0002 | Test loss: 0.5733 | Test acc: 79.6702\n",
      "Train loss: 0.0003 | Test loss: 0.6070 | Test acc: 78.0101\n",
      "Train loss: 0.0003 | Test loss: 0.5757 | Test acc: 80.0116\n",
      "Train loss: 0.0003 | Test loss: 0.5784 | Test acc: 79.8483\n",
      "Train loss: 0.0003 | Test loss: 0.5929 | Test acc: 78.6397\n",
      "Train loss: 0.0002 | Test loss: 0.5993 | Test acc: 78.5659\n",
      "Train loss: 0.0003 | Test loss: 0.5600 | Test acc: 80.4427\n",
      "Train loss: 0.0002 | Test loss: 0.5936 | Test acc: 79.1208\n",
      "Train loss: 0.0003 | Test loss: 0.6061 | Test acc: 77.6989\n",
      "Train loss: 0.0004 | Test loss: 0.5931 | Test acc: 79.6013\n",
      "Train loss: 0.0003 | Test loss: 0.5955 | Test acc: 78.6988\n",
      "Train loss: 0.0004 | Test loss: 0.5894 | Test acc: 79.6943\n",
      "Train loss: 0.0004 | Test loss: 0.6833 | Test acc: 72.4491\n",
      "Train loss: 0.0005 | Test loss: 0.5666 | Test acc: 80.1536\n",
      "Train loss: 0.0003 | Test loss: 0.5994 | Test acc: 79.0201\n",
      "Train loss: 0.0003 | Test loss: 0.6328 | Test acc: 76.5304\n",
      "Train loss: 0.0004 | Test loss: 0.5918 | Test acc: 79.2181\n",
      "Train loss: 0.0002 | Test loss: 0.5773 | Test acc: 79.9656\n",
      "Train loss: 0.0001 | Test loss: 0.5925 | Test acc: 79.2591\n",
      "Train loss: 0.0003 | Test loss: 0.5976 | Test acc: 78.8075\n",
      "Train loss: 0.0002 | Test loss: 0.5933 | Test acc: 79.2154\n",
      "Train loss: 0.0004 | Test loss: 0.6025 | Test acc: 78.1185\n",
      "Train loss: 0.0003 | Test loss: 0.6300 | Test acc: 78.9537\n",
      "Train loss: 0.0002 | Test loss: 0.6147 | Test acc: 79.3257\n",
      "Train loss: 0.0003 | Test loss: 0.6379 | Test acc: 78.2387\n",
      "Train loss: 0.0004 | Test loss: 0.7513 | Test acc: 71.7456\n",
      "Train loss: 0.0004 | Test loss: 0.7149 | Test acc: 75.2592\n",
      "Train loss: 0.0003 | Test loss: 0.6180 | Test acc: 78.4253\n",
      "Train loss: 0.0003 | Test loss: 0.6333 | Test acc: 76.9379\n",
      "Train loss: 0.0005 | Test loss: 0.6133 | Test acc: 78.2011\n",
      "Train loss: 0.0004 | Test loss: 0.6075 | Test acc: 79.1236\n",
      "Train loss: 0.0004 | Test loss: 0.6291 | Test acc: 77.5092\n",
      "Train loss: 0.0003 | Test loss: 0.6254 | Test acc: 78.4725\n",
      "Train loss: 0.0005 | Test loss: 0.6179 | Test acc: 78.3957\n",
      "Train loss: 0.0005 | Test loss: 0.6508 | Test acc: 76.5184\n",
      "Train loss: 0.0003 | Test loss: 0.6766 | Test acc: 73.3874\n",
      "Train loss: 0.0004 | Test loss: 0.5758 | Test acc: 79.5176\n",
      "Train loss: 0.0003 | Test loss: 0.6008 | Test acc: 78.5188\n",
      "Train loss: 0.0003 | Test loss: 0.5791 | Test acc: 79.6638\n",
      "Train loss: 0.0004 | Test loss: 0.5946 | Test acc: 79.1982\n",
      "Train loss: 0.0003 | Test loss: 0.5657 | Test acc: 79.8956\n",
      "Train loss: 0.0003 | Test loss: 0.5824 | Test acc: 79.5883\n",
      "Train loss: 0.0003 | Test loss: 0.6087 | Test acc: 78.6488\n",
      "Train loss: 0.0002 | Test loss: 0.6062 | Test acc: 78.2565\n",
      "Train loss: 0.0002 | Test loss: 0.5820 | Test acc: 79.4134\n",
      "Train loss: 0.0004 | Test loss: 0.5866 | Test acc: 79.2773\n",
      "Train loss: 0.0003 | Test loss: 0.5782 | Test acc: 79.5065\n",
      "Train loss: 0.0004 | Test loss: 0.5672 | Test acc: 80.2560\n",
      "Train loss: 0.0002 | Test loss: 0.6037 | Test acc: 78.6011\n",
      "Train loss: 0.0004 | Test loss: 0.5685 | Test acc: 79.9935\n",
      "Train loss: 0.0002 | Test loss: 0.5642 | Test acc: 80.0479\n",
      "Train loss: 0.0003 | Test loss: 0.5971 | Test acc: 78.8700\n",
      "Train loss: 0.0003 | Test loss: 0.5942 | Test acc: 78.7664\n",
      "Train loss: 0.0003 | Test loss: 0.5701 | Test acc: 79.9841\n",
      "Train loss: 0.0003 | Test loss: 0.6118 | Test acc: 77.4520\n",
      "Train loss: 0.0002 | Test loss: 0.5581 | Test acc: 81.0582\n",
      "Train loss: 0.0003 | Test loss: 0.6163 | Test acc: 79.6819\n",
      "Train loss: 0.0003 | Test loss: 0.6946 | Test acc: 75.3844\n",
      "Train loss: 0.0006 | Test loss: 0.7298 | Test acc: 73.9230\n",
      "Train loss: 0.0003 | Test loss: 0.6087 | Test acc: 78.5409\n",
      "Train loss: 0.0003 | Test loss: 0.5946 | Test acc: 79.5141\n",
      "Train loss: 0.0004 | Test loss: 0.5915 | Test acc: 79.3375\n",
      "Train loss: 0.0005 | Test loss: 0.6156 | Test acc: 78.5582\n",
      "Train loss: 0.0003 | Test loss: 0.6227 | Test acc: 78.9551\n",
      "Train loss: 0.0006 | Test loss: 0.6186 | Test acc: 79.5953\n",
      "Train loss: 0.0004 | Test loss: 0.5978 | Test acc: 79.2579\n",
      "Train loss: 0.0003 | Test loss: 0.6709 | Test acc: 75.9321\n",
      "Train loss: 0.0003 | Test loss: 0.5879 | Test acc: 79.4359\n",
      "Train loss: 0.0003 | Test loss: 0.6193 | Test acc: 79.1675\n",
      "Train loss: 0.0003 | Test loss: 0.5741 | Test acc: 79.8955\n",
      "Train loss: 0.0003 | Test loss: 0.5534 | Test acc: 80.6366\n",
      "Train loss: 0.0004 | Test loss: 0.6036 | Test acc: 78.3127\n",
      "Train loss: 0.0006 | Test loss: 0.6899 | Test acc: 77.4966\n",
      "Train loss: 0.0004 | Test loss: 0.5820 | Test acc: 79.6705\n",
      "Train loss: 0.0002 | Test loss: 0.6023 | Test acc: 78.6990\n",
      "Train loss: 0.0006 | Test loss: 0.5925 | Test acc: 78.5761\n",
      "Train loss: 0.0003 | Test loss: 0.6097 | Test acc: 79.7638\n",
      "Train loss: 0.0002 | Test loss: 0.6050 | Test acc: 79.5480\n",
      "Train loss: 0.0003 | Test loss: 0.6014 | Test acc: 79.1479\n",
      "Train loss: 0.0005 | Test loss: 0.6282 | Test acc: 75.9817\n",
      "Train loss: 0.0003 | Test loss: 0.5683 | Test acc: 80.3646\n",
      "Train loss: 0.0002 | Test loss: 0.5754 | Test acc: 79.8095\n",
      "Train loss: 0.0003 | Test loss: 0.5791 | Test acc: 79.6180\n",
      "Train loss: 0.0002 | Test loss: 0.5827 | Test acc: 79.6873\n",
      "Train loss: 0.0004 | Test loss: 0.5571 | Test acc: 80.7857\n",
      "Train loss: 0.0003 | Test loss: 0.5666 | Test acc: 80.6894\n",
      "Train loss: 0.0003 | Test loss: 0.6067 | Test acc: 78.5326\n",
      "Train loss: 0.0003 | Test loss: 0.6373 | Test acc: 76.5189\n",
      "Train loss: 0.0003 | Test loss: 0.5776 | Test acc: 79.1482\n",
      "Train loss: 0.0002 | Test loss: 0.6277 | Test acc: 76.7704\n",
      "Train loss: 0.0002 | Test loss: 0.5688 | Test acc: 79.8878\n",
      "Train loss: 0.0002 | Test loss: 0.5625 | Test acc: 80.2373\n",
      "Train loss: 0.0004 | Test loss: 0.6770 | Test acc: 74.9968\n",
      "Train loss: 0.0004 | Test loss: 0.6308 | Test acc: 77.2164\n",
      "Train loss: 0.0002 | Test loss: 0.6048 | Test acc: 79.2203\n",
      "Train loss: 0.0003 | Test loss: 0.6386 | Test acc: 78.2383\n",
      "Train loss: 0.0003 | Test loss: 0.5621 | Test acc: 80.4916\n",
      "Train loss: 0.0002 | Test loss: 0.5618 | Test acc: 80.2991\n",
      "Train loss: 0.0003 | Test loss: 0.6278 | Test acc: 78.7609\n",
      "Train loss: 0.0003 | Test loss: 0.5794 | Test acc: 79.9541\n",
      "Train loss: 0.0003 | Test loss: 0.5527 | Test acc: 80.7367\n",
      "Train loss: 0.0002 | Test loss: 0.6247 | Test acc: 77.4744\n",
      "Train loss: 0.0003 | Test loss: 0.6014 | Test acc: 78.3326\n",
      "Train loss: 0.0003 | Test loss: 0.6131 | Test acc: 77.8860\n",
      "Train loss: 0.0004 | Test loss: 0.6233 | Test acc: 78.3139\n",
      "Train loss: 0.0004 | Test loss: 0.5675 | Test acc: 80.1623\n",
      "Train loss: 0.0003 | Test loss: 0.5935 | Test acc: 79.6790\n",
      "Train loss: 0.0004 | Test loss: 0.5810 | Test acc: 79.6675\n",
      "Train loss: 0.0003 | Test loss: 0.5838 | Test acc: 79.3679\n",
      "Train loss: 0.0006 | Test loss: 0.5576 | Test acc: 81.0144\n",
      "Train loss: 0.0002 | Test loss: 0.6090 | Test acc: 78.8431\n",
      "Train loss: 0.0004 | Test loss: 0.5909 | Test acc: 79.3753\n",
      "Train loss: 0.0003 | Test loss: 0.6892 | Test acc: 75.6230\n",
      "Train loss: 0.0002 | Test loss: 0.5971 | Test acc: 78.9856\n",
      "Train loss: 0.0004 | Test loss: 0.5663 | Test acc: 79.9648\n",
      "Train loss: 0.0001 | Test loss: 0.5519 | Test acc: 80.7167\n",
      "Train loss: 0.0002 | Test loss: 0.5490 | Test acc: 81.2882\n",
      "Train loss: 0.0004 | Test loss: 0.6197 | Test acc: 78.6742\n",
      "Train loss: 0.0002 | Test loss: 0.5808 | Test acc: 79.7941\n",
      "Train loss: 0.0004 | Test loss: 0.5839 | Test acc: 80.1371\n",
      "Train loss: 0.0003 | Test loss: 0.5559 | Test acc: 80.2480\n",
      "Train loss: 0.0005 | Test loss: 0.5697 | Test acc: 79.6993\n",
      "Train loss: 0.0002 | Test loss: 0.5595 | Test acc: 80.2666\n",
      "Train loss: 0.0004 | Test loss: 0.5879 | Test acc: 78.7608\n",
      "Train loss: 0.0002 | Test loss: 0.5747 | Test acc: 79.6047\n",
      "Train loss: 0.0003 | Test loss: 0.5654 | Test acc: 79.8869\n",
      "Train loss: 0.0003 | Test loss: 0.6012 | Test acc: 78.5899\n",
      "Train loss: 0.0008 | Test loss: 0.5660 | Test acc: 80.4328\n",
      "Train loss: 0.0003 | Test loss: 0.5972 | Test acc: 78.2522\n",
      "Train loss: 0.0004 | Test loss: 0.5928 | Test acc: 78.4449\n",
      "Train loss: 0.0004 | Test loss: 0.5849 | Test acc: 79.7834\n",
      "Train loss: 0.0002 | Test loss: 0.6156 | Test acc: 77.9606\n",
      "Train loss: 0.0002 | Test loss: 0.5641 | Test acc: 80.8401\n",
      "Train loss: 0.0003 | Test loss: 0.6090 | Test acc: 78.8725\n",
      "Train loss: 0.0003 | Test loss: 0.5887 | Test acc: 79.0659\n",
      "Train loss: 0.0003 | Test loss: 0.5970 | Test acc: 78.3876\n",
      "Train loss: 0.0003 | Test loss: 0.5847 | Test acc: 78.9645\n",
      "Train loss: 0.0003 | Test loss: 0.7455 | Test acc: 73.4651\n",
      "Train loss: 0.0003 | Test loss: 0.5809 | Test acc: 79.4779\n",
      "Train loss: 0.0002 | Test loss: 0.5699 | Test acc: 80.1561\n",
      "Train loss: 0.0002 | Test loss: 0.5596 | Test acc: 80.5676\n",
      "Train loss: 0.0002 | Test loss: 0.5530 | Test acc: 80.7586\n",
      "Train loss: 0.0002 | Test loss: 0.5889 | Test acc: 78.8722\n",
      "Train loss: 0.0002 | Test loss: 0.6424 | Test acc: 78.3870\n",
      "Train loss: 0.0002 | Test loss: 0.6054 | Test acc: 78.3455\n",
      "Train loss: 0.0004 | Test loss: 0.5699 | Test acc: 80.6317\n",
      "Train loss: 0.0003 | Test loss: 0.5630 | Test acc: 80.6690\n",
      "Train loss: 0.0003 | Test loss: 0.5455 | Test acc: 81.1583\n",
      "Train loss: 0.0004 | Test loss: 0.6241 | Test acc: 77.4558\n",
      "Train loss: 0.0002 | Test loss: 0.6897 | Test acc: 73.5302\n",
      "Train loss: 0.0003 | Test loss: 0.5679 | Test acc: 79.5880\n",
      "Train loss: 0.0006 | Test loss: 0.6045 | Test acc: 79.1281\n",
      "Train loss: 0.0002 | Test loss: 0.6408 | Test acc: 75.9118\n",
      "Train loss: 0.0003 | Test loss: 0.5781 | Test acc: 80.3344\n",
      "Train loss: 0.0003 | Test loss: 0.6371 | Test acc: 77.2235\n",
      "Train loss: 0.0002 | Test loss: 0.5994 | Test acc: 78.6313\n",
      "Train loss: 0.0003 | Test loss: 0.5949 | Test acc: 79.4345\n",
      "Train loss: 0.0005 | Test loss: 0.5527 | Test acc: 81.0645\n",
      "Train loss: 0.0002 | Test loss: 0.5585 | Test acc: 80.7203\n",
      "Train loss: 0.0002 | Test loss: 0.5719 | Test acc: 80.6293\n",
      "Train loss: 0.0002 | Test loss: 0.6646 | Test acc: 75.9565\n",
      "Train loss: 0.0002 | Test loss: 0.6144 | Test acc: 77.5290\n",
      "Train loss: 0.0003 | Test loss: 0.6094 | Test acc: 77.3543\n",
      "Train loss: 0.0003 | Test loss: 0.5899 | Test acc: 79.6800\n",
      "Train loss: 0.0002 | Test loss: 0.5722 | Test acc: 80.4063\n",
      "Train loss: 0.0003 | Test loss: 0.5919 | Test acc: 79.6898\n",
      "Train loss: 0.0003 | Test loss: 0.6539 | Test acc: 77.0517\n",
      "Train loss: 0.0005 | Test loss: 0.9546 | Test acc: 68.7466\n",
      "Train loss: 0.0004 | Test loss: 0.5511 | Test acc: 80.7708\n",
      "Train loss: 0.0003 | Test loss: 0.5431 | Test acc: 81.1087\n",
      "Train loss: 0.0002 | Test loss: 0.5694 | Test acc: 79.9816\n",
      "Train loss: 0.0001 | Test loss: 0.5618 | Test acc: 80.4572\n",
      "Train loss: 0.0002 | Test loss: 0.5492 | Test acc: 81.1975\n",
      "Train loss: 0.0002 | Test loss: 0.5995 | Test acc: 77.9252\n",
      "Train loss: 0.0002 | Test loss: 0.5932 | Test acc: 78.6335\n",
      "Train loss: 0.0003 | Test loss: 0.5718 | Test acc: 80.0236\n",
      "Train loss: 0.0003 | Test loss: 0.6134 | Test acc: 77.1027\n",
      "Train loss: 0.0004 | Test loss: 0.6214 | Test acc: 76.8238\n",
      "Train loss: 0.0004 | Test loss: 0.5895 | Test acc: 79.6983\n",
      "Train loss: 0.0002 | Test loss: 0.5629 | Test acc: 80.7858\n",
      "Train loss: 0.0004 | Test loss: 0.6217 | Test acc: 77.0652\n",
      "Train loss: 0.0003 | Test loss: 0.5557 | Test acc: 80.5877\n",
      "Train loss: 0.0002 | Test loss: 0.5644 | Test acc: 80.4591\n",
      "Train loss: 0.0003 | Test loss: 0.5954 | Test acc: 79.1908\n",
      "Train loss: 0.0003 | Test loss: 0.5778 | Test acc: 79.9155\n",
      "Train loss: 0.0002 | Test loss: 0.5780 | Test acc: 79.9179\n",
      "Train loss: 0.0003 | Test loss: 0.5510 | Test acc: 80.8564\n",
      "Train loss: 0.0002 | Test loss: 0.5601 | Test acc: 80.1505\n",
      "Train loss: 0.0002 | Test loss: 0.5837 | Test acc: 79.5292\n",
      "Train loss: 0.0003 | Test loss: 0.5953 | Test acc: 79.6471\n",
      "Train loss: 0.0004 | Test loss: 0.5928 | Test acc: 79.3379\n",
      "Train loss: 0.0003 | Test loss: 0.5924 | Test acc: 79.0075\n",
      "Train loss: 0.0002 | Test loss: 0.6390 | Test acc: 76.9497\n",
      "Train loss: 0.0003 | Test loss: 0.5730 | Test acc: 79.8784\n",
      "Train loss: 0.0002 | Test loss: 0.5623 | Test acc: 80.7364\n",
      "Train loss: 0.0002 | Test loss: 0.5674 | Test acc: 79.9604\n",
      "Train loss: 0.0003 | Test loss: 0.5551 | Test acc: 80.8266\n",
      "Train loss: 0.0004 | Test loss: 0.6459 | Test acc: 76.9855\n",
      "Train loss: 0.0004 | Test loss: 0.6236 | Test acc: 79.1697\n",
      "Train loss: 0.0003 | Test loss: 0.5810 | Test acc: 79.2765\n",
      "Train loss: 0.0003 | Test loss: 0.5627 | Test acc: 80.5648\n",
      "Train loss: 0.0004 | Test loss: 0.6171 | Test acc: 78.2726\n",
      "Train loss: 0.0005 | Test loss: 0.5645 | Test acc: 80.5216\n",
      "Train loss: 0.0004 | Test loss: 0.5811 | Test acc: 80.2293\n",
      "Train loss: 0.0003 | Test loss: 0.6138 | Test acc: 77.5427\n",
      "Train loss: 0.0004 | Test loss: 0.5955 | Test acc: 78.2429\n",
      "Train loss: 0.0005 | Test loss: 0.5847 | Test acc: 79.8526\n",
      "Train loss: 0.0002 | Test loss: 0.5966 | Test acc: 79.7679\n",
      "Train loss: 0.0003 | Test loss: 0.5759 | Test acc: 80.0771\n",
      "Train loss: 0.0004 | Test loss: 0.5995 | Test acc: 79.0298\n",
      "Train loss: 0.0002 | Test loss: 0.5625 | Test acc: 80.0149\n",
      "Train loss: 0.0003 | Test loss: 0.5897 | Test acc: 80.1778\n",
      "Train loss: 0.0003 | Test loss: 0.5897 | Test acc: 79.6991\n",
      "Train loss: 0.0004 | Test loss: 0.6998 | Test acc: 75.8637\n",
      "Train loss: 0.0002 | Test loss: 0.6119 | Test acc: 78.8366\n",
      "Train loss: 0.0003 | Test loss: 0.5628 | Test acc: 80.6432\n",
      "Train loss: 0.0002 | Test loss: 0.5559 | Test acc: 80.5891\n",
      "Train loss: 0.0004 | Test loss: 0.5817 | Test acc: 78.7419\n",
      "Train loss: 0.0004 | Test loss: 0.6227 | Test acc: 77.4980\n",
      "Train loss: 0.0003 | Test loss: 0.5700 | Test acc: 80.5291\n",
      "Train loss: 0.0004 | Test loss: 0.7459 | Test acc: 70.2553\n",
      "Train loss: 0.0005 | Test loss: 0.7289 | Test acc: 77.5807\n",
      "Train loss: 0.0004 | Test loss: 0.6256 | Test acc: 78.9719\n",
      "Train loss: 0.0004 | Test loss: 0.5743 | Test acc: 79.8450\n",
      "Train loss: 0.0003 | Test loss: 0.5475 | Test acc: 81.0958\n",
      "Train loss: 0.0002 | Test loss: 0.5494 | Test acc: 80.5406\n",
      "Train loss: 0.0003 | Test loss: 0.5747 | Test acc: 80.3891\n",
      "Train loss: 0.0002 | Test loss: 0.5431 | Test acc: 81.2572\n",
      "Train loss: 0.0002 | Test loss: 0.5777 | Test acc: 79.7824\n",
      "Train loss: 0.0001 | Test loss: 0.5677 | Test acc: 80.1870\n",
      "Train loss: 0.0003 | Test loss: 0.5922 | Test acc: 78.0817\n",
      "Train loss: 0.0004 | Test loss: 0.5666 | Test acc: 80.9304\n",
      "Train loss: 0.0002 | Test loss: 0.5617 | Test acc: 80.8696\n",
      "Train loss: 0.0004 | Test loss: 0.5729 | Test acc: 80.2504\n",
      "Train loss: 0.0002 | Test loss: 0.5631 | Test acc: 80.7276\n",
      "Train loss: 0.0003 | Test loss: 0.5764 | Test acc: 79.3913\n",
      "Train loss: 0.0002 | Test loss: 0.6163 | Test acc: 76.6614\n",
      "Train loss: 0.0003 | Test loss: 0.6311 | Test acc: 75.6842\n",
      "Train loss: 0.0003 | Test loss: 0.5459 | Test acc: 80.6631\n",
      "Train loss: 0.0003 | Test loss: 0.5695 | Test acc: 79.6906\n",
      "Train loss: 0.0004 | Test loss: 0.6089 | Test acc: 78.8888\n",
      "Train loss: 0.0003 | Test loss: 0.5607 | Test acc: 80.3938\n",
      "Train loss: 0.0003 | Test loss: 0.5478 | Test acc: 80.7780\n",
      "Train loss: 0.0004 | Test loss: 0.5744 | Test acc: 79.8407\n",
      "Train loss: 0.0003 | Test loss: 0.5491 | Test acc: 80.5766\n",
      "Train loss: 0.0004 | Test loss: 0.6024 | Test acc: 77.7534\n",
      "Train loss: 0.0002 | Test loss: 0.5748 | Test acc: 79.0723\n",
      "Train loss: 0.0004 | Test loss: 0.5909 | Test acc: 79.4559\n",
      "Train loss: 0.0004 | Test loss: 0.5996 | Test acc: 78.9979\n",
      "Train loss: 0.0003 | Test loss: 0.5856 | Test acc: 78.7967\n",
      "Train loss: 0.0003 | Test loss: 0.5392 | Test acc: 81.3220\n",
      "Train loss: 0.0003 | Test loss: 0.5322 | Test acc: 81.7794\n",
      "Train loss: 0.0003 | Test loss: 0.5511 | Test acc: 80.6926\n",
      "Train loss: 0.0002 | Test loss: 0.5581 | Test acc: 80.6592\n",
      "Train loss: 0.0003 | Test loss: 0.5653 | Test acc: 80.3795\n",
      "Train loss: 0.0003 | Test loss: 0.5515 | Test acc: 80.4485\n",
      "Train loss: 0.0004 | Test loss: 0.5783 | Test acc: 79.5801\n",
      "Train loss: 0.0003 | Test loss: 0.5459 | Test acc: 80.9252\n",
      "Train loss: 0.0003 | Test loss: 0.5562 | Test acc: 80.9794\n",
      "Train loss: 0.0002 | Test loss: 0.5692 | Test acc: 80.3007\n",
      "Train loss: 0.0003 | Test loss: 0.6773 | Test acc: 73.5293\n",
      "Train loss: 0.0003 | Test loss: 0.5485 | Test acc: 81.1255\n",
      "Train loss: 0.0001 | Test loss: 0.5704 | Test acc: 80.6206\n",
      "Train loss: 0.0001 | Test loss: 0.5678 | Test acc: 80.3295\n",
      "Train loss: 0.0003 | Test loss: 0.5600 | Test acc: 80.6081\n",
      "Train loss: 0.0005 | Test loss: 0.5650 | Test acc: 80.6589\n",
      "Train loss: 0.0002 | Test loss: 0.5695 | Test acc: 80.7589\n",
      "Train loss: 0.0003 | Test loss: 0.5785 | Test acc: 79.6610\n",
      "Train loss: 0.0002 | Test loss: 0.5484 | Test acc: 81.1551\n",
      "Train loss: 0.0004 | Test loss: 0.5347 | Test acc: 81.5392\n",
      "Train loss: 0.0004 | Test loss: 0.5531 | Test acc: 79.9630\n",
      "Train loss: 0.0003 | Test loss: 0.5436 | Test acc: 80.8465\n",
      "Train loss: 0.0002 | Test loss: 0.6506 | Test acc: 76.9356\n",
      "Train loss: 0.0002 | Test loss: 0.6556 | Test acc: 76.4838\n",
      "Train loss: 0.0004 | Test loss: 0.5651 | Test acc: 79.9968\n",
      "Train loss: 0.0004 | Test loss: 0.5880 | Test acc: 79.9081\n",
      "Train loss: 0.0002 | Test loss: 0.5604 | Test acc: 80.3971\n",
      "Train loss: 0.0003 | Test loss: 0.5569 | Test acc: 80.8479\n",
      "Train loss: 0.0003 | Test loss: 0.5587 | Test acc: 80.7895\n",
      "Train loss: 0.0003 | Test loss: 0.5435 | Test acc: 81.7677\n",
      "Train loss: 0.0004 | Test loss: 0.5510 | Test acc: 80.4030\n",
      "Train loss: 0.0004 | Test loss: 0.5871 | Test acc: 78.6415\n",
      "Train loss: 0.0003 | Test loss: 0.5461 | Test acc: 80.7524\n",
      "Train loss: 0.0002 | Test loss: 0.5273 | Test acc: 81.4381\n",
      "Train loss: 0.0005 | Test loss: 0.5756 | Test acc: 78.4551\n",
      "Train loss: 0.0004 | Test loss: 0.5938 | Test acc: 77.4671\n",
      "Train loss: 0.0003 | Test loss: 0.5695 | Test acc: 80.0698\n",
      "Train loss: 0.0003 | Test loss: 0.5984 | Test acc: 78.2610\n",
      "Train loss: 0.0001 | Test loss: 0.5611 | Test acc: 80.1123\n",
      "Train loss: 0.0004 | Test loss: 0.5943 | Test acc: 78.2212\n",
      "Train loss: 0.0002 | Test loss: 0.5387 | Test acc: 81.4700\n",
      "Train loss: 0.0004 | Test loss: 0.5573 | Test acc: 79.5834\n",
      "Train loss: 0.0002 | Test loss: 0.5455 | Test acc: 81.0051\n",
      "Train loss: 0.0005 | Test loss: 0.5674 | Test acc: 79.7316\n",
      "Train loss: 0.0002 | Test loss: 0.5451 | Test acc: 80.7759\n",
      "Train loss: 0.0004 | Test loss: 0.6099 | Test acc: 77.8140\n",
      "Train loss: 0.0003 | Test loss: 0.5590 | Test acc: 80.5801\n",
      "Train loss: 0.0003 | Test loss: 0.5435 | Test acc: 80.7786\n",
      "Train loss: 0.0003 | Test loss: 0.5572 | Test acc: 80.7493\n",
      "Train loss: 0.0003 | Test loss: 0.5516 | Test acc: 80.8391\n",
      "Train loss: 0.0003 | Test loss: 0.5489 | Test acc: 80.9891\n",
      "Train loss: 0.0004 | Test loss: 0.5826 | Test acc: 77.6250\n",
      "Train loss: 0.0002 | Test loss: 0.5505 | Test acc: 79.7608\n",
      "Train loss: 0.0001 | Test loss: 0.5555 | Test acc: 80.3067\n",
      "Train loss: 0.0003 | Test loss: 0.5611 | Test acc: 79.3900\n",
      "Train loss: 0.0003 | Test loss: 0.5727 | Test acc: 79.3072\n",
      "Train loss: 0.0003 | Test loss: 0.5473 | Test acc: 80.8544\n",
      "Train loss: 0.0002 | Test loss: 0.5304 | Test acc: 81.6980\n",
      "Train loss: 0.0003 | Test loss: 0.6344 | Test acc: 77.0981\n",
      "Train loss: 0.0005 | Test loss: 0.5517 | Test acc: 80.5978\n",
      "Train loss: 0.0003 | Test loss: 0.5449 | Test acc: 80.3993\n",
      "Train loss: 0.0001 | Test loss: 0.5302 | Test acc: 81.5967\n",
      "Train loss: 0.0002 | Test loss: 0.5781 | Test acc: 78.7052\n",
      "Train loss: 0.0003 | Test loss: 0.5781 | Test acc: 79.2850\n",
      "Train loss: 0.0002 | Test loss: 0.5314 | Test acc: 81.4933\n",
      "Train loss: 0.0002 | Test loss: 0.5328 | Test acc: 81.5902\n",
      "Train loss: 0.0004 | Test loss: 0.5997 | Test acc: 78.9747\n",
      "Train loss: 0.0003 | Test loss: 0.5382 | Test acc: 81.3725\n",
      "Train loss: 0.0003 | Test loss: 0.5635 | Test acc: 79.3335\n",
      "Train loss: 0.0004 | Test loss: 0.5571 | Test acc: 80.5350\n",
      "Train loss: 0.0002 | Test loss: 0.5434 | Test acc: 81.3575\n",
      "Train loss: 0.0004 | Test loss: 0.5743 | Test acc: 79.2236\n",
      "Train loss: 0.0001 | Test loss: 0.5512 | Test acc: 80.3450\n",
      "Train loss: 0.0004 | Test loss: 0.5710 | Test acc: 79.0806\n",
      "Train loss: 0.0004 | Test loss: 0.5390 | Test acc: 81.0334\n",
      "Train loss: 0.0003 | Test loss: 0.6060 | Test acc: 79.7916\n",
      "Train loss: 0.0005 | Test loss: 0.5480 | Test acc: 81.3751\n",
      "Train loss: 0.0003 | Test loss: 0.5439 | Test acc: 80.8111\n",
      "Train loss: 0.0003 | Test loss: 0.5509 | Test acc: 80.1104\n",
      "Train loss: 0.0003 | Test loss: 0.5459 | Test acc: 81.3562\n",
      "Train loss: 0.0003 | Test loss: 0.5615 | Test acc: 79.3833\n",
      "Train loss: 0.0004 | Test loss: 0.5605 | Test acc: 80.6350\n",
      "Train loss: 0.0002 | Test loss: 0.5430 | Test acc: 81.3379\n",
      "Train loss: 0.0002 | Test loss: 0.5434 | Test acc: 81.1504\n",
      "Train loss: 0.0002 | Test loss: 0.5389 | Test acc: 81.3595\n",
      "Train loss: 0.0003 | Test loss: 0.5482 | Test acc: 80.4516\n",
      "Train loss: 0.0003 | Test loss: 0.7393 | Test acc: 77.0841\n",
      "Train loss: 0.0006 | Test loss: 0.5741 | Test acc: 80.3781\n",
      "Looked at 25600 / 60000 samples\n",
      "Train loss: 0.0003 | Test loss: 0.5964 | Test acc: 78.1622\n",
      "Train loss: 0.0003 | Test loss: 0.5428 | Test acc: 81.0305\n",
      "Train loss: 0.0003 | Test loss: 0.5680 | Test acc: 80.1610\n",
      "Train loss: 0.0004 | Test loss: 0.6010 | Test acc: 78.9202\n",
      "Train loss: 0.0003 | Test loss: 0.5666 | Test acc: 79.6651\n",
      "Train loss: 0.0003 | Test loss: 0.5569 | Test acc: 79.9570\n",
      "Train loss: 0.0003 | Test loss: 0.5340 | Test acc: 81.7351\n",
      "Train loss: 0.0003 | Test loss: 0.5596 | Test acc: 80.4528\n",
      "Train loss: 0.0008 | Test loss: 0.5384 | Test acc: 81.6568\n",
      "Train loss: 0.0003 | Test loss: 0.5658 | Test acc: 79.4741\n",
      "Train loss: 0.0004 | Test loss: 0.5676 | Test acc: 81.0446\n",
      "Train loss: 0.0004 | Test loss: 0.5705 | Test acc: 80.3009\n",
      "Train loss: 0.0003 | Test loss: 0.6130 | Test acc: 77.0038\n",
      "Train loss: 0.0005 | Test loss: 0.6898 | Test acc: 74.5871\n",
      "Train loss: 0.0006 | Test loss: 0.6508 | Test acc: 75.9971\n",
      "Train loss: 0.0002 | Test loss: 0.6396 | Test acc: 76.9900\n",
      "Train loss: 0.0004 | Test loss: 0.6122 | Test acc: 78.0515\n",
      "Train loss: 0.0003 | Test loss: 0.5604 | Test acc: 80.2514\n",
      "Train loss: 0.0003 | Test loss: 0.5307 | Test acc: 81.5363\n",
      "Train loss: 0.0003 | Test loss: 0.5420 | Test acc: 81.6802\n",
      "Train loss: 0.0004 | Test loss: 0.5345 | Test acc: 81.6607\n",
      "Train loss: 0.0002 | Test loss: 0.5552 | Test acc: 80.7321\n",
      "Train loss: 0.0003 | Test loss: 0.5314 | Test acc: 81.6577\n",
      "Train loss: 0.0003 | Test loss: 0.5531 | Test acc: 80.6023\n",
      "Train loss: 0.0004 | Test loss: 0.5487 | Test acc: 80.9584\n",
      "Train loss: 0.0002 | Test loss: 0.5416 | Test acc: 80.8996\n",
      "Train loss: 0.0003 | Test loss: 0.5372 | Test acc: 81.7980\n",
      "Train loss: 0.0004 | Test loss: 0.5468 | Test acc: 80.4430\n",
      "Train loss: 0.0004 | Test loss: 0.5574 | Test acc: 80.3189\n",
      "Train loss: 0.0004 | Test loss: 0.5381 | Test acc: 81.7961\n",
      "Train loss: 0.0003 | Test loss: 0.5488 | Test acc: 81.4814\n",
      "Train loss: 0.0003 | Test loss: 0.5256 | Test acc: 82.2591\n",
      "Train loss: 0.0003 | Test loss: 0.5386 | Test acc: 81.6925\n",
      "Train loss: 0.0003 | Test loss: 0.5539 | Test acc: 80.9219\n",
      "Train loss: 0.0004 | Test loss: 0.5561 | Test acc: 79.9410\n",
      "Train loss: 0.0003 | Test loss: 0.5260 | Test acc: 82.0246\n",
      "Train loss: 0.0004 | Test loss: 0.5920 | Test acc: 79.0859\n",
      "Train loss: 0.0002 | Test loss: 0.5831 | Test acc: 79.4060\n",
      "Train loss: 0.0002 | Test loss: 0.5591 | Test acc: 80.4654\n",
      "Train loss: 0.0003 | Test loss: 0.6192 | Test acc: 78.0925\n",
      "Train loss: 0.0003 | Test loss: 0.5617 | Test acc: 80.4013\n",
      "Train loss: 0.0003 | Test loss: 0.5948 | Test acc: 78.5616\n",
      "Train loss: 0.0003 | Test loss: 0.6160 | Test acc: 77.6671\n",
      "Train loss: 0.0005 | Test loss: 0.5830 | Test acc: 79.4115\n",
      "Train loss: 0.0004 | Test loss: 0.5324 | Test acc: 81.5836\n",
      "Train loss: 0.0002 | Test loss: 0.5382 | Test acc: 80.8916\n",
      "Train loss: 0.0002 | Test loss: 0.5376 | Test acc: 81.3387\n",
      "Train loss: 0.0002 | Test loss: 0.5504 | Test acc: 80.8010\n",
      "Train loss: 0.0004 | Test loss: 0.5281 | Test acc: 81.8276\n",
      "Train loss: 0.0002 | Test loss: 0.5379 | Test acc: 81.3117\n",
      "Train loss: 0.0002 | Test loss: 0.5287 | Test acc: 81.4698\n",
      "Train loss: 0.0003 | Test loss: 0.5328 | Test acc: 81.6001\n",
      "Train loss: 0.0004 | Test loss: 0.5975 | Test acc: 78.1760\n",
      "Train loss: 0.0004 | Test loss: 0.6624 | Test acc: 75.9586\n",
      "Train loss: 0.0002 | Test loss: 0.5679 | Test acc: 80.2347\n",
      "Train loss: 0.0003 | Test loss: 0.5570 | Test acc: 79.9189\n",
      "Train loss: 0.0003 | Test loss: 0.5755 | Test acc: 79.4985\n",
      "Train loss: 0.0004 | Test loss: 0.5566 | Test acc: 80.5156\n",
      "Train loss: 0.0004 | Test loss: 0.6520 | Test acc: 76.9745\n",
      "Train loss: 0.0003 | Test loss: 0.5742 | Test acc: 79.9484\n",
      "Train loss: 0.0002 | Test loss: 0.5902 | Test acc: 79.5186\n",
      "Train loss: 0.0002 | Test loss: 0.5689 | Test acc: 79.1678\n",
      "Train loss: 0.0002 | Test loss: 0.5371 | Test acc: 82.2318\n",
      "Train loss: 0.0002 | Test loss: 0.5206 | Test acc: 82.1317\n",
      "Train loss: 0.0002 | Test loss: 0.5283 | Test acc: 81.6821\n",
      "Train loss: 0.0003 | Test loss: 0.5223 | Test acc: 82.0501\n",
      "Train loss: 0.0002 | Test loss: 0.5366 | Test acc: 81.6719\n",
      "Train loss: 0.0003 | Test loss: 0.6496 | Test acc: 75.0712\n",
      "Train loss: 0.0002 | Test loss: 0.5354 | Test acc: 81.9291\n",
      "Train loss: 0.0002 | Test loss: 0.5159 | Test acc: 82.1807\n",
      "Train loss: 0.0002 | Test loss: 0.5591 | Test acc: 80.2745\n",
      "Train loss: 0.0004 | Test loss: 0.5865 | Test acc: 78.3216\n",
      "Train loss: 0.0004 | Test loss: 0.5323 | Test acc: 81.5202\n",
      "Train loss: 0.0002 | Test loss: 0.5189 | Test acc: 81.9797\n",
      "Train loss: 0.0001 | Test loss: 0.5234 | Test acc: 81.7216\n",
      "Train loss: 0.0004 | Test loss: 0.6069 | Test acc: 77.6073\n",
      "Train loss: 0.0003 | Test loss: 0.5553 | Test acc: 80.8989\n",
      "Train loss: 0.0003 | Test loss: 0.5498 | Test acc: 80.8096\n",
      "Train loss: 0.0003 | Test loss: 0.6805 | Test acc: 73.2714\n",
      "Train loss: 0.0004 | Test loss: 0.5863 | Test acc: 79.3076\n",
      "Train loss: 0.0003 | Test loss: 0.5412 | Test acc: 80.8544\n",
      "Train loss: 0.0003 | Test loss: 0.5524 | Test acc: 79.6213\n",
      "Train loss: 0.0003 | Test loss: 0.5556 | Test acc: 80.5459\n",
      "Train loss: 0.0003 | Test loss: 0.5774 | Test acc: 80.4690\n",
      "Train loss: 0.0002 | Test loss: 0.5968 | Test acc: 79.4404\n",
      "Train loss: 0.0004 | Test loss: 0.5531 | Test acc: 81.3940\n",
      "Train loss: 0.0002 | Test loss: 0.5480 | Test acc: 81.3902\n",
      "Train loss: 0.0003 | Test loss: 0.5660 | Test acc: 80.5016\n",
      "Train loss: 0.0002 | Test loss: 0.5569 | Test acc: 80.5487\n",
      "Train loss: 0.0003 | Test loss: 0.6433 | Test acc: 77.1443\n",
      "Train loss: 0.0003 | Test loss: 0.5482 | Test acc: 80.8675\n",
      "Train loss: 0.0003 | Test loss: 0.5813 | Test acc: 78.9924\n",
      "Train loss: 0.0008 | Test loss: 0.5512 | Test acc: 81.2428\n",
      "Train loss: 0.0004 | Test loss: 0.5425 | Test acc: 81.3498\n",
      "Train loss: 0.0004 | Test loss: 0.5808 | Test acc: 80.1621\n",
      "Train loss: 0.0002 | Test loss: 0.5699 | Test acc: 80.0784\n",
      "Train loss: 0.0003 | Test loss: 0.5395 | Test acc: 81.3261\n",
      "Train loss: 0.0003 | Test loss: 0.5671 | Test acc: 80.4216\n",
      "Train loss: 0.0002 | Test loss: 0.5466 | Test acc: 81.0477\n",
      "Train loss: 0.0002 | Test loss: 0.5757 | Test acc: 80.0014\n",
      "Train loss: 0.0003 | Test loss: 0.5683 | Test acc: 80.3275\n",
      "Train loss: 0.0004 | Test loss: 0.5802 | Test acc: 79.9691\n",
      "Train loss: 0.0003 | Test loss: 0.5496 | Test acc: 80.7767\n",
      "Train loss: 0.0001 | Test loss: 0.5656 | Test acc: 80.8691\n",
      "Train loss: 0.0003 | Test loss: 0.5927 | Test acc: 77.6146\n",
      "Train loss: 0.0003 | Test loss: 0.5624 | Test acc: 80.1901\n",
      "Train loss: 0.0004 | Test loss: 0.6106 | Test acc: 78.5409\n",
      "Train loss: 0.0003 | Test loss: 0.5682 | Test acc: 79.8236\n",
      "Train loss: 0.0003 | Test loss: 0.5481 | Test acc: 80.9859\n",
      "Train loss: 0.0003 | Test loss: 0.5637 | Test acc: 80.4504\n",
      "Train loss: 0.0003 | Test loss: 0.5415 | Test acc: 81.3173\n",
      "Train loss: 0.0003 | Test loss: 0.5435 | Test acc: 81.4798\n",
      "Train loss: 0.0003 | Test loss: 0.5641 | Test acc: 79.4736\n",
      "Train loss: 0.0003 | Test loss: 0.5496 | Test acc: 80.5554\n",
      "Train loss: 0.0004 | Test loss: 0.7280 | Test acc: 75.2374\n",
      "Train loss: 0.0004 | Test loss: 0.5816 | Test acc: 78.5850\n",
      "Train loss: 0.0003 | Test loss: 0.5756 | Test acc: 80.5127\n",
      "Train loss: 0.0003 | Test loss: 0.5454 | Test acc: 81.2976\n",
      "Train loss: 0.0002 | Test loss: 0.5972 | Test acc: 79.4231\n",
      "Train loss: 0.0002 | Test loss: 0.5343 | Test acc: 81.4039\n",
      "Train loss: 0.0003 | Test loss: 0.5660 | Test acc: 80.7213\n",
      "Train loss: 0.0003 | Test loss: 0.5641 | Test acc: 79.8505\n",
      "Train loss: 0.0002 | Test loss: 0.5843 | Test acc: 79.9077\n",
      "Train loss: 0.0002 | Test loss: 0.5648 | Test acc: 81.0760\n",
      "Train loss: 0.0003 | Test loss: 0.5587 | Test acc: 80.9998\n",
      "Train loss: 0.0003 | Test loss: 0.5476 | Test acc: 81.6985\n",
      "Train loss: 0.0002 | Test loss: 0.5309 | Test acc: 82.1001\n",
      "Train loss: 0.0003 | Test loss: 0.5499 | Test acc: 79.6253\n",
      "Train loss: 0.0003 | Test loss: 0.5674 | Test acc: 78.8886\n",
      "Train loss: 0.0004 | Test loss: 0.5386 | Test acc: 81.1127\n",
      "Train loss: 0.0003 | Test loss: 0.5419 | Test acc: 81.1897\n",
      "Train loss: 0.0003 | Test loss: 0.5503 | Test acc: 80.5110\n",
      "Train loss: 0.0003 | Test loss: 0.5680 | Test acc: 80.7584\n",
      "Train loss: 0.0004 | Test loss: 0.5927 | Test acc: 79.0819\n",
      "Train loss: 0.0002 | Test loss: 0.6139 | Test acc: 78.2379\n",
      "Train loss: 0.0004 | Test loss: 0.5195 | Test acc: 82.2088\n",
      "Train loss: 0.0002 | Test loss: 0.5100 | Test acc: 82.3313\n",
      "Train loss: 0.0002 | Test loss: 0.5389 | Test acc: 81.4531\n",
      "Train loss: 0.0003 | Test loss: 0.5590 | Test acc: 80.6816\n",
      "Train loss: 0.0002 | Test loss: 0.5776 | Test acc: 80.4594\n",
      "Train loss: 0.0003 | Test loss: 0.5686 | Test acc: 80.5785\n",
      "Train loss: 0.0002 | Test loss: 0.5478 | Test acc: 80.7487\n",
      "Train loss: 0.0003 | Test loss: 0.5730 | Test acc: 79.8706\n",
      "Train loss: 0.0003 | Test loss: 0.5214 | Test acc: 82.0243\n",
      "Train loss: 0.0004 | Test loss: 0.6014 | Test acc: 78.7065\n",
      "Train loss: 0.0002 | Test loss: 0.5892 | Test acc: 80.0438\n",
      "Train loss: 0.0002 | Test loss: 0.5391 | Test acc: 81.3560\n",
      "Train loss: 0.0002 | Test loss: 0.5469 | Test acc: 80.5914\n",
      "Train loss: 0.0004 | Test loss: 0.5361 | Test acc: 80.5989\n",
      "Train loss: 0.0004 | Test loss: 0.6491 | Test acc: 76.3258\n",
      "Train loss: 0.0003 | Test loss: 0.6660 | Test acc: 75.7131\n",
      "Train loss: 0.0004 | Test loss: 0.5545 | Test acc: 81.0326\n",
      "Train loss: 0.0004 | Test loss: 0.5350 | Test acc: 81.6786\n",
      "Train loss: 0.0004 | Test loss: 0.6026 | Test acc: 78.0864\n",
      "Train loss: 0.0003 | Test loss: 0.5379 | Test acc: 81.7291\n",
      "Train loss: 0.0007 | Test loss: 0.6865 | Test acc: 74.2827\n",
      "Train loss: 0.0002 | Test loss: 0.5945 | Test acc: 78.7118\n",
      "Train loss: 0.0005 | Test loss: 0.6338 | Test acc: 75.1516\n",
      "Train loss: 0.0003 | Test loss: 0.5600 | Test acc: 81.0808\n",
      "Train loss: 0.0002 | Test loss: 0.5443 | Test acc: 81.0398\n",
      "Train loss: 0.0002 | Test loss: 0.6015 | Test acc: 79.7617\n",
      "Train loss: 0.0005 | Test loss: 0.6995 | Test acc: 74.8455\n",
      "Train loss: 0.0003 | Test loss: 0.6181 | Test acc: 76.9763\n",
      "Train loss: 0.0004 | Test loss: 0.6187 | Test acc: 77.5023\n",
      "Train loss: 0.0002 | Test loss: 0.5776 | Test acc: 78.9317\n",
      "Train loss: 0.0002 | Test loss: 0.5608 | Test acc: 80.2841\n",
      "Train loss: 0.0004 | Test loss: 0.5274 | Test acc: 81.9258\n",
      "Train loss: 0.0003 | Test loss: 0.5409 | Test acc: 80.8528\n",
      "Train loss: 0.0003 | Test loss: 0.5335 | Test acc: 81.0191\n",
      "Train loss: 0.0002 | Test loss: 0.5419 | Test acc: 81.1894\n",
      "Train loss: 0.0002 | Test loss: 0.5596 | Test acc: 80.7306\n",
      "Train loss: 0.0002 | Test loss: 0.5759 | Test acc: 79.6209\n",
      "Train loss: 0.0002 | Test loss: 0.5477 | Test acc: 80.6857\n",
      "Train loss: 0.0002 | Test loss: 0.5556 | Test acc: 80.8788\n",
      "Train loss: 0.0004 | Test loss: 0.5407 | Test acc: 81.1190\n",
      "Train loss: 0.0002 | Test loss: 0.5331 | Test acc: 80.9700\n",
      "Train loss: 0.0005 | Test loss: 0.5658 | Test acc: 80.4803\n",
      "Train loss: 0.0003 | Test loss: 0.5551 | Test acc: 80.7883\n",
      "Train loss: 0.0003 | Test loss: 0.5599 | Test acc: 80.3899\n",
      "Train loss: 0.0002 | Test loss: 0.5315 | Test acc: 81.3970\n",
      "Train loss: 0.0002 | Test loss: 0.5356 | Test acc: 81.0009\n",
      "Train loss: 0.0002 | Test loss: 0.5404 | Test acc: 81.0795\n",
      "Train loss: 0.0002 | Test loss: 0.5634 | Test acc: 80.5106\n",
      "Train loss: 0.0002 | Test loss: 0.5546 | Test acc: 79.8199\n",
      "Train loss: 0.0002 | Test loss: 0.5703 | Test acc: 79.3485\n",
      "Train loss: 0.0004 | Test loss: 0.6175 | Test acc: 77.9093\n",
      "Train loss: 0.0003 | Test loss: 0.6017 | Test acc: 78.4738\n",
      "Train loss: 0.0002 | Test loss: 0.5506 | Test acc: 81.0414\n",
      "Train loss: 0.0003 | Test loss: 0.5572 | Test acc: 80.7401\n",
      "Train loss: 0.0005 | Test loss: 0.6942 | Test acc: 76.6857\n",
      "Train loss: 0.0003 | Test loss: 0.6625 | Test acc: 77.7510\n",
      "Train loss: 0.0003 | Test loss: 0.6056 | Test acc: 78.3335\n",
      "Train loss: 0.0003 | Test loss: 0.5914 | Test acc: 79.7131\n",
      "Train loss: 0.0002 | Test loss: 0.6037 | Test acc: 79.1884\n",
      "Train loss: 0.0003 | Test loss: 0.5526 | Test acc: 81.0337\n",
      "Train loss: 0.0003 | Test loss: 0.6097 | Test acc: 78.6235\n",
      "Train loss: 0.0002 | Test loss: 0.6186 | Test acc: 79.1949\n",
      "Train loss: 0.0004 | Test loss: 0.5747 | Test acc: 81.0038\n",
      "Train loss: 0.0003 | Test loss: 0.5963 | Test acc: 79.5819\n",
      "Train loss: 0.0002 | Test loss: 0.5739 | Test acc: 80.3062\n",
      "Train loss: 0.0003 | Test loss: 0.5437 | Test acc: 81.6963\n",
      "Train loss: 0.0003 | Test loss: 0.5786 | Test acc: 78.8952\n",
      "Train loss: 0.0002 | Test loss: 0.6369 | Test acc: 74.8427\n",
      "Train loss: 0.0002 | Test loss: 0.5511 | Test acc: 80.4408\n",
      "Train loss: 0.0001 | Test loss: 0.5208 | Test acc: 81.9563\n",
      "Train loss: 0.0004 | Test loss: 0.5953 | Test acc: 78.5666\n",
      "Train loss: 0.0003 | Test loss: 0.5328 | Test acc: 81.9703\n",
      "Train loss: 0.0002 | Test loss: 0.5362 | Test acc: 81.7016\n",
      "Train loss: 0.0004 | Test loss: 0.5947 | Test acc: 79.1847\n",
      "Train loss: 0.0004 | Test loss: 0.5466 | Test acc: 80.8241\n",
      "Train loss: 0.0002 | Test loss: 0.5332 | Test acc: 81.8577\n",
      "Train loss: 0.0002 | Test loss: 0.5476 | Test acc: 81.8310\n",
      "Train loss: 0.0002 | Test loss: 0.5745 | Test acc: 80.6828\n",
      "Train loss: 0.0004 | Test loss: 0.5363 | Test acc: 81.3181\n",
      "Train loss: 0.0002 | Test loss: 0.5300 | Test acc: 81.4499\n",
      "Train loss: 0.0004 | Test loss: 0.5471 | Test acc: 81.2806\n",
      "Train loss: 0.0002 | Test loss: 0.5393 | Test acc: 81.4997\n",
      "Train loss: 0.0003 | Test loss: 0.6228 | Test acc: 77.8562\n",
      "Train loss: 0.0004 | Test loss: 0.5453 | Test acc: 81.2192\n",
      "Train loss: 0.0003 | Test loss: 0.5528 | Test acc: 80.8206\n",
      "Train loss: 0.0002 | Test loss: 0.5932 | Test acc: 78.8624\n",
      "Train loss: 0.0003 | Test loss: 0.5371 | Test acc: 81.9912\n",
      "Train loss: 0.0004 | Test loss: 0.5656 | Test acc: 79.7348\n",
      "Train loss: 0.0002 | Test loss: 0.5219 | Test acc: 82.0239\n",
      "Train loss: 0.0004 | Test loss: 0.5739 | Test acc: 79.6550\n",
      "Train loss: 0.0003 | Test loss: 0.6020 | Test acc: 78.6990\n",
      "Train loss: 0.0003 | Test loss: 0.5233 | Test acc: 81.7910\n",
      "Train loss: 0.0002 | Test loss: 0.5951 | Test acc: 78.5161\n",
      "Train loss: 0.0003 | Test loss: 0.5352 | Test acc: 81.7405\n",
      "Train loss: 0.0003 | Test loss: 0.5439 | Test acc: 80.0834\n",
      "Train loss: 0.0002 | Test loss: 0.5257 | Test acc: 82.2047\n",
      "Train loss: 0.0004 | Test loss: 0.5480 | Test acc: 81.3828\n",
      "Train loss: 0.0003 | Test loss: 0.5816 | Test acc: 77.7960\n",
      "Train loss: 0.0002 | Test loss: 0.5699 | Test acc: 79.0225\n",
      "Train loss: 0.0004 | Test loss: 0.6022 | Test acc: 78.8667\n",
      "Train loss: 0.0002 | Test loss: 0.5686 | Test acc: 80.1142\n",
      "Train loss: 0.0002 | Test loss: 0.5374 | Test acc: 81.6357\n",
      "Train loss: 0.0002 | Test loss: 0.5436 | Test acc: 81.1314\n",
      "Train loss: 0.0005 | Test loss: 0.5357 | Test acc: 81.4992\n",
      "Train loss: 0.0003 | Test loss: 0.5432 | Test acc: 81.2408\n",
      "Train loss: 0.0002 | Test loss: 0.5214 | Test acc: 82.2584\n",
      "Train loss: 0.0003 | Test loss: 0.5279 | Test acc: 81.3830\n",
      "Train loss: 0.0001 | Test loss: 0.5244 | Test acc: 81.8794\n",
      "Train loss: 0.0003 | Test loss: 0.5259 | Test acc: 81.7013\n",
      "Train loss: 0.0000 | Test loss: 0.5214 | Test acc: 81.8505\n",
      "Train loss: 0.0004 | Test loss: 0.5230 | Test acc: 82.1006\n",
      "Train loss: 0.0001 | Test loss: 0.5252 | Test acc: 82.0514\n",
      "Train loss: 0.0002 | Test loss: 0.5345 | Test acc: 81.4323\n",
      "Train loss: 0.0002 | Test loss: 0.5236 | Test acc: 81.7098\n",
      "Train loss: 0.0002 | Test loss: 0.5641 | Test acc: 80.0933\n",
      "Train loss: 0.0003 | Test loss: 0.5772 | Test acc: 81.2363\n",
      "Train loss: 0.0003 | Test loss: 0.5289 | Test acc: 81.6893\n",
      "Train loss: 0.0003 | Test loss: 0.5397 | Test acc: 80.6424\n",
      "Train loss: 0.0004 | Test loss: 0.5296 | Test acc: 82.1167\n",
      "Train loss: 0.0003 | Test loss: 0.6049 | Test acc: 79.0962\n",
      "Train loss: 0.0005 | Test loss: 0.5951 | Test acc: 78.4975\n",
      "Train loss: 0.0003 | Test loss: 0.6081 | Test acc: 78.1162\n",
      "Train loss: 0.0002 | Test loss: 0.5500 | Test acc: 81.2200\n",
      "Train loss: 0.0002 | Test loss: 0.5193 | Test acc: 81.8689\n",
      "Train loss: 0.0004 | Test loss: 0.5660 | Test acc: 81.5515\n",
      "Train loss: 0.0003 | Test loss: 0.5753 | Test acc: 80.0030\n",
      "Train loss: 0.0004 | Test loss: 0.5843 | Test acc: 80.2276\n",
      "Train loss: 0.0004 | Test loss: 0.5377 | Test acc: 81.3665\n",
      "Train loss: 0.0004 | Test loss: 0.5325 | Test acc: 81.2504\n",
      "Train loss: 0.0003 | Test loss: 0.5271 | Test acc: 81.7292\n",
      "Train loss: 0.0001 | Test loss: 0.5192 | Test acc: 82.1002\n",
      "Train loss: 0.0003 | Test loss: 0.5545 | Test acc: 80.4939\n",
      "Train loss: 0.0003 | Test loss: 0.5453 | Test acc: 81.0978\n",
      "Train loss: 0.0004 | Test loss: 0.5766 | Test acc: 79.0031\n",
      "Train loss: 0.0003 | Test loss: 0.5961 | Test acc: 78.4872\n",
      "Train loss: 0.0003 | Test loss: 0.5506 | Test acc: 80.3426\n",
      "Train loss: 0.0003 | Test loss: 0.6365 | Test acc: 76.2351\n",
      "Train loss: 0.0004 | Test loss: 0.5936 | Test acc: 79.9660\n",
      "Train loss: 0.0002 | Test loss: 0.5479 | Test acc: 81.1560\n",
      "Train loss: 0.0004 | Test loss: 0.5308 | Test acc: 81.7489\n",
      "Train loss: 0.0003 | Test loss: 0.5612 | Test acc: 80.3031\n",
      "Train loss: 0.0005 | Test loss: 0.5835 | Test acc: 79.1304\n",
      "Train loss: 0.0003 | Test loss: 0.5416 | Test acc: 80.2149\n",
      "Train loss: 0.0003 | Test loss: 0.5186 | Test acc: 82.0854\n",
      "Train loss: 0.0002 | Test loss: 0.5434 | Test acc: 81.0929\n",
      "Train loss: 0.0002 | Test loss: 0.5096 | Test acc: 82.0682\n",
      "Train loss: 0.0003 | Test loss: 0.5173 | Test acc: 82.0114\n",
      "Train loss: 0.0003 | Test loss: 0.5299 | Test acc: 81.7716\n",
      "Train loss: 0.0002 | Test loss: 0.5337 | Test acc: 81.7209\n",
      "Train loss: 0.0002 | Test loss: 0.5404 | Test acc: 81.0818\n",
      "Train loss: 0.0002 | Test loss: 0.5445 | Test acc: 80.9200\n",
      "Train loss: 0.0004 | Test loss: 0.5704 | Test acc: 79.8612\n",
      "Train loss: 0.0002 | Test loss: 0.5143 | Test acc: 81.9944\n",
      "Train loss: 0.0002 | Test loss: 0.5197 | Test acc: 81.9612\n",
      "Train loss: 0.0002 | Test loss: 0.5385 | Test acc: 80.9028\n",
      "Train loss: 0.0003 | Test loss: 0.5316 | Test acc: 81.6782\n",
      "Train loss: 0.0005 | Test loss: 0.5285 | Test acc: 82.3296\n",
      "Train loss: 0.0003 | Test loss: 0.5502 | Test acc: 80.4847\n",
      "Train loss: 0.0003 | Test loss: 0.5582 | Test acc: 80.8881\n",
      "Train loss: 0.0002 | Test loss: 0.5403 | Test acc: 81.9577\n",
      "Train loss: 0.0002 | Test loss: 0.5857 | Test acc: 79.6249\n",
      "Train loss: 0.0004 | Test loss: 0.5190 | Test acc: 82.2732\n",
      "Train loss: 0.0003 | Test loss: 0.5382 | Test acc: 81.4430\n",
      "Train loss: 0.0003 | Test loss: 0.5588 | Test acc: 80.5917\n",
      "Train loss: 0.0003 | Test loss: 0.5340 | Test acc: 81.6572\n",
      "Train loss: 0.0003 | Test loss: 0.6035 | Test acc: 77.2078\n",
      "Train loss: 0.0004 | Test loss: 0.5212 | Test acc: 81.8761\n",
      "Train loss: 0.0002 | Test loss: 0.5334 | Test acc: 81.5016\n",
      "Train loss: 0.0003 | Test loss: 0.5331 | Test acc: 81.7300\n",
      "Train loss: 0.0005 | Test loss: 0.5154 | Test acc: 81.9205\n",
      "Train loss: 0.0001 | Test loss: 0.5073 | Test acc: 82.3404\n",
      "Train loss: 0.0002 | Test loss: 0.5391 | Test acc: 80.8142\n",
      "Train loss: 0.0002 | Test loss: 0.5284 | Test acc: 80.9790\n",
      "Train loss: 0.0002 | Test loss: 0.5147 | Test acc: 81.7983\n",
      "Train loss: 0.0002 | Test loss: 0.5186 | Test acc: 81.9906\n",
      "Train loss: 0.0003 | Test loss: 0.6148 | Test acc: 77.5483\n",
      "Train loss: 0.0003 | Test loss: 0.5296 | Test acc: 82.1268\n",
      "Train loss: 0.0004 | Test loss: 0.5638 | Test acc: 80.2444\n",
      "Train loss: 0.0003 | Test loss: 0.5569 | Test acc: 80.2184\n",
      "Train loss: 0.0003 | Test loss: 0.5218 | Test acc: 81.7259\n",
      "Train loss: 0.0003 | Test loss: 0.5666 | Test acc: 80.4328\n",
      "Train loss: 0.0003 | Test loss: 0.5386 | Test acc: 81.3372\n",
      "Train loss: 0.0003 | Test loss: 0.5298 | Test acc: 81.4899\n",
      "Train loss: 0.0002 | Test loss: 0.5232 | Test acc: 81.7899\n",
      "Train loss: 0.0003 | Test loss: 0.5516 | Test acc: 80.6627\n",
      "Train loss: 0.0004 | Test loss: 0.5238 | Test acc: 81.5077\n",
      "Train loss: 0.0002 | Test loss: 0.5455 | Test acc: 81.2309\n",
      "Train loss: 0.0003 | Test loss: 0.5735 | Test acc: 80.9804\n",
      "Train loss: 0.0003 | Test loss: 0.5195 | Test acc: 82.2475\n",
      "Train loss: 0.0003 | Test loss: 0.5158 | Test acc: 81.9621\n",
      "Train loss: 0.0004 | Test loss: 0.6004 | Test acc: 79.0758\n",
      "Train loss: 0.0003 | Test loss: 0.5694 | Test acc: 80.2347\n",
      "Train loss: 0.0002 | Test loss: 0.5519 | Test acc: 81.0770\n",
      "Train loss: 0.0003 | Test loss: 0.5780 | Test acc: 79.1828\n",
      "Train loss: 0.0002 | Test loss: 0.5716 | Test acc: 79.8456\n",
      "Train loss: 0.0002 | Test loss: 0.5437 | Test acc: 81.2156\n",
      "Train loss: 0.0004 | Test loss: 0.5587 | Test acc: 79.8222\n",
      "Train loss: 0.0003 | Test loss: 0.5392 | Test acc: 81.0258\n",
      "Train loss: 0.0006 | Test loss: 0.5271 | Test acc: 81.8284\n",
      "Train loss: 0.0004 | Test loss: 0.5242 | Test acc: 82.0506\n",
      "Train loss: 0.0003 | Test loss: 0.5495 | Test acc: 80.0545\n",
      "Train loss: 0.0002 | Test loss: 0.5350 | Test acc: 81.0665\n",
      "Train loss: 0.0002 | Test loss: 0.5371 | Test acc: 81.4790\n",
      "Train loss: 0.0002 | Test loss: 0.5629 | Test acc: 80.4221\n",
      "Train loss: 0.0003 | Test loss: 0.5171 | Test acc: 82.3057\n",
      "Train loss: 0.0003 | Test loss: 0.5379 | Test acc: 81.0437\n",
      "Train loss: 0.0004 | Test loss: 0.5723 | Test acc: 79.8416\n",
      "Train loss: 0.0002 | Test loss: 0.5381 | Test acc: 81.2155\n",
      "Train loss: 0.0004 | Test loss: 0.5727 | Test acc: 79.5027\n",
      "Train loss: 0.0002 | Test loss: 0.5536 | Test acc: 80.8251\n",
      "Train loss: 0.0003 | Test loss: 0.5337 | Test acc: 81.1688\n",
      "Train loss: 0.0003 | Test loss: 0.5509 | Test acc: 80.8903\n",
      "Train loss: 0.0004 | Test loss: 0.5662 | Test acc: 79.5116\n",
      "Train loss: 0.0002 | Test loss: 0.6534 | Test acc: 74.6949\n",
      "Train loss: 0.0002 | Test loss: 0.5610 | Test acc: 79.0426\n",
      "Train loss: 0.0004 | Test loss: 0.6474 | Test acc: 77.8184\n",
      "Train loss: 0.0002 | Test loss: 0.5126 | Test acc: 82.1875\n",
      "Train loss: 0.0003 | Test loss: 0.5934 | Test acc: 79.6456\n",
      "Train loss: 0.0001 | Test loss: 0.5420 | Test acc: 81.1251\n",
      "Train loss: 0.0004 | Test loss: 0.5468 | Test acc: 80.7204\n",
      "Train loss: 0.0003 | Test loss: 0.5433 | Test acc: 80.8889\n",
      "Train loss: 0.0002 | Test loss: 0.5564 | Test acc: 81.3387\n",
      "Train loss: 0.0004 | Test loss: 0.5959 | Test acc: 77.1768\n",
      "Train loss: 0.0002 | Test loss: 0.5403 | Test acc: 81.1172\n",
      "Train loss: 0.0002 | Test loss: 0.5457 | Test acc: 80.7903\n",
      "Train loss: 0.0003 | Test loss: 0.5468 | Test acc: 81.3584\n",
      "Train loss: 0.0004 | Test loss: 0.5420 | Test acc: 80.8909\n",
      "Train loss: 0.0002 | Test loss: 0.5106 | Test acc: 82.3471\n",
      "Train loss: 0.0002 | Test loss: 0.5363 | Test acc: 81.4831\n",
      "Train loss: 0.0003 | Test loss: 0.5266 | Test acc: 81.3506\n",
      "Train loss: 0.0002 | Test loss: 0.5299 | Test acc: 81.2004\n",
      "Train loss: 0.0003 | Test loss: 0.5344 | Test acc: 81.0502\n",
      "Train loss: 0.0003 | Test loss: 0.5370 | Test acc: 80.7701\n",
      "Train loss: 0.0004 | Test loss: 0.5586 | Test acc: 79.4314\n",
      "Train loss: 0.0004 | Test loss: 0.5540 | Test acc: 80.4155\n",
      "Train loss: 0.0003 | Test loss: 0.5782 | Test acc: 79.6100\n",
      "Train loss: 0.0003 | Test loss: 0.6474 | Test acc: 76.9616\n",
      "Train loss: 0.0002 | Test loss: 0.5344 | Test acc: 81.1664\n",
      "Train loss: 0.0002 | Test loss: 0.5637 | Test acc: 79.6822\n",
      "Train loss: 0.0002 | Test loss: 0.5261 | Test acc: 81.5245\n",
      "Train loss: 0.0002 | Test loss: 0.5200 | Test acc: 81.8100\n",
      "Train loss: 0.0002 | Test loss: 0.5432 | Test acc: 80.7925\n",
      "Train loss: 0.0002 | Test loss: 0.5547 | Test acc: 80.5397\n",
      "Train loss: 0.0002 | Test loss: 0.5332 | Test acc: 81.9167\n",
      "Train loss: 0.0003 | Test loss: 0.5427 | Test acc: 81.2921\n",
      "Train loss: 0.0003 | Test loss: 0.5618 | Test acc: 80.4015\n",
      "Train loss: 0.0003 | Test loss: 0.5772 | Test acc: 79.5600\n",
      "Train loss: 0.0003 | Test loss: 0.5518 | Test acc: 80.6456\n",
      "Train loss: 0.0003 | Test loss: 0.5673 | Test acc: 80.6790\n",
      "Train loss: 0.0002 | Test loss: 0.5327 | Test acc: 81.8672\n",
      "Train loss: 0.0003 | Test loss: 0.5341 | Test acc: 81.5914\n",
      "Train loss: 0.0002 | Test loss: 0.5096 | Test acc: 82.3493\n",
      "Train loss: 0.0003 | Test loss: 0.5250 | Test acc: 81.6329\n",
      "Train loss: 0.0003 | Test loss: 0.5284 | Test acc: 81.1214\n",
      "Train loss: 0.0002 | Test loss: 0.5504 | Test acc: 80.7803\n",
      "Train loss: 0.0002 | Test loss: 0.5295 | Test acc: 81.2485\n",
      "Train loss: 0.0002 | Test loss: 0.5359 | Test acc: 81.3399\n",
      "Train loss: 0.0002 | Test loss: 0.5249 | Test acc: 81.2603\n",
      "Train loss: 0.0001 | Test loss: 0.5284 | Test acc: 81.3998\n",
      "Train loss: 0.0003 | Test loss: 0.5178 | Test acc: 82.1590\n",
      "Train loss: 0.0002 | Test loss: 0.5166 | Test acc: 81.6722\n",
      "Train loss: 0.0003 | Test loss: 0.5768 | Test acc: 80.1331\n",
      "Train loss: 0.0002 | Test loss: 0.5381 | Test acc: 81.0068\n",
      "Train loss: 0.0002 | Test loss: 0.5068 | Test acc: 82.3574\n",
      "Train loss: 0.0002 | Test loss: 0.5269 | Test acc: 81.5431\n",
      "Looked at 38400 / 60000 samples\n",
      "Train loss: 0.0002 | Test loss: 0.5325 | Test acc: 80.3723\n",
      "Train loss: 0.0003 | Test loss: 0.5165 | Test acc: 82.3355\n",
      "Train loss: 0.0001 | Test loss: 0.5422 | Test acc: 81.5829\n",
      "Train loss: 0.0003 | Test loss: 0.5691 | Test acc: 79.8233\n",
      "Train loss: 0.0003 | Test loss: 0.5559 | Test acc: 80.5565\n",
      "Train loss: 0.0002 | Test loss: 0.5974 | Test acc: 79.0014\n",
      "Train loss: 0.0003 | Test loss: 0.5483 | Test acc: 79.4756\n",
      "Train loss: 0.0003 | Test loss: 0.5105 | Test acc: 82.3625\n",
      "Train loss: 0.0004 | Test loss: 0.5133 | Test acc: 81.7627\n",
      "Train loss: 0.0002 | Test loss: 0.5200 | Test acc: 81.9605\n",
      "Train loss: 0.0003 | Test loss: 0.5182 | Test acc: 82.1708\n",
      "Train loss: 0.0003 | Test loss: 0.5183 | Test acc: 81.9718\n",
      "Train loss: 0.0003 | Test loss: 0.5210 | Test acc: 82.2307\n",
      "Train loss: 0.0003 | Test loss: 0.5459 | Test acc: 81.7124\n",
      "Train loss: 0.0004 | Test loss: 0.5599 | Test acc: 79.9336\n",
      "Train loss: 0.0005 | Test loss: 0.5129 | Test acc: 81.8149\n",
      "Train loss: 0.0004 | Test loss: 0.6371 | Test acc: 78.8956\n",
      "Train loss: 0.0001 | Test loss: 0.5852 | Test acc: 80.5336\n",
      "Train loss: 0.0003 | Test loss: 0.5370 | Test acc: 81.5772\n",
      "Train loss: 0.0003 | Test loss: 0.5633 | Test acc: 79.3840\n",
      "Train loss: 0.0003 | Test loss: 0.5880 | Test acc: 78.9178\n",
      "Train loss: 0.0004 | Test loss: 0.5075 | Test acc: 82.3108\n",
      "Train loss: 0.0002 | Test loss: 0.5264 | Test acc: 81.2434\n",
      "Train loss: 0.0004 | Test loss: 0.5151 | Test acc: 82.2783\n",
      "Train loss: 0.0003 | Test loss: 0.6376 | Test acc: 74.6039\n",
      "Train loss: 0.0002 | Test loss: 0.5208 | Test acc: 81.8877\n",
      "Train loss: 0.0004 | Test loss: 0.5173 | Test acc: 81.7912\n",
      "Train loss: 0.0003 | Test loss: 0.5201 | Test acc: 81.2717\n",
      "Train loss: 0.0003 | Test loss: 0.5392 | Test acc: 80.2117\n",
      "Train loss: 0.0002 | Test loss: 0.5458 | Test acc: 80.8373\n",
      "Train loss: 0.0003 | Test loss: 0.5183 | Test acc: 81.8877\n",
      "Train loss: 0.0002 | Test loss: 0.5203 | Test acc: 81.8012\n",
      "Train loss: 0.0002 | Test loss: 0.5560 | Test acc: 79.9638\n",
      "Train loss: 0.0003 | Test loss: 0.5381 | Test acc: 80.8964\n",
      "Train loss: 0.0002 | Test loss: 0.5029 | Test acc: 82.8763\n",
      "Train loss: 0.0002 | Test loss: 0.5535 | Test acc: 80.6861\n",
      "Train loss: 0.0002 | Test loss: 0.5260 | Test acc: 81.7774\n",
      "Train loss: 0.0005 | Test loss: 0.5371 | Test acc: 81.2317\n",
      "Train loss: 0.0002 | Test loss: 0.5226 | Test acc: 81.9588\n",
      "Train loss: 0.0002 | Test loss: 0.5881 | Test acc: 78.8661\n",
      "Train loss: 0.0002 | Test loss: 0.5188 | Test acc: 81.8414\n",
      "Train loss: 0.0002 | Test loss: 0.4990 | Test acc: 82.8593\n",
      "Train loss: 0.0002 | Test loss: 0.5263 | Test acc: 82.2535\n",
      "Train loss: 0.0003 | Test loss: 0.5449 | Test acc: 81.5927\n",
      "Train loss: 0.0002 | Test loss: 0.5464 | Test acc: 81.8002\n",
      "Train loss: 0.0002 | Test loss: 0.5325 | Test acc: 81.9307\n",
      "Train loss: 0.0002 | Test loss: 0.5334 | Test acc: 81.5717\n",
      "Train loss: 0.0002 | Test loss: 0.5518 | Test acc: 80.0030\n",
      "Train loss: 0.0002 | Test loss: 0.5119 | Test acc: 82.2844\n",
      "Train loss: 0.0002 | Test loss: 0.5159 | Test acc: 82.3715\n",
      "Train loss: 0.0002 | Test loss: 0.5183 | Test acc: 82.0623\n",
      "Train loss: 0.0003 | Test loss: 0.6336 | Test acc: 76.6799\n",
      "Train loss: 0.0002 | Test loss: 0.5405 | Test acc: 81.3153\n",
      "Train loss: 0.0002 | Test loss: 0.5968 | Test acc: 78.8740\n",
      "Train loss: 0.0003 | Test loss: 0.5536 | Test acc: 81.1226\n",
      "Train loss: 0.0003 | Test loss: 0.5227 | Test acc: 81.7488\n",
      "Train loss: 0.0004 | Test loss: 0.5493 | Test acc: 81.0419\n",
      "Train loss: 0.0003 | Test loss: 0.5294 | Test acc: 81.7585\n",
      "Train loss: 0.0005 | Test loss: 0.5997 | Test acc: 79.1250\n",
      "Train loss: 0.0003 | Test loss: 0.5252 | Test acc: 82.0220\n",
      "Train loss: 0.0002 | Test loss: 0.5733 | Test acc: 80.4138\n",
      "Train loss: 0.0005 | Test loss: 0.5758 | Test acc: 79.5500\n",
      "Train loss: 0.0004 | Test loss: 0.5450 | Test acc: 81.4842\n",
      "Train loss: 0.0003 | Test loss: 0.5587 | Test acc: 80.4121\n",
      "Train loss: 0.0002 | Test loss: 0.5605 | Test acc: 80.4087\n",
      "Train loss: 0.0004 | Test loss: 0.5893 | Test acc: 79.7098\n",
      "Train loss: 0.0002 | Test loss: 0.5751 | Test acc: 80.8956\n",
      "Train loss: 0.0004 | Test loss: 0.5455 | Test acc: 80.9693\n",
      "Train loss: 0.0003 | Test loss: 0.5090 | Test acc: 82.0079\n",
      "Train loss: 0.0002 | Test loss: 0.5071 | Test acc: 82.4605\n",
      "Train loss: 0.0004 | Test loss: 0.5446 | Test acc: 80.0658\n",
      "Train loss: 0.0002 | Test loss: 0.5268 | Test acc: 81.5457\n",
      "Train loss: 0.0002 | Test loss: 0.5509 | Test acc: 79.8931\n",
      "Train loss: 0.0003 | Test loss: 0.5123 | Test acc: 82.2840\n",
      "Train loss: 0.0002 | Test loss: 0.5108 | Test acc: 82.0920\n",
      "Train loss: 0.0004 | Test loss: 0.6071 | Test acc: 78.4572\n",
      "Train loss: 0.0003 | Test loss: 0.6001 | Test acc: 78.0162\n",
      "Train loss: 0.0004 | Test loss: 0.5249 | Test acc: 81.6590\n",
      "Train loss: 0.0003 | Test loss: 0.5159 | Test acc: 82.2297\n",
      "Train loss: 0.0003 | Test loss: 0.5105 | Test acc: 82.2216\n",
      "Train loss: 0.0002 | Test loss: 0.5138 | Test acc: 81.7423\n",
      "Train loss: 0.0003 | Test loss: 0.5680 | Test acc: 80.5427\n",
      "Train loss: 0.0005 | Test loss: 0.5480 | Test acc: 80.5788\n",
      "Train loss: 0.0003 | Test loss: 0.5491 | Test acc: 80.9384\n",
      "Train loss: 0.0001 | Test loss: 0.5144 | Test acc: 81.9479\n",
      "Train loss: 0.0003 | Test loss: 0.5301 | Test acc: 81.4719\n",
      "Train loss: 0.0003 | Test loss: 0.6030 | Test acc: 77.7164\n",
      "Train loss: 0.0003 | Test loss: 0.5251 | Test acc: 81.5382\n",
      "Train loss: 0.0003 | Test loss: 0.5328 | Test acc: 81.1710\n",
      "Train loss: 0.0003 | Test loss: 0.5206 | Test acc: 81.9287\n",
      "Train loss: 0.0003 | Test loss: 0.5908 | Test acc: 78.5864\n",
      "Train loss: 0.0002 | Test loss: 0.5075 | Test acc: 82.2000\n",
      "Train loss: 0.0003 | Test loss: 0.5135 | Test acc: 81.9719\n",
      "Train loss: 0.0004 | Test loss: 0.5425 | Test acc: 81.0327\n",
      "Train loss: 0.0002 | Test loss: 0.5084 | Test acc: 82.4773\n",
      "Train loss: 0.0001 | Test loss: 0.4992 | Test acc: 82.7815\n",
      "Train loss: 0.0002 | Test loss: 0.5644 | Test acc: 79.8771\n",
      "Train loss: 0.0003 | Test loss: 0.5226 | Test acc: 81.1757\n",
      "Train loss: 0.0002 | Test loss: 0.6015 | Test acc: 77.2262\n",
      "Train loss: 0.0002 | Test loss: 0.5280 | Test acc: 80.8677\n",
      "Train loss: 0.0002 | Test loss: 0.5144 | Test acc: 81.6881\n",
      "Train loss: 0.0002 | Test loss: 0.5327 | Test acc: 81.5809\n",
      "Train loss: 0.0002 | Test loss: 0.5105 | Test acc: 82.6688\n",
      "Train loss: 0.0003 | Test loss: 0.5574 | Test acc: 80.2561\n",
      "Train loss: 0.0003 | Test loss: 0.5793 | Test acc: 77.9820\n",
      "Train loss: 0.0005 | Test loss: 0.5556 | Test acc: 80.7104\n",
      "Train loss: 0.0003 | Test loss: 0.5515 | Test acc: 80.3098\n",
      "Train loss: 0.0003 | Test loss: 0.5128 | Test acc: 82.1456\n",
      "Train loss: 0.0002 | Test loss: 0.5050 | Test acc: 82.4110\n",
      "Train loss: 0.0003 | Test loss: 0.5199 | Test acc: 82.3020\n",
      "Train loss: 0.0002 | Test loss: 0.5210 | Test acc: 82.2617\n",
      "Train loss: 0.0002 | Test loss: 0.5223 | Test acc: 82.3714\n",
      "Train loss: 0.0002 | Test loss: 0.5038 | Test acc: 82.6214\n",
      "Train loss: 0.0002 | Test loss: 0.5570 | Test acc: 81.4341\n",
      "Train loss: 0.0003 | Test loss: 0.5266 | Test acc: 81.5002\n",
      "Train loss: 0.0003 | Test loss: 0.5419 | Test acc: 80.8015\n",
      "Train loss: 0.0002 | Test loss: 0.5962 | Test acc: 79.9107\n",
      "Train loss: 0.0002 | Test loss: 0.5738 | Test acc: 80.0876\n",
      "Train loss: 0.0005 | Test loss: 0.5556 | Test acc: 80.7371\n",
      "Train loss: 0.0003 | Test loss: 0.5111 | Test acc: 82.4964\n",
      "Train loss: 0.0003 | Test loss: 0.5355 | Test acc: 80.9944\n",
      "Train loss: 0.0004 | Test loss: 0.5265 | Test acc: 81.6585\n",
      "Train loss: 0.0002 | Test loss: 0.5454 | Test acc: 81.0317\n",
      "Train loss: 0.0005 | Test loss: 0.5851 | Test acc: 79.7617\n",
      "Train loss: 0.0002 | Test loss: 0.5110 | Test acc: 82.4333\n",
      "Train loss: 0.0004 | Test loss: 0.5127 | Test acc: 82.3021\n",
      "Train loss: 0.0002 | Test loss: 0.5537 | Test acc: 80.9039\n",
      "Train loss: 0.0003 | Test loss: 0.5512 | Test acc: 80.7996\n",
      "Train loss: 0.0003 | Test loss: 0.5432 | Test acc: 80.9490\n",
      "Train loss: 0.0004 | Test loss: 0.5320 | Test acc: 81.5486\n",
      "Train loss: 0.0003 | Test loss: 0.5426 | Test acc: 81.4107\n",
      "Train loss: 0.0001 | Test loss: 0.5134 | Test acc: 82.0592\n",
      "Train loss: 0.0002 | Test loss: 0.5407 | Test acc: 81.6320\n",
      "Train loss: 0.0003 | Test loss: 0.5239 | Test acc: 82.0000\n",
      "Train loss: 0.0004 | Test loss: 0.5909 | Test acc: 78.1274\n",
      "Train loss: 0.0003 | Test loss: 0.5237 | Test acc: 81.8890\n",
      "Train loss: 0.0001 | Test loss: 0.5001 | Test acc: 82.5400\n",
      "Train loss: 0.0002 | Test loss: 0.5556 | Test acc: 80.0860\n",
      "Train loss: 0.0002 | Test loss: 0.5092 | Test acc: 82.1748\n",
      "Train loss: 0.0005 | Test loss: 0.6051 | Test acc: 77.2094\n",
      "Train loss: 0.0002 | Test loss: 0.5458 | Test acc: 80.1788\n",
      "Train loss: 0.0002 | Test loss: 0.5270 | Test acc: 81.5960\n",
      "Train loss: 0.0002 | Test loss: 0.5085 | Test acc: 82.2795\n",
      "Train loss: 0.0003 | Test loss: 0.5349 | Test acc: 81.3531\n",
      "Train loss: 0.0002 | Test loss: 0.5205 | Test acc: 81.6197\n",
      "Train loss: 0.0004 | Test loss: 0.5086 | Test acc: 81.9800\n",
      "Train loss: 0.0002 | Test loss: 0.5280 | Test acc: 81.2124\n",
      "Train loss: 0.0002 | Test loss: 0.5759 | Test acc: 79.6125\n",
      "Train loss: 0.0003 | Test loss: 0.5051 | Test acc: 82.4229\n",
      "Train loss: 0.0004 | Test loss: 0.5678 | Test acc: 79.9059\n",
      "Train loss: 0.0003 | Test loss: 0.5112 | Test acc: 82.3040\n",
      "Train loss: 0.0002 | Test loss: 0.5185 | Test acc: 81.8025\n",
      "Train loss: 0.0003 | Test loss: 0.6256 | Test acc: 77.3181\n",
      "Train loss: 0.0003 | Test loss: 0.5652 | Test acc: 78.9810\n",
      "Train loss: 0.0001 | Test loss: 0.5428 | Test acc: 80.1844\n",
      "Train loss: 0.0003 | Test loss: 0.5236 | Test acc: 81.5561\n",
      "Train loss: 0.0005 | Test loss: 0.6111 | Test acc: 76.6983\n",
      "Train loss: 0.0003 | Test loss: 0.5227 | Test acc: 82.1540\n",
      "Train loss: 0.0003 | Test loss: 0.5349 | Test acc: 80.8236\n",
      "Train loss: 0.0002 | Test loss: 0.5531 | Test acc: 80.7494\n",
      "Train loss: 0.0004 | Test loss: 0.5249 | Test acc: 81.8974\n",
      "Train loss: 0.0003 | Test loss: 0.5112 | Test acc: 82.6398\n",
      "Train loss: 0.0002 | Test loss: 0.5403 | Test acc: 80.6854\n",
      "Train loss: 0.0003 | Test loss: 0.4987 | Test acc: 82.5861\n",
      "Train loss: 0.0002 | Test loss: 0.5045 | Test acc: 82.4623\n",
      "Train loss: 0.0001 | Test loss: 0.5441 | Test acc: 81.8030\n",
      "Train loss: 0.0004 | Test loss: 0.5564 | Test acc: 81.0421\n",
      "Train loss: 0.0002 | Test loss: 0.5059 | Test acc: 82.6371\n",
      "Train loss: 0.0003 | Test loss: 0.5196 | Test acc: 81.8036\n",
      "Train loss: 0.0002 | Test loss: 0.5249 | Test acc: 81.8009\n",
      "Train loss: 0.0002 | Test loss: 0.5617 | Test acc: 81.1020\n",
      "Train loss: 0.0002 | Test loss: 0.5418 | Test acc: 81.6289\n",
      "Train loss: 0.0005 | Test loss: 0.6121 | Test acc: 77.2676\n",
      "Train loss: 0.0003 | Test loss: 0.5131 | Test acc: 82.4653\n",
      "Train loss: 0.0002 | Test loss: 0.5400 | Test acc: 81.6233\n",
      "Train loss: 0.0003 | Test loss: 0.5603 | Test acc: 79.5539\n",
      "Train loss: 0.0002 | Test loss: 0.5094 | Test acc: 82.3229\n",
      "Train loss: 0.0003 | Test loss: 0.5292 | Test acc: 81.1236\n",
      "Train loss: 0.0002 | Test loss: 0.5207 | Test acc: 81.8686\n",
      "Train loss: 0.0002 | Test loss: 0.5177 | Test acc: 82.0607\n",
      "Train loss: 0.0002 | Test loss: 0.5203 | Test acc: 82.0713\n",
      "Train loss: 0.0003 | Test loss: 0.5757 | Test acc: 79.8549\n",
      "Train loss: 0.0002 | Test loss: 0.5983 | Test acc: 77.9308\n",
      "Train loss: 0.0002 | Test loss: 0.5842 | Test acc: 78.4638\n",
      "Train loss: 0.0004 | Test loss: 0.5344 | Test acc: 81.7004\n",
      "Train loss: 0.0002 | Test loss: 0.5808 | Test acc: 79.0150\n",
      "Train loss: 0.0004 | Test loss: 0.5501 | Test acc: 81.2928\n",
      "Train loss: 0.0004 | Test loss: 0.5472 | Test acc: 80.8907\n",
      "Train loss: 0.0003 | Test loss: 0.6136 | Test acc: 77.2053\n",
      "Train loss: 0.0002 | Test loss: 0.5404 | Test acc: 81.1672\n",
      "Train loss: 0.0004 | Test loss: 0.5305 | Test acc: 81.4993\n",
      "Train loss: 0.0001 | Test loss: 0.5308 | Test acc: 81.9497\n",
      "Train loss: 0.0004 | Test loss: 0.5232 | Test acc: 82.2007\n",
      "Train loss: 0.0003 | Test loss: 0.5397 | Test acc: 81.4228\n",
      "Train loss: 0.0003 | Test loss: 0.5480 | Test acc: 81.2905\n",
      "Train loss: 0.0002 | Test loss: 0.5207 | Test acc: 82.1786\n",
      "Train loss: 0.0003 | Test loss: 0.5418 | Test acc: 81.0733\n",
      "Train loss: 0.0001 | Test loss: 0.5349 | Test acc: 81.6688\n",
      "Train loss: 0.0003 | Test loss: 0.5660 | Test acc: 80.6223\n",
      "Train loss: 0.0004 | Test loss: 0.5254 | Test acc: 81.5974\n",
      "Train loss: 0.0003 | Test loss: 0.5090 | Test acc: 82.3993\n",
      "Train loss: 0.0002 | Test loss: 0.6495 | Test acc: 75.1534\n",
      "Train loss: 0.0002 | Test loss: 0.5061 | Test acc: 82.8879\n",
      "Train loss: 0.0003 | Test loss: 0.5538 | Test acc: 80.0771\n",
      "Train loss: 0.0003 | Test loss: 0.5264 | Test acc: 81.4260\n",
      "Train loss: 0.0004 | Test loss: 0.5211 | Test acc: 81.6100\n",
      "Train loss: 0.0002 | Test loss: 0.5057 | Test acc: 82.7088\n",
      "Train loss: 0.0003 | Test loss: 0.5270 | Test acc: 82.4827\n",
      "Train loss: 0.0002 | Test loss: 0.5193 | Test acc: 82.7116\n",
      "Train loss: 0.0003 | Test loss: 0.5708 | Test acc: 79.4775\n",
      "Train loss: 0.0004 | Test loss: 0.5310 | Test acc: 81.8434\n",
      "Train loss: 0.0002 | Test loss: 0.5348 | Test acc: 81.7411\n",
      "Train loss: 0.0002 | Test loss: 0.5217 | Test acc: 82.2100\n",
      "Train loss: 0.0005 | Test loss: 0.5638 | Test acc: 79.9052\n",
      "Train loss: 0.0003 | Test loss: 0.5190 | Test acc: 82.0045\n",
      "Train loss: 0.0005 | Test loss: 0.5307 | Test acc: 82.0212\n",
      "Train loss: 0.0003 | Test loss: 0.5422 | Test acc: 80.5436\n",
      "Train loss: 0.0003 | Test loss: 0.5452 | Test acc: 81.3676\n",
      "Train loss: 0.0002 | Test loss: 0.5295 | Test acc: 82.0591\n",
      "Train loss: 0.0003 | Test loss: 0.5431 | Test acc: 81.4023\n",
      "Train loss: 0.0002 | Test loss: 0.5388 | Test acc: 81.4901\n",
      "Train loss: 0.0002 | Test loss: 0.5314 | Test acc: 82.1294\n",
      "Train loss: 0.0002 | Test loss: 0.5450 | Test acc: 81.4625\n",
      "Train loss: 0.0002 | Test loss: 0.5516 | Test acc: 81.5202\n",
      "Train loss: 0.0003 | Test loss: 0.5270 | Test acc: 81.9298\n",
      "Train loss: 0.0002 | Test loss: 0.5260 | Test acc: 82.0808\n",
      "Train loss: 0.0003 | Test loss: 0.5505 | Test acc: 81.2527\n",
      "Train loss: 0.0003 | Test loss: 0.5399 | Test acc: 81.1202\n",
      "Train loss: 0.0003 | Test loss: 0.7176 | Test acc: 74.3606\n",
      "Train loss: 0.0003 | Test loss: 0.5613 | Test acc: 80.2096\n",
      "Train loss: 0.0002 | Test loss: 0.5371 | Test acc: 81.4963\n",
      "Train loss: 0.0004 | Test loss: 0.5542 | Test acc: 81.5104\n",
      "Train loss: 0.0002 | Test loss: 0.5113 | Test acc: 83.0979\n",
      "Train loss: 0.0002 | Test loss: 0.5086 | Test acc: 82.7735\n",
      "Train loss: 0.0002 | Test loss: 0.5148 | Test acc: 81.9038\n",
      "Train loss: 0.0004 | Test loss: 0.5144 | Test acc: 82.8296\n",
      "Train loss: 0.0002 | Test loss: 0.5166 | Test acc: 82.5130\n",
      "Train loss: 0.0004 | Test loss: 0.6145 | Test acc: 79.3970\n",
      "Train loss: 0.0003 | Test loss: 0.5531 | Test acc: 80.3355\n",
      "Train loss: 0.0003 | Test loss: 0.5157 | Test acc: 82.1157\n",
      "Train loss: 0.0002 | Test loss: 0.5165 | Test acc: 82.4708\n",
      "Train loss: 0.0003 | Test loss: 0.5407 | Test acc: 80.1157\n",
      "Train loss: 0.0002 | Test loss: 0.5111 | Test acc: 82.1050\n",
      "Train loss: 0.0004 | Test loss: 0.5169 | Test acc: 81.5922\n",
      "Train loss: 0.0003 | Test loss: 0.5253 | Test acc: 81.5706\n",
      "Train loss: 0.0002 | Test loss: 0.5390 | Test acc: 81.5406\n",
      "Train loss: 0.0002 | Test loss: 0.5034 | Test acc: 82.3691\n",
      "Train loss: 0.0002 | Test loss: 0.5128 | Test acc: 81.9225\n",
      "Train loss: 0.0002 | Test loss: 0.5146 | Test acc: 82.3604\n",
      "Train loss: 0.0004 | Test loss: 0.5275 | Test acc: 81.6829\n",
      "Train loss: 0.0002 | Test loss: 0.6344 | Test acc: 78.3261\n",
      "Train loss: 0.0004 | Test loss: 0.5169 | Test acc: 82.4188\n",
      "Train loss: 0.0002 | Test loss: 0.5095 | Test acc: 83.0209\n",
      "Train loss: 0.0002 | Test loss: 0.5452 | Test acc: 80.1075\n",
      "Train loss: 0.0004 | Test loss: 0.5794 | Test acc: 79.8785\n",
      "Train loss: 0.0005 | Test loss: 0.5164 | Test acc: 81.9245\n",
      "Train loss: 0.0002 | Test loss: 0.5595 | Test acc: 80.0641\n",
      "Train loss: 0.0002 | Test loss: 0.5486 | Test acc: 80.6572\n",
      "Train loss: 0.0002 | Test loss: 0.5200 | Test acc: 81.9071\n",
      "Train loss: 0.0002 | Test loss: 0.5172 | Test acc: 82.4801\n",
      "Train loss: 0.0004 | Test loss: 0.5505 | Test acc: 80.4951\n",
      "Train loss: 0.0003 | Test loss: 0.5320 | Test acc: 81.1777\n",
      "Train loss: 0.0002 | Test loss: 0.5131 | Test acc: 82.0984\n",
      "Train loss: 0.0003 | Test loss: 0.5026 | Test acc: 82.8302\n",
      "Train loss: 0.0004 | Test loss: 0.6803 | Test acc: 75.4743\n",
      "Train loss: 0.0002 | Test loss: 0.5503 | Test acc: 79.9436\n",
      "Train loss: 0.0003 | Test loss: 0.5071 | Test acc: 82.4439\n",
      "Train loss: 0.0002 | Test loss: 0.5059 | Test acc: 82.6915\n",
      "Train loss: 0.0002 | Test loss: 0.5039 | Test acc: 82.6324\n",
      "Train loss: 0.0002 | Test loss: 0.5102 | Test acc: 82.2728\n",
      "Train loss: 0.0002 | Test loss: 0.5581 | Test acc: 80.5244\n",
      "Train loss: 0.0003 | Test loss: 0.6356 | Test acc: 76.3555\n",
      "Train loss: 0.0004 | Test loss: 0.5516 | Test acc: 80.5355\n",
      "Train loss: 0.0003 | Test loss: 0.5076 | Test acc: 82.7653\n",
      "Train loss: 0.0002 | Test loss: 0.5305 | Test acc: 81.6542\n",
      "Train loss: 0.0003 | Test loss: 0.5103 | Test acc: 82.2996\n",
      "Train loss: 0.0001 | Test loss: 0.5226 | Test acc: 81.6627\n",
      "Train loss: 0.0004 | Test loss: 0.5075 | Test acc: 82.9786\n",
      "Train loss: 0.0003 | Test loss: 0.5506 | Test acc: 82.1341\n",
      "Train loss: 0.0003 | Test loss: 0.5038 | Test acc: 82.8702\n",
      "Train loss: 0.0002 | Test loss: 0.5009 | Test acc: 82.7628\n",
      "Train loss: 0.0002 | Test loss: 0.5261 | Test acc: 81.8439\n",
      "Train loss: 0.0005 | Test loss: 0.5576 | Test acc: 80.8026\n",
      "Train loss: 0.0002 | Test loss: 0.5120 | Test acc: 82.4467\n",
      "Train loss: 0.0002 | Test loss: 0.5342 | Test acc: 81.3337\n",
      "Train loss: 0.0004 | Test loss: 0.5470 | Test acc: 81.5598\n",
      "Train loss: 0.0002 | Test loss: 0.5410 | Test acc: 81.3808\n",
      "Train loss: 0.0002 | Test loss: 0.5135 | Test acc: 82.1190\n",
      "Train loss: 0.0002 | Test loss: 0.5134 | Test acc: 82.5307\n",
      "Train loss: 0.0003 | Test loss: 0.6096 | Test acc: 77.9594\n",
      "Train loss: 0.0003 | Test loss: 0.5078 | Test acc: 82.5873\n",
      "Train loss: 0.0002 | Test loss: 0.5187 | Test acc: 81.9332\n",
      "Train loss: 0.0002 | Test loss: 0.5286 | Test acc: 80.9527\n",
      "Train loss: 0.0002 | Test loss: 0.5766 | Test acc: 79.1824\n",
      "Train loss: 0.0003 | Test loss: 0.5215 | Test acc: 81.8624\n",
      "Train loss: 0.0002 | Test loss: 0.5550 | Test acc: 80.3734\n",
      "Train loss: 0.0002 | Test loss: 0.5118 | Test acc: 82.2955\n",
      "Train loss: 0.0003 | Test loss: 0.5277 | Test acc: 81.7326\n",
      "Train loss: 0.0001 | Test loss: 0.5315 | Test acc: 82.1102\n",
      "Train loss: 0.0003 | Test loss: 0.5588 | Test acc: 80.7236\n",
      "Train loss: 0.0004 | Test loss: 0.5354 | Test acc: 81.9971\n",
      "Train loss: 0.0003 | Test loss: 0.5284 | Test acc: 81.7216\n",
      "Train loss: 0.0003 | Test loss: 0.5131 | Test acc: 82.2000\n",
      "Train loss: 0.0002 | Test loss: 0.5248 | Test acc: 81.8920\n",
      "Train loss: 0.0002 | Test loss: 0.5012 | Test acc: 82.4701\n",
      "Train loss: 0.0001 | Test loss: 0.4952 | Test acc: 83.0410\n",
      "Train loss: 0.0003 | Test loss: 0.5067 | Test acc: 82.5536\n",
      "Train loss: 0.0003 | Test loss: 0.5474 | Test acc: 80.7150\n",
      "Train loss: 0.0002 | Test loss: 0.5801 | Test acc: 79.7806\n",
      "Train loss: 0.0002 | Test loss: 0.5182 | Test acc: 81.3252\n",
      "Train loss: 0.0003 | Test loss: 0.5642 | Test acc: 78.6544\n",
      "Train loss: 0.0004 | Test loss: 0.5657 | Test acc: 80.9023\n",
      "Train loss: 0.0002 | Test loss: 0.5296 | Test acc: 81.2189\n",
      "Train loss: 0.0003 | Test loss: 0.5156 | Test acc: 82.2882\n",
      "Train loss: 0.0003 | Test loss: 0.4965 | Test acc: 82.8807\n",
      "Train loss: 0.0001 | Test loss: 0.5086 | Test acc: 82.3235\n",
      "Train loss: 0.0002 | Test loss: 0.5393 | Test acc: 81.4132\n",
      "Train loss: 0.0002 | Test loss: 0.5558 | Test acc: 80.5816\n",
      "Train loss: 0.0004 | Test loss: 0.5294 | Test acc: 81.2878\n",
      "Train loss: 0.0002 | Test loss: 0.6194 | Test acc: 78.4346\n",
      "Train loss: 0.0003 | Test loss: 0.5417 | Test acc: 81.2410\n",
      "Train loss: 0.0001 | Test loss: 0.5266 | Test acc: 81.5395\n",
      "Train loss: 0.0004 | Test loss: 0.5269 | Test acc: 81.3108\n",
      "Train loss: 0.0004 | Test loss: 0.5187 | Test acc: 82.0090\n",
      "Train loss: 0.0002 | Test loss: 0.5089 | Test acc: 82.0212\n",
      "Train loss: 0.0005 | Test loss: 0.5205 | Test acc: 82.1111\n",
      "Train loss: 0.0005 | Test loss: 0.6068 | Test acc: 79.3658\n",
      "Train loss: 0.0002 | Test loss: 0.5686 | Test acc: 80.3953\n",
      "Train loss: 0.0004 | Test loss: 0.5352 | Test acc: 81.4469\n",
      "Train loss: 0.0003 | Test loss: 0.5220 | Test acc: 81.6799\n",
      "Train loss: 0.0003 | Test loss: 0.5293 | Test acc: 81.1715\n",
      "Train loss: 0.0002 | Test loss: 0.5608 | Test acc: 79.9119\n",
      "Train loss: 0.0003 | Test loss: 0.6215 | Test acc: 78.0409\n",
      "Train loss: 0.0004 | Test loss: 0.5214 | Test acc: 82.1383\n",
      "Train loss: 0.0004 | Test loss: 0.5344 | Test acc: 80.6438\n",
      "Train loss: 0.0004 | Test loss: 0.5266 | Test acc: 81.1882\n",
      "Train loss: 0.0005 | Test loss: 0.5163 | Test acc: 81.9687\n",
      "Train loss: 0.0001 | Test loss: 0.5274 | Test acc: 81.3521\n",
      "Train loss: 0.0003 | Test loss: 0.5465 | Test acc: 79.5730\n",
      "Train loss: 0.0003 | Test loss: 0.5470 | Test acc: 80.8153\n",
      "Train loss: 0.0003 | Test loss: 0.5000 | Test acc: 82.7762\n",
      "Train loss: 0.0003 | Test loss: 0.5108 | Test acc: 81.8539\n",
      "Train loss: 0.0002 | Test loss: 0.5085 | Test acc: 82.0107\n",
      "Train loss: 0.0004 | Test loss: 0.5106 | Test acc: 82.2408\n",
      "Train loss: 0.0003 | Test loss: 0.5137 | Test acc: 82.0419\n",
      "Train loss: 0.0004 | Test loss: 0.5606 | Test acc: 79.1559\n",
      "Train loss: 0.0003 | Test loss: 0.5264 | Test acc: 80.8939\n",
      "Train loss: 0.0005 | Test loss: 0.5332 | Test acc: 80.7197\n",
      "Train loss: 0.0002 | Test loss: 0.4996 | Test acc: 82.6561\n",
      "Train loss: 0.0004 | Test loss: 0.5193 | Test acc: 81.8036\n",
      "Train loss: 0.0002 | Test loss: 0.5527 | Test acc: 80.3432\n",
      "Train loss: 0.0002 | Test loss: 0.5312 | Test acc: 81.1073\n",
      "Train loss: 0.0005 | Test loss: 0.5740 | Test acc: 79.2428\n",
      "Train loss: 0.0003 | Test loss: 0.5202 | Test acc: 81.8526\n",
      "Train loss: 0.0002 | Test loss: 0.5095 | Test acc: 82.2004\n",
      "Train loss: 0.0003 | Test loss: 0.5011 | Test acc: 82.4411\n",
      "Train loss: 0.0002 | Test loss: 0.5237 | Test acc: 81.8728\n",
      "Train loss: 0.0002 | Test loss: 0.5052 | Test acc: 82.3003\n",
      "Train loss: 0.0002 | Test loss: 0.5375 | Test acc: 80.7342\n",
      "Train loss: 0.0002 | Test loss: 0.5030 | Test acc: 82.5662\n",
      "Train loss: 0.0004 | Test loss: 0.5281 | Test acc: 81.6236\n",
      "Train loss: 0.0004 | Test loss: 0.5428 | Test acc: 80.5323\n",
      "Train loss: 0.0004 | Test loss: 0.5472 | Test acc: 80.2493\n",
      "Train loss: 0.0003 | Test loss: 0.5036 | Test acc: 82.9940\n",
      "Train loss: 0.0002 | Test loss: 0.5080 | Test acc: 82.6234\n",
      "Train loss: 0.0002 | Test loss: 0.5004 | Test acc: 82.8119\n",
      "Train loss: 0.0003 | Test loss: 0.5063 | Test acc: 82.1436\n",
      "Train loss: 0.0002 | Test loss: 0.5119 | Test acc: 81.6223\n",
      "Train loss: 0.0001 | Test loss: 0.5043 | Test acc: 82.5591\n",
      "Train loss: 0.0001 | Test loss: 0.4940 | Test acc: 82.7718\n",
      "Train loss: 0.0002 | Test loss: 0.5365 | Test acc: 81.0252\n",
      "Train loss: 0.0002 | Test loss: 0.5047 | Test acc: 81.9382\n",
      "Train loss: 0.0002 | Test loss: 0.5297 | Test acc: 81.0326\n",
      "Train loss: 0.0002 | Test loss: 0.5189 | Test acc: 81.7285\n",
      "Train loss: 0.0002 | Test loss: 0.5312 | Test acc: 81.5510\n",
      "Train loss: 0.0004 | Test loss: 0.5444 | Test acc: 79.5936\n",
      "Train loss: 0.0002 | Test loss: 0.5163 | Test acc: 81.6241\n",
      "Train loss: 0.0003 | Test loss: 0.5417 | Test acc: 81.1314\n",
      "Train loss: 0.0003 | Test loss: 0.5096 | Test acc: 82.1981\n",
      "Train loss: 0.0002 | Test loss: 0.6610 | Test acc: 76.8201\n",
      "Train loss: 0.0003 | Test loss: 0.5206 | Test acc: 81.5953\n",
      "Train loss: 0.0003 | Test loss: 0.5564 | Test acc: 81.1712\n",
      "Train loss: 0.0002 | Test loss: 0.5071 | Test acc: 82.3979\n",
      "Train loss: 0.0002 | Test loss: 0.5189 | Test acc: 81.7329\n",
      "Train loss: 0.0003 | Test loss: 0.5101 | Test acc: 82.4297\n",
      "Train loss: 0.0003 | Test loss: 0.5362 | Test acc: 81.3935\n",
      "Train loss: 0.0002 | Test loss: 0.5411 | Test acc: 81.5001\n",
      "Train loss: 0.0002 | Test loss: 0.5194 | Test acc: 81.9497\n",
      "Train loss: 0.0001 | Test loss: 0.5151 | Test acc: 82.4104\n",
      "Train loss: 0.0003 | Test loss: 0.5151 | Test acc: 82.2222\n",
      "Train loss: 0.0003 | Test loss: 0.5313 | Test acc: 80.6041\n",
      "Train loss: 0.0003 | Test loss: 0.5051 | Test acc: 82.6557\n",
      "Train loss: 0.0002 | Test loss: 0.5100 | Test acc: 82.2529\n",
      "Train loss: 0.0002 | Test loss: 0.5194 | Test acc: 81.9022\n",
      "Train loss: 0.0002 | Test loss: 0.4981 | Test acc: 82.8296\n",
      "Train loss: 0.0002 | Test loss: 0.4968 | Test acc: 82.7626\n",
      "Train loss: 0.0002 | Test loss: 0.5022 | Test acc: 82.5028\n",
      "Train loss: 0.0003 | Test loss: 0.5467 | Test acc: 79.6566\n",
      "Train loss: 0.0002 | Test loss: 0.5257 | Test acc: 81.7741\n",
      "Train loss: 0.0003 | Test loss: 0.5119 | Test acc: 82.2800\n",
      "Looked at 51200 / 60000 samples\n",
      "Train loss: 0.0002 | Test loss: 0.5096 | Test acc: 82.1219\n",
      "Train loss: 0.0001 | Test loss: 0.4988 | Test acc: 82.3910\n",
      "Train loss: 0.0002 | Test loss: 0.5136 | Test acc: 81.5632\n",
      "Train loss: 0.0005 | Test loss: 0.5032 | Test acc: 82.7187\n",
      "Train loss: 0.0004 | Test loss: 0.5305 | Test acc: 80.8154\n",
      "Train loss: 0.0002 | Test loss: 0.5096 | Test acc: 82.5066\n",
      "Train loss: 0.0003 | Test loss: 0.6159 | Test acc: 79.8263\n",
      "Train loss: 0.0002 | Test loss: 0.5193 | Test acc: 82.1839\n",
      "Train loss: 0.0001 | Test loss: 0.5344 | Test acc: 81.0633\n",
      "Train loss: 0.0005 | Test loss: 0.5397 | Test acc: 80.9798\n",
      "Train loss: 0.0001 | Test loss: 0.5293 | Test acc: 81.2891\n",
      "Train loss: 0.0002 | Test loss: 0.5284 | Test acc: 81.3799\n",
      "Train loss: 0.0004 | Test loss: 0.7064 | Test acc: 73.4928\n",
      "Train loss: 0.0004 | Test loss: 0.5570 | Test acc: 79.8275\n",
      "Train loss: 0.0003 | Test loss: 0.5544 | Test acc: 80.5366\n",
      "Train loss: 0.0003 | Test loss: 0.4921 | Test acc: 82.8651\n",
      "Train loss: 0.0003 | Test loss: 0.5609 | Test acc: 79.4481\n",
      "Train loss: 0.0005 | Test loss: 0.6019 | Test acc: 79.7167\n",
      "Train loss: 0.0002 | Test loss: 0.5993 | Test acc: 79.5478\n",
      "Train loss: 0.0003 | Test loss: 0.5331 | Test acc: 81.5641\n",
      "Train loss: 0.0001 | Test loss: 0.5419 | Test acc: 81.3708\n",
      "Train loss: 0.0003 | Test loss: 0.4970 | Test acc: 82.6082\n",
      "Train loss: 0.0004 | Test loss: 0.5186 | Test acc: 81.8434\n",
      "Train loss: 0.0003 | Test loss: 0.6273 | Test acc: 76.1800\n",
      "Train loss: 0.0004 | Test loss: 0.5164 | Test acc: 81.9327\n",
      "Train loss: 0.0002 | Test loss: 0.4967 | Test acc: 82.8896\n",
      "Train loss: 0.0004 | Test loss: 0.5449 | Test acc: 80.8659\n",
      "Train loss: 0.0002 | Test loss: 0.5291 | Test acc: 81.7679\n",
      "Train loss: 0.0003 | Test loss: 0.5261 | Test acc: 81.7309\n",
      "Train loss: 0.0005 | Test loss: 0.5477 | Test acc: 79.8638\n",
      "Train loss: 0.0004 | Test loss: 0.5559 | Test acc: 81.9245\n",
      "Train loss: 0.0003 | Test loss: 0.5445 | Test acc: 81.3121\n",
      "Train loss: 0.0002 | Test loss: 0.5262 | Test acc: 82.0389\n",
      "Train loss: 0.0002 | Test loss: 0.5070 | Test acc: 82.3807\n",
      "Train loss: 0.0002 | Test loss: 0.4975 | Test acc: 82.6414\n",
      "Train loss: 0.0002 | Test loss: 0.5146 | Test acc: 81.8535\n",
      "Train loss: 0.0002 | Test loss: 0.5695 | Test acc: 80.6729\n",
      "Train loss: 0.0002 | Test loss: 0.5006 | Test acc: 83.0453\n",
      "Train loss: 0.0002 | Test loss: 0.5381 | Test acc: 81.3356\n",
      "Train loss: 0.0002 | Test loss: 0.5239 | Test acc: 81.0706\n",
      "Train loss: 0.0001 | Test loss: 0.5121 | Test acc: 82.2678\n",
      "Train loss: 0.0003 | Test loss: 0.6268 | Test acc: 76.1314\n",
      "Train loss: 0.0002 | Test loss: 0.5620 | Test acc: 79.7061\n",
      "Train loss: 0.0002 | Test loss: 0.5020 | Test acc: 82.7127\n",
      "Train loss: 0.0003 | Test loss: 0.5079 | Test acc: 82.5925\n",
      "Train loss: 0.0002 | Test loss: 0.5078 | Test acc: 82.9216\n",
      "Train loss: 0.0002 | Test loss: 0.5435 | Test acc: 79.8775\n",
      "Train loss: 0.0003 | Test loss: 0.4996 | Test acc: 82.6034\n",
      "Train loss: 0.0001 | Test loss: 0.4988 | Test acc: 82.6621\n",
      "Train loss: 0.0006 | Test loss: 0.5630 | Test acc: 79.8168\n",
      "Train loss: 0.0002 | Test loss: 0.5275 | Test acc: 81.5050\n",
      "Train loss: 0.0002 | Test loss: 0.5411 | Test acc: 79.9729\n",
      "Train loss: 0.0003 | Test loss: 0.5328 | Test acc: 81.1261\n",
      "Train loss: 0.0005 | Test loss: 0.5594 | Test acc: 78.9633\n",
      "Train loss: 0.0002 | Test loss: 0.5055 | Test acc: 82.3709\n",
      "Train loss: 0.0003 | Test loss: 0.5616 | Test acc: 79.0471\n",
      "Train loss: 0.0003 | Test loss: 0.5780 | Test acc: 80.1347\n",
      "Train loss: 0.0003 | Test loss: 0.5374 | Test acc: 80.9569\n",
      "Train loss: 0.0001 | Test loss: 0.5213 | Test acc: 82.2974\n",
      "Train loss: 0.0005 | Test loss: 0.5241 | Test acc: 82.0321\n",
      "Train loss: 0.0004 | Test loss: 0.5280 | Test acc: 81.2625\n",
      "Train loss: 0.0003 | Test loss: 0.5320 | Test acc: 81.1003\n",
      "Train loss: 0.0003 | Test loss: 0.5015 | Test acc: 82.7671\n",
      "Train loss: 0.0003 | Test loss: 0.5064 | Test acc: 82.4230\n",
      "Train loss: 0.0003 | Test loss: 0.5346 | Test acc: 80.8744\n",
      "Train loss: 0.0002 | Test loss: 0.5103 | Test acc: 82.2672\n",
      "Train loss: 0.0002 | Test loss: 0.5537 | Test acc: 80.5943\n",
      "Train loss: 0.0003 | Test loss: 0.5211 | Test acc: 81.7970\n",
      "Train loss: 0.0002 | Test loss: 0.5355 | Test acc: 81.0421\n",
      "Train loss: 0.0002 | Test loss: 0.5392 | Test acc: 81.1894\n",
      "Train loss: 0.0002 | Test loss: 0.5751 | Test acc: 79.0733\n",
      "Train loss: 0.0004 | Test loss: 0.5469 | Test acc: 80.4044\n",
      "Train loss: 0.0002 | Test loss: 0.5618 | Test acc: 79.1007\n",
      "Train loss: 0.0003 | Test loss: 0.5148 | Test acc: 81.3729\n",
      "Train loss: 0.0004 | Test loss: 0.5075 | Test acc: 82.5783\n",
      "Train loss: 0.0002 | Test loss: 0.5124 | Test acc: 81.9831\n",
      "Train loss: 0.0003 | Test loss: 0.5122 | Test acc: 82.1110\n",
      "Train loss: 0.0003 | Test loss: 0.5098 | Test acc: 82.4508\n",
      "Train loss: 0.0004 | Test loss: 0.4975 | Test acc: 82.9212\n",
      "Train loss: 0.0003 | Test loss: 0.5368 | Test acc: 81.1355\n",
      "Train loss: 0.0002 | Test loss: 0.5367 | Test acc: 81.1698\n",
      "Train loss: 0.0004 | Test loss: 0.5987 | Test acc: 80.2913\n",
      "Train loss: 0.0004 | Test loss: 0.5917 | Test acc: 79.9889\n",
      "Train loss: 0.0002 | Test loss: 0.5476 | Test acc: 81.5355\n",
      "Train loss: 0.0002 | Test loss: 0.5370 | Test acc: 81.9398\n",
      "Train loss: 0.0003 | Test loss: 0.4979 | Test acc: 82.6999\n",
      "Train loss: 0.0003 | Test loss: 0.5295 | Test acc: 81.4743\n",
      "Train loss: 0.0003 | Test loss: 0.5022 | Test acc: 83.3274\n",
      "Train loss: 0.0004 | Test loss: 0.5602 | Test acc: 80.7275\n",
      "Train loss: 0.0003 | Test loss: 0.5013 | Test acc: 82.5163\n",
      "Train loss: 0.0003 | Test loss: 0.5123 | Test acc: 82.1925\n",
      "Train loss: 0.0003 | Test loss: 0.5159 | Test acc: 81.9719\n",
      "Train loss: 0.0002 | Test loss: 0.5049 | Test acc: 82.0111\n",
      "Train loss: 0.0002 | Test loss: 0.4910 | Test acc: 82.8798\n",
      "Train loss: 0.0003 | Test loss: 0.5251 | Test acc: 82.2336\n",
      "Train loss: 0.0004 | Test loss: 0.5586 | Test acc: 81.0634\n",
      "Train loss: 0.0002 | Test loss: 0.5243 | Test acc: 82.2179\n",
      "Train loss: 0.0002 | Test loss: 0.5372 | Test acc: 81.7822\n",
      "Train loss: 0.0002 | Test loss: 0.5049 | Test acc: 82.7293\n",
      "Train loss: 0.0002 | Test loss: 0.5297 | Test acc: 81.2248\n",
      "Train loss: 0.0003 | Test loss: 0.5209 | Test acc: 82.2583\n",
      "Train loss: 0.0003 | Test loss: 0.4984 | Test acc: 82.8307\n",
      "Train loss: 0.0002 | Test loss: 0.5065 | Test acc: 82.1536\n",
      "Train loss: 0.0002 | Test loss: 0.5278 | Test acc: 81.2329\n",
      "Train loss: 0.0002 | Test loss: 0.5313 | Test acc: 81.7891\n",
      "Train loss: 0.0001 | Test loss: 0.5114 | Test acc: 82.7094\n",
      "Train loss: 0.0003 | Test loss: 0.5084 | Test acc: 82.6624\n",
      "Train loss: 0.0002 | Test loss: 0.5267 | Test acc: 82.0632\n",
      "Train loss: 0.0002 | Test loss: 0.5087 | Test acc: 82.6204\n",
      "Train loss: 0.0003 | Test loss: 0.6000 | Test acc: 77.0411\n",
      "Train loss: 0.0004 | Test loss: 0.5672 | Test acc: 79.8388\n",
      "Train loss: 0.0001 | Test loss: 0.5291 | Test acc: 81.5051\n",
      "Train loss: 0.0002 | Test loss: 0.5135 | Test acc: 82.1494\n",
      "Train loss: 0.0001 | Test loss: 0.5129 | Test acc: 82.3711\n",
      "Train loss: 0.0003 | Test loss: 0.5117 | Test acc: 82.3219\n",
      "Train loss: 0.0001 | Test loss: 0.5418 | Test acc: 81.1436\n",
      "Train loss: 0.0002 | Test loss: 0.5204 | Test acc: 81.9685\n",
      "Train loss: 0.0003 | Test loss: 0.6006 | Test acc: 79.7048\n",
      "Train loss: 0.0003 | Test loss: 0.6267 | Test acc: 79.5877\n",
      "Train loss: 0.0001 | Test loss: 0.6181 | Test acc: 79.7371\n",
      "Train loss: 0.0002 | Test loss: 0.5865 | Test acc: 80.1769\n",
      "Train loss: 0.0002 | Test loss: 0.5318 | Test acc: 81.7458\n",
      "Train loss: 0.0003 | Test loss: 0.5175 | Test acc: 81.4513\n",
      "Train loss: 0.0002 | Test loss: 0.5204 | Test acc: 81.9895\n",
      "Train loss: 0.0002 | Test loss: 0.5588 | Test acc: 79.7548\n",
      "Train loss: 0.0002 | Test loss: 0.4970 | Test acc: 82.6530\n",
      "Train loss: 0.0004 | Test loss: 0.5223 | Test acc: 82.2229\n",
      "Train loss: 0.0003 | Test loss: 0.5038 | Test acc: 82.5111\n",
      "Train loss: 0.0005 | Test loss: 0.5218 | Test acc: 80.9845\n",
      "Train loss: 0.0002 | Test loss: 0.5339 | Test acc: 80.8198\n",
      "Train loss: 0.0003 | Test loss: 0.5055 | Test acc: 82.7562\n",
      "Train loss: 0.0002 | Test loss: 0.5248 | Test acc: 82.0036\n",
      "Train loss: 0.0002 | Test loss: 0.5631 | Test acc: 81.0228\n",
      "Train loss: 0.0002 | Test loss: 0.5369 | Test acc: 81.6087\n",
      "Train loss: 0.0003 | Test loss: 0.5079 | Test acc: 82.4991\n",
      "Train loss: 0.0002 | Test loss: 0.5158 | Test acc: 81.7133\n",
      "Train loss: 0.0002 | Test loss: 0.5061 | Test acc: 82.0602\n",
      "Train loss: 0.0003 | Test loss: 0.5193 | Test acc: 81.7418\n",
      "Train loss: 0.0002 | Test loss: 0.5337 | Test acc: 81.0519\n",
      "Train loss: 0.0003 | Test loss: 0.5747 | Test acc: 79.7817\n",
      "Train loss: 0.0002 | Test loss: 0.6396 | Test acc: 75.7840\n",
      "Train loss: 0.0004 | Test loss: 0.4963 | Test acc: 82.8999\n",
      "Train loss: 0.0003 | Test loss: 0.5195 | Test acc: 81.5748\n",
      "Train loss: 0.0003 | Test loss: 0.5721 | Test acc: 79.3641\n",
      "Train loss: 0.0003 | Test loss: 0.5296 | Test acc: 80.9944\n",
      "Train loss: 0.0003 | Test loss: 0.5455 | Test acc: 81.1793\n",
      "Train loss: 0.0001 | Test loss: 0.5712 | Test acc: 80.4111\n",
      "Train loss: 0.0002 | Test loss: 0.5865 | Test acc: 80.0992\n",
      "Train loss: 0.0004 | Test loss: 0.5055 | Test acc: 81.6157\n",
      "Train loss: 0.0003 | Test loss: 0.5146 | Test acc: 81.8003\n",
      "Train loss: 0.0001 | Test loss: 0.5205 | Test acc: 81.6611\n",
      "Train loss: 0.0002 | Test loss: 0.5131 | Test acc: 81.4610\n",
      "Train loss: 0.0002 | Test loss: 0.5531 | Test acc: 79.9827\n",
      "Train loss: 0.0003 | Test loss: 0.5275 | Test acc: 81.8350\n",
      "Train loss: 0.0001 | Test loss: 0.5386 | Test acc: 81.8010\n",
      "Train loss: 0.0005 | Test loss: 0.5190 | Test acc: 82.1903\n",
      "Train loss: 0.0004 | Test loss: 0.5744 | Test acc: 80.6340\n",
      "Train loss: 0.0002 | Test loss: 0.5642 | Test acc: 80.9186\n",
      "Train loss: 0.0002 | Test loss: 0.5439 | Test acc: 80.9594\n",
      "Train loss: 0.0002 | Test loss: 0.4986 | Test acc: 82.9364\n",
      "Train loss: 0.0001 | Test loss: 0.5392 | Test acc: 81.3652\n",
      "Train loss: 0.0003 | Test loss: 0.5315 | Test acc: 82.1889\n",
      "Train loss: 0.0003 | Test loss: 0.6193 | Test acc: 77.8884\n",
      "Train loss: 0.0002 | Test loss: 0.5304 | Test acc: 81.5288\n",
      "Train loss: 0.0004 | Test loss: 0.5846 | Test acc: 78.3156\n",
      "Train loss: 0.0002 | Test loss: 0.6021 | Test acc: 77.5765\n",
      "Train loss: 0.0002 | Test loss: 0.5388 | Test acc: 80.8888\n",
      "Train loss: 0.0002 | Test loss: 0.5097 | Test acc: 82.3671\n",
      "Train loss: 0.0002 | Test loss: 0.5331 | Test acc: 81.3334\n",
      "Train loss: 0.0003 | Test loss: 0.5468 | Test acc: 81.3202\n",
      "Train loss: 0.0002 | Test loss: 0.5379 | Test acc: 80.8708\n",
      "Train loss: 0.0004 | Test loss: 0.5622 | Test acc: 79.2520\n",
      "Train loss: 0.0002 | Test loss: 0.5285 | Test acc: 81.3834\n",
      "Train loss: 0.0003 | Test loss: 0.5289 | Test acc: 82.2888\n",
      "Train loss: 0.0002 | Test loss: 0.5363 | Test acc: 81.8524\n",
      "Train loss: 0.0003 | Test loss: 0.5302 | Test acc: 81.5015\n",
      "Train loss: 0.0003 | Test loss: 0.5426 | Test acc: 81.2109\n",
      "Train loss: 0.0004 | Test loss: 0.5644 | Test acc: 80.7107\n",
      "Train loss: 0.0001 | Test loss: 0.5523 | Test acc: 80.6792\n",
      "Train loss: 0.0002 | Test loss: 0.5011 | Test acc: 82.7757\n",
      "Train loss: 0.0001 | Test loss: 0.4999 | Test acc: 82.7724\n",
      "Train loss: 0.0002 | Test loss: 0.5099 | Test acc: 82.3331\n",
      "Train loss: 0.0002 | Test loss: 0.5376 | Test acc: 80.5246\n",
      "Train loss: 0.0002 | Test loss: 0.5175 | Test acc: 81.9765\n",
      "Train loss: 0.0001 | Test loss: 0.4918 | Test acc: 83.2491\n",
      "Train loss: 0.0002 | Test loss: 0.5163 | Test acc: 82.4445\n",
      "Train loss: 0.0002 | Test loss: 0.5165 | Test acc: 82.2822\n",
      "Train loss: 0.0003 | Test loss: 0.5271 | Test acc: 82.2517\n",
      "Train loss: 0.0002 | Test loss: 0.5247 | Test acc: 81.5627\n",
      "Train loss: 0.0004 | Test loss: 0.5527 | Test acc: 80.9415\n",
      "Train loss: 0.0002 | Test loss: 0.5417 | Test acc: 81.5585\n",
      "Train loss: 0.0003 | Test loss: 0.5202 | Test acc: 82.0098\n",
      "Train loss: 0.0002 | Test loss: 0.5868 | Test acc: 79.0959\n",
      "Train loss: 0.0002 | Test loss: 0.5114 | Test acc: 82.0818\n",
      "Train loss: 0.0002 | Test loss: 0.5233 | Test acc: 81.8717\n",
      "Train loss: 0.0004 | Test loss: 0.5488 | Test acc: 81.3718\n",
      "Train loss: 0.0004 | Test loss: 0.5433 | Test acc: 81.0807\n",
      "Train loss: 0.0003 | Test loss: 0.6001 | Test acc: 77.6253\n",
      "Train loss: 0.0003 | Test loss: 0.5054 | Test acc: 82.2768\n",
      "Train loss: 0.0002 | Test loss: 0.5001 | Test acc: 82.6411\n",
      "Train loss: 0.0003 | Test loss: 0.5399 | Test acc: 81.8735\n",
      "Train loss: 0.0003 | Test loss: 0.5610 | Test acc: 80.1238\n",
      "Train loss: 0.0002 | Test loss: 0.5341 | Test acc: 81.5060\n",
      "Train loss: 0.0003 | Test loss: 0.5562 | Test acc: 81.3007\n",
      "Train loss: 0.0003 | Test loss: 0.5113 | Test acc: 82.0589\n",
      "Train loss: 0.0001 | Test loss: 0.5028 | Test acc: 82.7003\n",
      "Train loss: 0.0002 | Test loss: 0.4995 | Test acc: 82.7023\n",
      "Train loss: 0.0002 | Test loss: 0.5687 | Test acc: 80.1165\n",
      "Train loss: 0.0003 | Test loss: 0.5001 | Test acc: 82.6441\n",
      "Train loss: 0.0001 | Test loss: 0.5006 | Test acc: 82.6223\n",
      "Train loss: 0.0002 | Test loss: 0.5118 | Test acc: 81.8934\n",
      "Train loss: 0.0002 | Test loss: 0.4961 | Test acc: 83.0691\n",
      "Train loss: 0.0002 | Test loss: 0.4901 | Test acc: 83.1528\n",
      "Train loss: 0.0002 | Test loss: 0.5062 | Test acc: 82.6838\n",
      "Train loss: 0.0002 | Test loss: 0.5166 | Test acc: 82.1631\n",
      "Train loss: 0.0002 | Test loss: 0.5406 | Test acc: 81.2130\n",
      "Train loss: 0.0003 | Test loss: 0.5520 | Test acc: 80.7207\n",
      "Train loss: 0.0003 | Test loss: 0.5517 | Test acc: 81.4180\n",
      "Train loss: 0.0003 | Test loss: 0.5379 | Test acc: 81.6299\n",
      "Train loss: 0.0002 | Test loss: 0.5184 | Test acc: 81.9501\n",
      "Train loss: 0.0002 | Test loss: 0.5408 | Test acc: 81.4319\n",
      "Train loss: 0.0001 | Test loss: 0.5548 | Test acc: 80.0126\n",
      "Train loss: 0.0003 | Test loss: 0.5299 | Test acc: 81.3459\n",
      "Train loss: 0.0004 | Test loss: 0.6145 | Test acc: 78.6944\n",
      "Train loss: 0.0004 | Test loss: 0.5135 | Test acc: 82.2602\n",
      "Train loss: 0.0002 | Test loss: 0.5201 | Test acc: 81.7125\n",
      "Train loss: 0.0002 | Test loss: 0.5002 | Test acc: 82.8589\n",
      "Train loss: 0.0005 | Test loss: 0.5207 | Test acc: 82.7228\n",
      "Train loss: 0.0003 | Test loss: 0.5046 | Test acc: 82.4628\n",
      "Train loss: 0.0002 | Test loss: 0.4970 | Test acc: 83.0210\n",
      "Train loss: 0.0003 | Test loss: 0.5552 | Test acc: 79.6782\n",
      "Train loss: 0.0004 | Test loss: 0.5349 | Test acc: 81.9838\n",
      "Train loss: 0.0005 | Test loss: 0.5349 | Test acc: 81.8414\n",
      "Train loss: 0.0002 | Test loss: 0.5299 | Test acc: 81.8609\n",
      "Train loss: 0.0002 | Test loss: 0.5443 | Test acc: 81.3318\n",
      "Train loss: 0.0003 | Test loss: 0.5031 | Test acc: 82.5682\n",
      "Train loss: 0.0002 | Test loss: 0.5094 | Test acc: 81.9830\n",
      "Train loss: 0.0002 | Test loss: 0.5436 | Test acc: 80.1541\n",
      "Train loss: 0.0002 | Test loss: 0.5049 | Test acc: 82.6043\n",
      "Train loss: 0.0003 | Test loss: 0.5672 | Test acc: 78.7084\n",
      "Train loss: 0.0003 | Test loss: 0.4925 | Test acc: 82.8094\n",
      "Train loss: 0.0002 | Test loss: 0.5564 | Test acc: 80.5960\n",
      "Train loss: 0.0002 | Test loss: 0.5211 | Test acc: 81.8370\n",
      "Train loss: 0.0002 | Test loss: 0.5360 | Test acc: 81.0023\n",
      "Train loss: 0.0002 | Test loss: 0.5079 | Test acc: 82.2276\n",
      "Train loss: 0.0001 | Test loss: 0.5146 | Test acc: 82.0219\n",
      "Train loss: 0.0002 | Test loss: 0.4957 | Test acc: 83.0795\n",
      "Train loss: 0.0003 | Test loss: 0.5200 | Test acc: 82.1943\n",
      "Train loss: 0.0003 | Test loss: 0.5101 | Test acc: 82.4711\n",
      "Train loss: 0.0002 | Test loss: 0.5296 | Test acc: 81.6333\n",
      "Train loss: 0.0003 | Test loss: 0.4990 | Test acc: 82.6190\n",
      "Train loss: 0.0002 | Test loss: 0.5227 | Test acc: 81.1945\n",
      "Train loss: 0.0002 | Test loss: 0.4879 | Test acc: 83.1168\n",
      "Train loss: 0.0003 | Test loss: 0.5323 | Test acc: 81.5155\n",
      "Train loss: 0.0002 | Test loss: 0.5321 | Test acc: 81.1310\n",
      "Train loss: 0.0002 | Test loss: 0.5273 | Test acc: 81.4892\n",
      "Train loss: 0.0002 | Test loss: 0.5399 | Test acc: 80.7715\n",
      "Train loss: 0.0002 | Test loss: 0.5651 | Test acc: 80.5795\n",
      "Train loss: 0.0003 | Test loss: 0.5230 | Test acc: 82.1464\n",
      "Train loss: 0.0001 | Test loss: 0.5015 | Test acc: 82.6606\n",
      "Train loss: 0.0003 | Test loss: 0.5230 | Test acc: 81.7138\n",
      "Train loss: 0.0005 | Test loss: 0.5281 | Test acc: 81.4212\n",
      "Train loss: 0.0002 | Test loss: 0.5353 | Test acc: 81.5601\n",
      "Train loss: 0.0003 | Test loss: 0.5114 | Test acc: 82.7087\n",
      "Train loss: 0.0003 | Test loss: 0.6403 | Test acc: 79.0881\n",
      "Train loss: 0.0005 | Test loss: 0.5230 | Test acc: 81.5526\n",
      "Train loss: 0.0004 | Test loss: 0.5071 | Test acc: 82.5788\n",
      "Train loss: 0.0001 | Test loss: 0.5023 | Test acc: 83.0014\n",
      "Train loss: 0.0002 | Test loss: 0.4978 | Test acc: 82.8231\n",
      "Train loss: 0.0004 | Test loss: 0.5137 | Test acc: 82.5230\n",
      "Train loss: 0.0004 | Test loss: 0.5206 | Test acc: 81.3938\n",
      "Train loss: 0.0002 | Test loss: 0.4939 | Test acc: 83.2073\n",
      "Train loss: 0.0005 | Test loss: 0.5247 | Test acc: 82.0650\n",
      "Train loss: 0.0003 | Test loss: 0.5622 | Test acc: 81.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|                                                                                            | 1/3 [28:42<57:25, 1722.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0002 | Test loss: 0.5106 | Test acc: 82.3375\n",
      "Train time on cpu: 1722.57 seconds\n",
      "Epoch: 1\n",
      "-----\n",
      "Looked at 0 / 60000 samples\n",
      "Train loss: 0.0002 | Test loss: 0.5118 | Test acc: 82.2983\n",
      "Train loss: 0.0002 | Test loss: 0.5203 | Test acc: 81.7625\n",
      "Train loss: 0.0001 | Test loss: 0.5073 | Test acc: 82.6694\n",
      "Train loss: 0.0003 | Test loss: 0.5072 | Test acc: 82.8021\n",
      "Train loss: 0.0003 | Test loss: 0.5374 | Test acc: 81.3149\n",
      "Train loss: 0.0003 | Test loss: 0.6277 | Test acc: 77.8956\n",
      "Train loss: 0.0003 | Test loss: 0.5363 | Test acc: 81.0596\n",
      "Train loss: 0.0003 | Test loss: 0.6095 | Test acc: 77.1659\n",
      "Train loss: 0.0003 | Test loss: 0.5443 | Test acc: 81.1072\n",
      "Train loss: 0.0003 | Test loss: 0.5588 | Test acc: 81.2096\n",
      "Train loss: 0.0003 | Test loss: 0.5495 | Test acc: 80.8106\n",
      "Train loss: 0.0002 | Test loss: 0.4985 | Test acc: 82.8261\n",
      "Train loss: 0.0002 | Test loss: 0.5088 | Test acc: 82.5729\n",
      "Train loss: 0.0003 | Test loss: 0.5145 | Test acc: 82.2726\n",
      "Train loss: 0.0003 | Test loss: 0.5329 | Test acc: 81.2033\n",
      "Train loss: 0.0004 | Test loss: 0.5541 | Test acc: 80.6808\n",
      "Train loss: 0.0004 | Test loss: 0.5175 | Test acc: 82.2166\n",
      "Train loss: 0.0002 | Test loss: 0.5125 | Test acc: 82.4013\n",
      "Train loss: 0.0001 | Test loss: 0.5246 | Test acc: 82.2521\n",
      "Train loss: 0.0002 | Test loss: 0.5390 | Test acc: 82.1817\n",
      "Train loss: 0.0002 | Test loss: 0.5046 | Test acc: 82.8804\n",
      "Train loss: 0.0002 | Test loss: 0.5001 | Test acc: 82.9525\n",
      "Train loss: 0.0003 | Test loss: 0.5143 | Test acc: 82.8329\n",
      "Train loss: 0.0005 | Test loss: 0.5543 | Test acc: 80.1968\n",
      "Train loss: 0.0003 | Test loss: 0.4980 | Test acc: 83.0937\n",
      "Train loss: 0.0002 | Test loss: 0.5087 | Test acc: 83.0031\n",
      "Train loss: 0.0002 | Test loss: 0.5053 | Test acc: 82.2939\n",
      "Train loss: 0.0002 | Test loss: 0.5316 | Test acc: 81.2334\n",
      "Train loss: 0.0002 | Test loss: 0.5274 | Test acc: 81.6793\n",
      "Train loss: 0.0002 | Test loss: 0.5210 | Test acc: 82.0501\n",
      "Train loss: 0.0003 | Test loss: 0.5125 | Test acc: 82.0313\n",
      "Train loss: 0.0003 | Test loss: 0.5251 | Test acc: 81.7417\n",
      "Train loss: 0.0002 | Test loss: 0.5286 | Test acc: 81.5611\n",
      "Train loss: 0.0002 | Test loss: 0.5279 | Test acc: 81.4207\n",
      "Train loss: 0.0002 | Test loss: 0.5348 | Test acc: 81.5401\n",
      "Train loss: 0.0003 | Test loss: 0.5253 | Test acc: 81.5205\n",
      "Train loss: 0.0003 | Test loss: 0.5273 | Test acc: 81.2808\n",
      "Train loss: 0.0002 | Test loss: 0.5164 | Test acc: 81.8991\n",
      "Train loss: 0.0002 | Test loss: 0.5308 | Test acc: 81.8411\n",
      "Train loss: 0.0003 | Test loss: 0.5261 | Test acc: 81.9608\n",
      "Train loss: 0.0004 | Test loss: 0.5628 | Test acc: 79.4751\n",
      "Train loss: 0.0003 | Test loss: 0.5405 | Test acc: 81.1245\n",
      "Train loss: 0.0002 | Test loss: 0.5325 | Test acc: 81.1498\n",
      "Train loss: 0.0003 | Test loss: 0.4959 | Test acc: 82.7772\n",
      "Train loss: 0.0002 | Test loss: 0.4946 | Test acc: 82.9921\n",
      "Train loss: 0.0004 | Test loss: 0.5203 | Test acc: 81.8247\n",
      "Train loss: 0.0002 | Test loss: 0.5244 | Test acc: 81.4815\n",
      "Train loss: 0.0005 | Test loss: 0.5807 | Test acc: 79.2140\n",
      "Train loss: 0.0004 | Test loss: 0.5150 | Test acc: 82.8310\n",
      "Train loss: 0.0004 | Test loss: 0.4947 | Test acc: 83.2718\n",
      "Train loss: 0.0002 | Test loss: 0.4991 | Test acc: 82.5644\n",
      "Train loss: 0.0001 | Test loss: 0.5224 | Test acc: 81.7434\n",
      "Train loss: 0.0002 | Test loss: 0.5086 | Test acc: 82.2999\n",
      "Train loss: 0.0003 | Test loss: 0.5089 | Test acc: 82.7110\n",
      "Train loss: 0.0002 | Test loss: 0.5127 | Test acc: 82.4428\n",
      "Train loss: 0.0003 | Test loss: 0.5124 | Test acc: 82.9711\n",
      "Train loss: 0.0004 | Test loss: 0.5848 | Test acc: 80.1073\n",
      "Train loss: 0.0003 | Test loss: 0.5947 | Test acc: 78.4309\n",
      "Train loss: 0.0003 | Test loss: 0.5611 | Test acc: 79.2442\n",
      "Train loss: 0.0002 | Test loss: 0.5367 | Test acc: 80.5347\n",
      "Train loss: 0.0002 | Test loss: 0.4940 | Test acc: 83.0149\n",
      "Train loss: 0.0002 | Test loss: 0.4974 | Test acc: 82.8830\n",
      "Train loss: 0.0003 | Test loss: 0.5319 | Test acc: 81.7145\n",
      "Train loss: 0.0002 | Test loss: 0.5102 | Test acc: 82.4296\n",
      "Train loss: 0.0004 | Test loss: 0.5468 | Test acc: 80.8544\n",
      "Train loss: 0.0002 | Test loss: 0.5104 | Test acc: 82.5666\n",
      "Train loss: 0.0002 | Test loss: 0.5085 | Test acc: 82.8317\n",
      "Train loss: 0.0002 | Test loss: 0.4938 | Test acc: 83.1221\n",
      "Train loss: 0.0002 | Test loss: 0.5678 | Test acc: 80.9165\n",
      "Train loss: 0.0004 | Test loss: 0.5218 | Test acc: 81.6183\n",
      "Train loss: 0.0002 | Test loss: 0.5210 | Test acc: 81.7803\n",
      "Train loss: 0.0003 | Test loss: 0.5256 | Test acc: 82.1503\n",
      "Train loss: 0.0002 | Test loss: 0.5251 | Test acc: 82.2113\n",
      "Train loss: 0.0001 | Test loss: 0.5104 | Test acc: 82.6109\n",
      "Train loss: 0.0002 | Test loss: 0.5307 | Test acc: 82.5423\n",
      "Train loss: 0.0003 | Test loss: 0.5224 | Test acc: 82.4123\n",
      "Train loss: 0.0002 | Test loss: 0.5131 | Test acc: 82.7114\n",
      "Train loss: 0.0003 | Test loss: 0.6677 | Test acc: 76.7219\n",
      "Train loss: 0.0004 | Test loss: 0.5550 | Test acc: 80.9759\n",
      "Train loss: 0.0002 | Test loss: 0.5456 | Test acc: 80.9197\n",
      "Train loss: 0.0003 | Test loss: 0.4849 | Test acc: 83.2557\n",
      "Train loss: 0.0001 | Test loss: 0.4856 | Test acc: 83.3531\n",
      "Train loss: 0.0002 | Test loss: 0.5084 | Test acc: 82.2252\n",
      "Train loss: 0.0002 | Test loss: 0.5188 | Test acc: 82.1617\n",
      "Train loss: 0.0001 | Test loss: 0.5069 | Test acc: 82.9003\n",
      "Train loss: 0.0002 | Test loss: 0.5074 | Test acc: 82.9526\n",
      "Train loss: 0.0002 | Test loss: 0.4970 | Test acc: 83.0126\n",
      "Train loss: 0.0002 | Test loss: 0.5475 | Test acc: 81.2556\n",
      "Train loss: 0.0003 | Test loss: 0.5072 | Test acc: 82.5180\n",
      "Train loss: 0.0001 | Test loss: 0.5176 | Test acc: 81.8731\n",
      "Train loss: 0.0002 | Test loss: 0.5229 | Test acc: 81.8910\n",
      "Train loss: 0.0001 | Test loss: 0.5495 | Test acc: 81.0524\n",
      "Train loss: 0.0003 | Test loss: 0.6082 | Test acc: 80.9299\n",
      "Train loss: 0.0002 | Test loss: 0.5464 | Test acc: 82.4471\n",
      "Train loss: 0.0002 | Test loss: 0.5090 | Test acc: 83.0709\n",
      "Train loss: 0.0003 | Test loss: 0.5179 | Test acc: 81.8349\n",
      "Train loss: 0.0002 | Test loss: 0.5408 | Test acc: 80.7227\n",
      "Train loss: 0.0003 | Test loss: 0.5378 | Test acc: 81.1285\n",
      "Train loss: 0.0002 | Test loss: 0.5994 | Test acc: 77.9149\n",
      "Train loss: 0.0003 | Test loss: 0.5061 | Test acc: 82.6171\n",
      "Train loss: 0.0003 | Test loss: 0.5265 | Test acc: 82.4325\n",
      "Train loss: 0.0004 | Test loss: 0.5866 | Test acc: 79.9059\n",
      "Train loss: 0.0002 | Test loss: 0.5320 | Test acc: 81.6351\n",
      "Train loss: 0.0002 | Test loss: 0.5230 | Test acc: 81.7504\n",
      "Train loss: 0.0004 | Test loss: 0.6307 | Test acc: 80.5128\n",
      "Train loss: 0.0002 | Test loss: 0.5882 | Test acc: 80.3591\n",
      "Train loss: 0.0006 | Test loss: 0.5600 | Test acc: 80.4384\n",
      "Train loss: 0.0002 | Test loss: 0.5549 | Test acc: 81.6168\n",
      "Train loss: 0.0002 | Test loss: 0.5320 | Test acc: 82.0898\n",
      "Train loss: 0.0003 | Test loss: 0.5124 | Test acc: 82.2012\n",
      "Train loss: 0.0004 | Test loss: 0.6133 | Test acc: 77.3193\n",
      "Train loss: 0.0003 | Test loss: 0.5458 | Test acc: 81.4471\n",
      "Train loss: 0.0002 | Test loss: 0.5072 | Test acc: 82.7183\n",
      "Train loss: 0.0002 | Test loss: 0.4973 | Test acc: 83.0518\n",
      "Train loss: 0.0003 | Test loss: 0.5507 | Test acc: 80.3272\n",
      "Train loss: 0.0003 | Test loss: 0.5468 | Test acc: 80.4982\n",
      "Train loss: 0.0002 | Test loss: 0.5457 | Test acc: 81.2077\n",
      "Train loss: 0.0003 | Test loss: 0.5296 | Test acc: 82.0186\n",
      "Train loss: 0.0002 | Test loss: 0.5405 | Test acc: 81.8715\n",
      "Train loss: 0.0003 | Test loss: 0.4959 | Test acc: 83.2089\n",
      "Train loss: 0.0003 | Test loss: 0.5072 | Test acc: 82.9036\n",
      "Train loss: 0.0003 | Test loss: 0.5320 | Test acc: 81.4949\n",
      "Train loss: 0.0003 | Test loss: 0.5277 | Test acc: 81.5104\n",
      "Train loss: 0.0003 | Test loss: 0.5556 | Test acc: 80.4521\n",
      "Train loss: 0.0002 | Test loss: 0.5358 | Test acc: 81.4871\n",
      "Train loss: 0.0003 | Test loss: 0.5183 | Test acc: 82.3690\n",
      "Train loss: 0.0001 | Test loss: 0.5212 | Test acc: 82.1222\n",
      "Train loss: 0.0003 | Test loss: 0.5166 | Test acc: 82.3211\n",
      "Train loss: 0.0002 | Test loss: 0.5549 | Test acc: 81.6428\n",
      "Train loss: 0.0004 | Test loss: 0.5244 | Test acc: 82.0400\n",
      "Train loss: 0.0002 | Test loss: 0.5249 | Test acc: 81.9414\n",
      "Train loss: 0.0002 | Test loss: 0.5000 | Test acc: 83.0393\n",
      "Train loss: 0.0004 | Test loss: 0.5078 | Test acc: 82.8831\n",
      "Train loss: 0.0003 | Test loss: 0.4985 | Test acc: 82.8427\n",
      "Train loss: 0.0002 | Test loss: 0.4875 | Test acc: 83.3817\n",
      "Train loss: 0.0003 | Test loss: 0.5377 | Test acc: 81.3367\n",
      "Train loss: 0.0003 | Test loss: 0.5064 | Test acc: 82.5582\n",
      "Train loss: 0.0002 | Test loss: 0.5140 | Test acc: 81.8133\n",
      "Train loss: 0.0002 | Test loss: 0.5120 | Test acc: 82.0905\n",
      "Train loss: 0.0002 | Test loss: 0.5357 | Test acc: 81.6421\n",
      "Train loss: 0.0004 | Test loss: 0.5349 | Test acc: 81.6806\n",
      "Train loss: 0.0003 | Test loss: 0.5474 | Test acc: 81.9702\n",
      "Train loss: 0.0003 | Test loss: 0.5045 | Test acc: 82.9196\n",
      "Train loss: 0.0004 | Test loss: 0.5188 | Test acc: 82.0840\n",
      "Train loss: 0.0002 | Test loss: 0.4995 | Test acc: 83.0698\n",
      "Train loss: 0.0003 | Test loss: 0.5429 | Test acc: 81.3057\n",
      "Train loss: 0.0003 | Test loss: 0.5731 | Test acc: 79.3732\n",
      "Train loss: 0.0002 | Test loss: 0.5090 | Test acc: 82.2424\n",
      "Train loss: 0.0002 | Test loss: 0.4997 | Test acc: 82.6809\n",
      "Train loss: 0.0002 | Test loss: 0.5029 | Test acc: 82.6823\n",
      "Train loss: 0.0002 | Test loss: 0.4928 | Test acc: 82.9019\n",
      "Train loss: 0.0003 | Test loss: 0.5178 | Test acc: 82.0041\n",
      "Train loss: 0.0003 | Test loss: 0.5248 | Test acc: 82.2009\n",
      "Train loss: 0.0002 | Test loss: 0.5085 | Test acc: 82.3613\n",
      "Train loss: 0.0002 | Test loss: 0.4897 | Test acc: 83.2903\n",
      "Train loss: 0.0003 | Test loss: 0.4926 | Test acc: 83.2833\n",
      "Train loss: 0.0004 | Test loss: 0.5193 | Test acc: 81.8855\n",
      "Train loss: 0.0004 | Test loss: 0.5558 | Test acc: 81.6614\n",
      "Train loss: 0.0003 | Test loss: 0.5283 | Test acc: 82.0500\n",
      "Train loss: 0.0002 | Test loss: 0.5447 | Test acc: 80.8632\n",
      "Train loss: 0.0002 | Test loss: 0.5414 | Test acc: 80.6897\n",
      "Train loss: 0.0003 | Test loss: 0.5505 | Test acc: 80.5393\n",
      "Train loss: 0.0002 | Test loss: 0.4943 | Test acc: 82.6355\n",
      "Train loss: 0.0003 | Test loss: 0.4878 | Test acc: 82.7820\n",
      "Train loss: 0.0003 | Test loss: 0.5405 | Test acc: 80.9354\n",
      "Train loss: 0.0002 | Test loss: 0.5026 | Test acc: 82.2773\n",
      "Train loss: 0.0002 | Test loss: 0.4903 | Test acc: 83.0005\n",
      "Train loss: 0.0001 | Test loss: 0.4878 | Test acc: 83.1226\n",
      "Train loss: 0.0002 | Test loss: 0.5224 | Test acc: 82.1745\n",
      "Train loss: 0.0002 | Test loss: 0.5013 | Test acc: 82.4810\n",
      "Train loss: 0.0003 | Test loss: 0.5393 | Test acc: 81.0143\n",
      "Train loss: 0.0003 | Test loss: 0.5166 | Test acc: 81.7584\n",
      "Train loss: 0.0003 | Test loss: 0.5251 | Test acc: 82.3099\n",
      "Train loss: 0.0003 | Test loss: 0.5256 | Test acc: 81.5729\n",
      "Train loss: 0.0003 | Test loss: 0.5175 | Test acc: 81.8002\n",
      "Train loss: 0.0002 | Test loss: 0.5113 | Test acc: 82.2402\n",
      "Train loss: 0.0002 | Test loss: 0.5206 | Test acc: 82.0719\n",
      "Train loss: 0.0003 | Test loss: 0.5435 | Test acc: 80.9331\n",
      "Train loss: 0.0004 | Test loss: 0.5903 | Test acc: 79.5218\n",
      "Train loss: 0.0003 | Test loss: 0.5494 | Test acc: 81.2445\n",
      "Train loss: 0.0001 | Test loss: 0.5532 | Test acc: 81.3598\n",
      "Train loss: 0.0003 | Test loss: 0.5519 | Test acc: 80.6114\n",
      "Train loss: 0.0002 | Test loss: 0.4925 | Test acc: 83.0551\n",
      "Train loss: 0.0002 | Test loss: 0.5166 | Test acc: 82.4638\n",
      "Train loss: 0.0002 | Test loss: 0.5089 | Test acc: 82.2722\n",
      "Train loss: 0.0003 | Test loss: 0.5616 | Test acc: 80.5344\n",
      "Train loss: 0.0003 | Test loss: 0.5412 | Test acc: 80.5588\n",
      "Train loss: 0.0004 | Test loss: 0.5037 | Test acc: 82.7154\n",
      "Train loss: 0.0002 | Test loss: 0.4917 | Test acc: 83.2215\n",
      "Train loss: 0.0003 | Test loss: 0.5372 | Test acc: 80.2579\n",
      "Train loss: 0.0004 | Test loss: 0.5109 | Test acc: 82.2452\n",
      "Train loss: 0.0003 | Test loss: 0.4980 | Test acc: 82.7608\n",
      "Train loss: 0.0002 | Test loss: 0.5040 | Test acc: 81.8639\n",
      "Train loss: 0.0003 | Test loss: 0.4988 | Test acc: 83.2687\n",
      "Train loss: 0.0002 | Test loss: 0.4946 | Test acc: 83.0336\n",
      "Train loss: 0.0003 | Test loss: 0.5284 | Test acc: 80.7265\n",
      "Train loss: 0.0003 | Test loss: 0.5041 | Test acc: 82.7659\n",
      "Train loss: 0.0002 | Test loss: 0.5103 | Test acc: 82.3731\n",
      "Train loss: 0.0002 | Test loss: 0.5251 | Test acc: 81.8626\n",
      "Train loss: 0.0002 | Test loss: 0.5208 | Test acc: 81.9409\n",
      "Train loss: 0.0004 | Test loss: 0.5149 | Test acc: 81.7913\n",
      "Train loss: 0.0002 | Test loss: 0.5216 | Test acc: 82.0205\n",
      "Train loss: 0.0001 | Test loss: 0.5797 | Test acc: 80.3339\n",
      "Train loss: 0.0004 | Test loss: 0.5127 | Test acc: 82.0757\n",
      "Train loss: 0.0001 | Test loss: 0.5079 | Test acc: 82.2710\n",
      "Train loss: 0.0003 | Test loss: 0.5270 | Test acc: 80.9038\n",
      "Train loss: 0.0002 | Test loss: 0.4997 | Test acc: 82.5468\n",
      "Train loss: 0.0003 | Test loss: 0.5082 | Test acc: 82.9015\n",
      "Train loss: 0.0002 | Test loss: 0.5154 | Test acc: 82.5632\n",
      "Train loss: 0.0003 | Test loss: 0.5509 | Test acc: 81.0845\n",
      "Train loss: 0.0003 | Test loss: 0.5394 | Test acc: 81.2095\n",
      "Train loss: 0.0001 | Test loss: 0.5426 | Test acc: 80.8605\n",
      "Train loss: 0.0002 | Test loss: 0.5379 | Test acc: 81.3386\n",
      "Train loss: 0.0002 | Test loss: 0.5662 | Test acc: 79.3933\n",
      "Train loss: 0.0002 | Test loss: 0.5125 | Test acc: 82.2425\n",
      "Train loss: 0.0002 | Test loss: 0.5278 | Test acc: 82.0918\n",
      "Train loss: 0.0002 | Test loss: 0.5314 | Test acc: 81.8118\n",
      "Train loss: 0.0003 | Test loss: 0.5509 | Test acc: 80.1436\n",
      "Train loss: 0.0003 | Test loss: 0.4915 | Test acc: 83.1534\n",
      "Train loss: 0.0002 | Test loss: 0.4895 | Test acc: 83.3527\n",
      "Train loss: 0.0001 | Test loss: 0.5263 | Test acc: 81.8058\n",
      "Train loss: 0.0002 | Test loss: 0.4859 | Test acc: 83.1687\n",
      "Train loss: 0.0002 | Test loss: 0.4843 | Test acc: 83.1032\n",
      "Train loss: 0.0001 | Test loss: 0.4784 | Test acc: 83.4824\n",
      "Train loss: 0.0004 | Test loss: 0.5140 | Test acc: 82.6948\n",
      "Train loss: 0.0002 | Test loss: 0.5391 | Test acc: 80.9351\n",
      "Train loss: 0.0005 | Test loss: 0.5026 | Test acc: 82.9862\n",
      "Train loss: 0.0002 | Test loss: 0.4834 | Test acc: 83.5319\n",
      "Train loss: 0.0002 | Test loss: 0.4971 | Test acc: 82.8248\n",
      "Train loss: 0.0002 | Test loss: 0.5068 | Test acc: 82.6528\n",
      "Train loss: 0.0003 | Test loss: 0.5742 | Test acc: 78.8983\n",
      "Train loss: 0.0003 | Test loss: 0.5679 | Test acc: 80.5236\n",
      "Train loss: 0.0004 | Test loss: 0.5367 | Test acc: 81.8367\n",
      "Train loss: 0.0002 | Test loss: 0.5318 | Test acc: 81.5614\n",
      "Train loss: 0.0004 | Test loss: 0.5203 | Test acc: 81.9798\n",
      "Train loss: 0.0003 | Test loss: 0.5352 | Test acc: 81.4620\n",
      "Train loss: 0.0002 | Test loss: 0.5149 | Test acc: 81.8797\n",
      "Train loss: 0.0002 | Test loss: 0.5141 | Test acc: 81.8411\n",
      "Train loss: 0.0002 | Test loss: 0.5044 | Test acc: 82.7195\n",
      "Train loss: 0.0002 | Test loss: 0.4920 | Test acc: 83.3414\n",
      "Train loss: 0.0002 | Test loss: 0.5385 | Test acc: 81.2667\n",
      "Train loss: 0.0003 | Test loss: 0.5070 | Test acc: 82.5280\n",
      "Train loss: 0.0005 | Test loss: 0.5811 | Test acc: 79.0476\n",
      "Train loss: 0.0004 | Test loss: 0.5328 | Test acc: 80.8835\n",
      "Train loss: 0.0004 | Test loss: 0.5473 | Test acc: 81.2588\n",
      "Train loss: 0.0002 | Test loss: 0.4969 | Test acc: 82.6578\n",
      "Train loss: 0.0002 | Test loss: 0.5258 | Test acc: 81.7237\n",
      "Train loss: 0.0004 | Test loss: 0.5614 | Test acc: 81.4712\n",
      "Train loss: 0.0003 | Test loss: 0.5451 | Test acc: 80.4520\n",
      "Train loss: 0.0004 | Test loss: 0.5098 | Test acc: 82.3157\n",
      "Train loss: 0.0002 | Test loss: 0.5309 | Test acc: 81.3532\n",
      "Train loss: 0.0003 | Test loss: 0.5183 | Test acc: 82.4584\n",
      "Train loss: 0.0002 | Test loss: 0.5220 | Test acc: 82.0925\n",
      "Train loss: 0.0002 | Test loss: 0.5223 | Test acc: 82.2311\n",
      "Train loss: 0.0002 | Test loss: 0.5138 | Test acc: 82.4412\n",
      "Train loss: 0.0002 | Test loss: 0.5156 | Test acc: 82.2522\n",
      "Train loss: 0.0002 | Test loss: 0.5135 | Test acc: 82.8207\n",
      "Train loss: 0.0002 | Test loss: 0.6010 | Test acc: 79.9072\n",
      "Train loss: 0.0003 | Test loss: 0.5293 | Test acc: 82.7034\n",
      "Train loss: 0.0002 | Test loss: 0.5097 | Test acc: 83.2714\n",
      "Train loss: 0.0002 | Test loss: 0.5046 | Test acc: 82.9637\n",
      "Train loss: 0.0002 | Test loss: 0.4903 | Test acc: 83.4420\n",
      "Train loss: 0.0002 | Test loss: 0.4901 | Test acc: 83.4834\n",
      "Train loss: 0.0001 | Test loss: 0.4934 | Test acc: 83.2939\n",
      "Train loss: 0.0002 | Test loss: 0.5052 | Test acc: 82.7342\n",
      "Train loss: 0.0003 | Test loss: 0.4864 | Test acc: 83.6110\n",
      "Train loss: 0.0001 | Test loss: 0.5020 | Test acc: 82.5854\n",
      "Train loss: 0.0002 | Test loss: 0.5261 | Test acc: 82.2227\n",
      "Train loss: 0.0002 | Test loss: 0.5023 | Test acc: 82.9704\n",
      "Train loss: 0.0002 | Test loss: 0.5094 | Test acc: 82.2439\n",
      "Train loss: 0.0002 | Test loss: 0.5077 | Test acc: 82.8606\n",
      "Train loss: 0.0002 | Test loss: 0.4911 | Test acc: 83.3019\n",
      "Train loss: 0.0003 | Test loss: 0.5022 | Test acc: 82.5744\n",
      "Train loss: 0.0002 | Test loss: 0.4948 | Test acc: 82.9515\n",
      "Train loss: 0.0003 | Test loss: 0.5598 | Test acc: 79.2187\n",
      "Train loss: 0.0003 | Test loss: 0.4877 | Test acc: 83.5498\n",
      "Train loss: 0.0002 | Test loss: 0.5007 | Test acc: 82.8648\n",
      "Train loss: 0.0002 | Test loss: 0.5010 | Test acc: 82.4233\n",
      "Train loss: 0.0002 | Test loss: 0.5017 | Test acc: 82.6914\n",
      "Train loss: 0.0003 | Test loss: 0.5323 | Test acc: 81.5042\n",
      "Train loss: 0.0003 | Test loss: 0.4954 | Test acc: 83.4673\n",
      "Train loss: 0.0003 | Test loss: 0.6287 | Test acc: 78.1021\n",
      "Train loss: 0.0002 | Test loss: 0.5000 | Test acc: 82.9372\n",
      "Train loss: 0.0003 | Test loss: 0.5213 | Test acc: 82.1140\n",
      "Train loss: 0.0003 | Test loss: 0.5071 | Test acc: 82.6006\n",
      "Train loss: 0.0003 | Test loss: 0.5161 | Test acc: 82.4324\n",
      "Train loss: 0.0003 | Test loss: 0.5636 | Test acc: 81.0441\n",
      "Train loss: 0.0003 | Test loss: 0.5489 | Test acc: 80.2010\n",
      "Train loss: 0.0000 | Test loss: 0.5594 | Test acc: 79.7990\n",
      "Train loss: 0.0001 | Test loss: 0.5366 | Test acc: 80.8859\n",
      "Train loss: 0.0005 | Test loss: 0.5568 | Test acc: 80.1107\n",
      "Train loss: 0.0003 | Test loss: 0.4961 | Test acc: 82.6841\n",
      "Train loss: 0.0002 | Test loss: 0.5093 | Test acc: 82.7921\n",
      "Train loss: 0.0004 | Test loss: 0.5337 | Test acc: 82.1036\n",
      "Train loss: 0.0004 | Test loss: 0.5735 | Test acc: 80.0247\n",
      "Train loss: 0.0002 | Test loss: 0.5111 | Test acc: 82.2645\n",
      "Train loss: 0.0003 | Test loss: 0.5224 | Test acc: 81.5328\n",
      "Train loss: 0.0002 | Test loss: 0.5189 | Test acc: 81.8599\n",
      "Train loss: 0.0003 | Test loss: 0.4902 | Test acc: 83.1090\n",
      "Train loss: 0.0004 | Test loss: 0.5092 | Test acc: 82.1046\n",
      "Train loss: 0.0001 | Test loss: 0.5221 | Test acc: 81.2527\n",
      "Train loss: 0.0002 | Test loss: 0.5032 | Test acc: 82.9673\n",
      "Train loss: 0.0003 | Test loss: 0.4941 | Test acc: 83.0027\n",
      "Train loss: 0.0003 | Test loss: 0.4979 | Test acc: 82.7432\n",
      "Train loss: 0.0003 | Test loss: 0.5403 | Test acc: 80.8754\n",
      "Train loss: 0.0003 | Test loss: 0.5180 | Test acc: 82.0575\n",
      "Train loss: 0.0003 | Test loss: 0.5007 | Test acc: 82.4207\n",
      "Train loss: 0.0002 | Test loss: 0.5083 | Test acc: 82.6016\n",
      "Train loss: 0.0003 | Test loss: 0.5039 | Test acc: 82.4824\n",
      "Train loss: 0.0002 | Test loss: 0.4966 | Test acc: 82.8314\n",
      "Train loss: 0.0002 | Test loss: 0.5425 | Test acc: 81.0654\n",
      "Train loss: 0.0001 | Test loss: 0.5241 | Test acc: 81.4191\n",
      "Train loss: 0.0006 | Test loss: 0.5272 | Test acc: 81.7597\n",
      "Train loss: 0.0004 | Test loss: 0.5457 | Test acc: 80.1035\n",
      "Train loss: 0.0002 | Test loss: 0.5667 | Test acc: 80.2180\n",
      "Train loss: 0.0002 | Test loss: 0.5283 | Test acc: 81.6261\n",
      "Train loss: 0.0002 | Test loss: 0.4984 | Test acc: 82.5891\n",
      "Train loss: 0.0002 | Test loss: 0.4894 | Test acc: 82.9815\n",
      "Train loss: 0.0003 | Test loss: 0.5309 | Test acc: 81.7048\n",
      "Train loss: 0.0004 | Test loss: 0.5516 | Test acc: 80.1532\n",
      "Train loss: 0.0003 | Test loss: 0.5329 | Test acc: 81.2964\n",
      "Train loss: 0.0001 | Test loss: 0.5387 | Test acc: 80.8109\n",
      "Train loss: 0.0003 | Test loss: 0.5378 | Test acc: 81.1687\n",
      "Train loss: 0.0003 | Test loss: 0.4984 | Test acc: 82.8472\n",
      "Train loss: 0.0002 | Test loss: 0.5213 | Test acc: 81.8042\n",
      "Train loss: 0.0002 | Test loss: 0.5097 | Test acc: 82.1403\n",
      "Train loss: 0.0004 | Test loss: 0.5082 | Test acc: 82.1314\n",
      "Train loss: 0.0002 | Test loss: 0.5173 | Test acc: 81.9916\n",
      "Train loss: 0.0002 | Test loss: 0.5141 | Test acc: 81.7017\n",
      "Train loss: 0.0002 | Test loss: 0.5089 | Test acc: 81.9403\n",
      "Train loss: 0.0002 | Test loss: 0.5223 | Test acc: 81.6416\n",
      "Train loss: 0.0003 | Test loss: 0.5481 | Test acc: 80.9018\n",
      "Train loss: 0.0004 | Test loss: 0.5203 | Test acc: 82.1674\n",
      "Train loss: 0.0002 | Test loss: 0.5424 | Test acc: 81.0832\n",
      "Train loss: 0.0003 | Test loss: 0.5238 | Test acc: 81.6289\n",
      "Train loss: 0.0003 | Test loss: 0.5385 | Test acc: 80.6921\n",
      "Train loss: 0.0002 | Test loss: 0.5378 | Test acc: 80.7989\n",
      "Train loss: 0.0004 | Test loss: 0.5445 | Test acc: 81.1887\n",
      "Train loss: 0.0003 | Test loss: 0.5097 | Test acc: 82.2782\n",
      "Train loss: 0.0002 | Test loss: 0.4947 | Test acc: 82.7010\n",
      "Train loss: 0.0002 | Test loss: 0.4858 | Test acc: 83.5609\n",
      "Train loss: 0.0003 | Test loss: 0.5061 | Test acc: 82.3357\n",
      "Train loss: 0.0004 | Test loss: 0.7577 | Test acc: 73.6257\n",
      "Train loss: 0.0004 | Test loss: 0.5284 | Test acc: 81.7648\n",
      "Train loss: 0.0001 | Test loss: 0.5421 | Test acc: 81.1019\n",
      "Train loss: 0.0003 | Test loss: 0.5149 | Test acc: 82.6074\n",
      "Train loss: 0.0004 | Test loss: 0.5177 | Test acc: 82.2927\n",
      "Train loss: 0.0003 | Test loss: 0.5216 | Test acc: 82.4015\n",
      "Train loss: 0.0002 | Test loss: 0.5009 | Test acc: 82.9010\n",
      "Train loss: 0.0003 | Test loss: 0.4923 | Test acc: 83.1522\n",
      "Train loss: 0.0002 | Test loss: 0.5341 | Test acc: 82.1846\n",
      "Train loss: 0.0002 | Test loss: 0.5266 | Test acc: 81.9718\n",
      "Train loss: 0.0002 | Test loss: 0.5221 | Test acc: 82.5902\n",
      "Train loss: 0.0002 | Test loss: 0.4886 | Test acc: 83.2311\n",
      "Train loss: 0.0002 | Test loss: 0.5268 | Test acc: 81.3062\n",
      "Train loss: 0.0002 | Test loss: 0.4890 | Test acc: 83.0773\n",
      "Train loss: 0.0002 | Test loss: 0.5020 | Test acc: 82.7235\n",
      "Train loss: 0.0002 | Test loss: 0.4980 | Test acc: 82.7124\n",
      "Train loss: 0.0001 | Test loss: 0.5022 | Test acc: 82.8821\n",
      "Train loss: 0.0003 | Test loss: 0.4937 | Test acc: 83.0024\n",
      "Train loss: 0.0002 | Test loss: 0.5229 | Test acc: 82.1841\n",
      "Train loss: 0.0003 | Test loss: 0.5308 | Test acc: 82.0517\n",
      "Train loss: 0.0004 | Test loss: 0.5589 | Test acc: 81.1627\n",
      "Train loss: 0.0002 | Test loss: 0.5855 | Test acc: 80.0017\n",
      "Train loss: 0.0003 | Test loss: 0.4888 | Test acc: 83.5324\n",
      "Train loss: 0.0002 | Test loss: 0.4905 | Test acc: 82.9745\n",
      "Train loss: 0.0003 | Test loss: 0.5214 | Test acc: 81.9544\n",
      "Train loss: 0.0002 | Test loss: 0.5317 | Test acc: 81.3621\n",
      "Train loss: 0.0001 | Test loss: 0.5002 | Test acc: 82.6881\n",
      "Train loss: 0.0004 | Test loss: 0.4963 | Test acc: 82.9319\n",
      "Train loss: 0.0004 | Test loss: 0.4925 | Test acc: 83.1124\n",
      "Train loss: 0.0003 | Test loss: 0.4891 | Test acc: 83.3127\n",
      "Train loss: 0.0003 | Test loss: 0.5172 | Test acc: 82.1452\n",
      "Train loss: 0.0002 | Test loss: 0.5174 | Test acc: 82.3511\n",
      "Train loss: 0.0002 | Test loss: 0.4899 | Test acc: 83.0806\n",
      "Train loss: 0.0003 | Test loss: 0.5000 | Test acc: 82.6436\n",
      "Train loss: 0.0001 | Test loss: 0.4885 | Test acc: 83.1814\n",
      "Train loss: 0.0003 | Test loss: 0.5137 | Test acc: 81.9650\n",
      "Train loss: 0.0001 | Test loss: 0.4878 | Test acc: 83.3190\n",
      "Train loss: 0.0003 | Test loss: 0.5244 | Test acc: 81.2267\n",
      "Train loss: 0.0003 | Test loss: 0.5166 | Test acc: 81.6693\n",
      "Train loss: 0.0002 | Test loss: 0.5177 | Test acc: 81.9303\n",
      "Train loss: 0.0003 | Test loss: 0.5155 | Test acc: 82.7398\n",
      "Train loss: 0.0002 | Test loss: 0.5291 | Test acc: 82.7623\n",
      "Train loss: 0.0003 | Test loss: 0.5123 | Test acc: 82.0436\n",
      "Train loss: 0.0004 | Test loss: 0.4948 | Test acc: 83.0596\n",
      "Train loss: 0.0001 | Test loss: 0.4762 | Test acc: 83.8017\n",
      "Train loss: 0.0001 | Test loss: 0.4870 | Test acc: 83.4147\n",
      "Train loss: 0.0005 | Test loss: 0.4990 | Test acc: 83.1339\n",
      "Train loss: 0.0001 | Test loss: 0.5017 | Test acc: 83.1730\n",
      "Train loss: 0.0003 | Test loss: 0.5010 | Test acc: 82.7937\n",
      "Train loss: 0.0003 | Test loss: 0.4958 | Test acc: 82.6926\n",
      "Train loss: 0.0003 | Test loss: 0.6814 | Test acc: 76.9814\n",
      "Train loss: 0.0005 | Test loss: 0.5142 | Test acc: 81.6357\n",
      "Train loss: 0.0001 | Test loss: 0.4874 | Test acc: 83.1781\n",
      "Train loss: 0.0001 | Test loss: 0.5067 | Test acc: 82.5042\n",
      "Train loss: 0.0001 | Test loss: 0.5038 | Test acc: 82.5619\n",
      "Train loss: 0.0004 | Test loss: 0.5340 | Test acc: 81.5038\n",
      "Train loss: 0.0004 | Test loss: 0.5067 | Test acc: 82.0395\n",
      "Train loss: 0.0002 | Test loss: 0.5157 | Test acc: 81.9814\n",
      "Looked at 12800 / 60000 samples\n",
      "Train loss: 0.0004 | Test loss: 0.4806 | Test acc: 83.2392\n",
      "Train loss: 0.0004 | Test loss: 0.5817 | Test acc: 78.4908\n",
      "Train loss: 0.0001 | Test loss: 0.5701 | Test acc: 78.5056\n",
      "Train loss: 0.0005 | Test loss: 0.5218 | Test acc: 81.8702\n",
      "Train loss: 0.0003 | Test loss: 0.4907 | Test acc: 83.0291\n",
      "Train loss: 0.0004 | Test loss: 0.5117 | Test acc: 82.7034\n",
      "Train loss: 0.0003 | Test loss: 0.4930 | Test acc: 83.4112\n",
      "Train loss: 0.0004 | Test loss: 0.5398 | Test acc: 81.1171\n",
      "Train loss: 0.0001 | Test loss: 0.5386 | Test acc: 81.0299\n",
      "Train loss: 0.0004 | Test loss: 0.5155 | Test acc: 81.5788\n",
      "Train loss: 0.0003 | Test loss: 0.5050 | Test acc: 82.2794\n",
      "Train loss: 0.0003 | Test loss: 0.5255 | Test acc: 81.3132\n",
      "Train loss: 0.0004 | Test loss: 0.5478 | Test acc: 81.4998\n",
      "Train loss: 0.0004 | Test loss: 0.5430 | Test acc: 81.3606\n",
      "Train loss: 0.0002 | Test loss: 0.5168 | Test acc: 82.3386\n",
      "Train loss: 0.0002 | Test loss: 0.5483 | Test acc: 80.6145\n",
      "Train loss: 0.0004 | Test loss: 0.5805 | Test acc: 79.2012\n",
      "Train loss: 0.0003 | Test loss: 0.5014 | Test acc: 82.7910\n",
      "Train loss: 0.0002 | Test loss: 0.5137 | Test acc: 81.7641\n",
      "Train loss: 0.0002 | Test loss: 0.4804 | Test acc: 83.5679\n",
      "Train loss: 0.0003 | Test loss: 0.4895 | Test acc: 82.5753\n",
      "Train loss: 0.0002 | Test loss: 0.4873 | Test acc: 83.2510\n",
      "Train loss: 0.0003 | Test loss: 0.5171 | Test acc: 81.6657\n",
      "Train loss: 0.0001 | Test loss: 0.4970 | Test acc: 82.5592\n",
      "Train loss: 0.0003 | Test loss: 0.5062 | Test acc: 82.3824\n",
      "Train loss: 0.0004 | Test loss: 0.5476 | Test acc: 81.2237\n",
      "Train loss: 0.0005 | Test loss: 0.4916 | Test acc: 82.8873\n",
      "Train loss: 0.0003 | Test loss: 0.4880 | Test acc: 83.0923\n",
      "Train loss: 0.0003 | Test loss: 0.4875 | Test acc: 83.1928\n",
      "Train loss: 0.0003 | Test loss: 0.4961 | Test acc: 82.4942\n",
      "Train loss: 0.0002 | Test loss: 0.4831 | Test acc: 83.2308\n",
      "Train loss: 0.0003 | Test loss: 0.4905 | Test acc: 82.9336\n",
      "Train loss: 0.0004 | Test loss: 0.5227 | Test acc: 81.6747\n",
      "Train loss: 0.0001 | Test loss: 0.5291 | Test acc: 81.6607\n",
      "Train loss: 0.0005 | Test loss: 0.4943 | Test acc: 83.4178\n",
      "Train loss: 0.0004 | Test loss: 0.6061 | Test acc: 79.5197\n",
      "Train loss: 0.0003 | Test loss: 0.5710 | Test acc: 81.0448\n",
      "Train loss: 0.0002 | Test loss: 0.5184 | Test acc: 82.0880\n",
      "Train loss: 0.0002 | Test loss: 0.5193 | Test acc: 82.0015\n",
      "Train loss: 0.0003 | Test loss: 0.5340 | Test acc: 81.5919\n",
      "Train loss: 0.0002 | Test loss: 0.5091 | Test acc: 82.4592\n",
      "Train loss: 0.0003 | Test loss: 0.4917 | Test acc: 82.9611\n",
      "Train loss: 0.0001 | Test loss: 0.4796 | Test acc: 83.6616\n",
      "Train loss: 0.0003 | Test loss: 0.4869 | Test acc: 83.1347\n",
      "Train loss: 0.0002 | Test loss: 0.5061 | Test acc: 82.7536\n",
      "Train loss: 0.0003 | Test loss: 0.4971 | Test acc: 82.6725\n",
      "Train loss: 0.0002 | Test loss: 0.5156 | Test acc: 82.2729\n",
      "Train loss: 0.0002 | Test loss: 0.4901 | Test acc: 83.0803\n",
      "Train loss: 0.0003 | Test loss: 0.4890 | Test acc: 82.9931\n",
      "Train loss: 0.0003 | Test loss: 0.4955 | Test acc: 83.0227\n",
      "Train loss: 0.0003 | Test loss: 0.4928 | Test acc: 82.7832\n",
      "Train loss: 0.0002 | Test loss: 0.4957 | Test acc: 83.1618\n",
      "Train loss: 0.0003 | Test loss: 0.4984 | Test acc: 82.3943\n",
      "Train loss: 0.0002 | Test loss: 0.5015 | Test acc: 82.5915\n",
      "Train loss: 0.0002 | Test loss: 0.4977 | Test acc: 82.8018\n",
      "Train loss: 0.0002 | Test loss: 0.4927 | Test acc: 83.3217\n",
      "Train loss: 0.0002 | Test loss: 0.5714 | Test acc: 78.3712\n",
      "Train loss: 0.0001 | Test loss: 0.5047 | Test acc: 82.0295\n",
      "Train loss: 0.0002 | Test loss: 0.4876 | Test acc: 83.2493\n",
      "Train loss: 0.0002 | Test loss: 0.5373 | Test acc: 81.0667\n",
      "Train loss: 0.0004 | Test loss: 0.5040 | Test acc: 82.0781\n",
      "Train loss: 0.0003 | Test loss: 0.4922 | Test acc: 82.5905\n",
      "Train loss: 0.0003 | Test loss: 0.5254 | Test acc: 81.9631\n",
      "Train loss: 0.0001 | Test loss: 0.5301 | Test acc: 81.8613\n",
      "Train loss: 0.0002 | Test loss: 0.5216 | Test acc: 81.8410\n",
      "Train loss: 0.0003 | Test loss: 0.5070 | Test acc: 82.1205\n",
      "Train loss: 0.0002 | Test loss: 0.4877 | Test acc: 82.6705\n",
      "Train loss: 0.0002 | Test loss: 0.4828 | Test acc: 82.9518\n",
      "Train loss: 0.0002 | Test loss: 0.4807 | Test acc: 83.2622\n",
      "Train loss: 0.0003 | Test loss: 0.4899 | Test acc: 83.0336\n",
      "Train loss: 0.0003 | Test loss: 0.4978 | Test acc: 82.9330\n",
      "Train loss: 0.0002 | Test loss: 0.4928 | Test acc: 82.7530\n",
      "Train loss: 0.0002 | Test loss: 0.5095 | Test acc: 82.5727\n",
      "Train loss: 0.0002 | Test loss: 0.4948 | Test acc: 83.3109\n",
      "Train loss: 0.0003 | Test loss: 0.5197 | Test acc: 81.3764\n",
      "Train loss: 0.0002 | Test loss: 0.5387 | Test acc: 81.1206\n",
      "Train loss: 0.0004 | Test loss: 0.5399 | Test acc: 80.8203\n",
      "Train loss: 0.0002 | Test loss: 0.5072 | Test acc: 81.7378\n",
      "Train loss: 0.0003 | Test loss: 0.6006 | Test acc: 80.5227\n",
      "Train loss: 0.0003 | Test loss: 0.5442 | Test acc: 80.7285\n",
      "Train loss: 0.0002 | Test loss: 0.5509 | Test acc: 80.5594\n",
      "Train loss: 0.0004 | Test loss: 0.5138 | Test acc: 82.5657\n",
      "Train loss: 0.0002 | Test loss: 0.4869 | Test acc: 83.3209\n",
      "Train loss: 0.0003 | Test loss: 0.4845 | Test acc: 83.2734\n",
      "Train loss: 0.0002 | Test loss: 0.5018 | Test acc: 82.5444\n",
      "Train loss: 0.0003 | Test loss: 0.4856 | Test acc: 83.1012\n",
      "Train loss: 0.0002 | Test loss: 0.5137 | Test acc: 81.7252\n",
      "Train loss: 0.0005 | Test loss: 0.5254 | Test acc: 80.8522\n",
      "Train loss: 0.0003 | Test loss: 0.5010 | Test acc: 82.9061\n",
      "Train loss: 0.0002 | Test loss: 0.4789 | Test acc: 83.3220\n",
      "Train loss: 0.0003 | Test loss: 0.5240 | Test acc: 81.8557\n",
      "Train loss: 0.0002 | Test loss: 0.5792 | Test acc: 79.4149\n",
      "Train loss: 0.0003 | Test loss: 0.5038 | Test acc: 82.6319\n",
      "Train loss: 0.0002 | Test loss: 0.5174 | Test acc: 82.2728\n",
      "Train loss: 0.0003 | Test loss: 0.5505 | Test acc: 80.7940\n",
      "Train loss: 0.0003 | Test loss: 0.5268 | Test acc: 81.6679\n",
      "Train loss: 0.0003 | Test loss: 0.5385 | Test acc: 81.6307\n",
      "Train loss: 0.0003 | Test loss: 0.5003 | Test acc: 82.5192\n",
      "Train loss: 0.0002 | Test loss: 0.5202 | Test acc: 81.8531\n",
      "Train loss: 0.0002 | Test loss: 0.5172 | Test acc: 82.0506\n",
      "Train loss: 0.0002 | Test loss: 0.5263 | Test acc: 81.4123\n",
      "Train loss: 0.0002 | Test loss: 0.5043 | Test acc: 82.3787\n",
      "Train loss: 0.0003 | Test loss: 0.4965 | Test acc: 82.4916\n",
      "Train loss: 0.0002 | Test loss: 0.5032 | Test acc: 82.5120\n",
      "Train loss: 0.0002 | Test loss: 0.4936 | Test acc: 82.7017\n",
      "Train loss: 0.0003 | Test loss: 0.4903 | Test acc: 82.6624\n",
      "Train loss: 0.0004 | Test loss: 0.4819 | Test acc: 83.0716\n",
      "Train loss: 0.0002 | Test loss: 0.5369 | Test acc: 80.3173\n",
      "Train loss: 0.0003 | Test loss: 0.4970 | Test acc: 81.8461\n",
      "Train loss: 0.0002 | Test loss: 0.4870 | Test acc: 82.4700\n",
      "Train loss: 0.0002 | Test loss: 0.4870 | Test acc: 82.9512\n",
      "Train loss: 0.0004 | Test loss: 0.6253 | Test acc: 77.8709\n",
      "Train loss: 0.0002 | Test loss: 0.5562 | Test acc: 80.0212\n",
      "Train loss: 0.0004 | Test loss: 0.5209 | Test acc: 82.4242\n",
      "Train loss: 0.0002 | Test loss: 0.5071 | Test acc: 82.5816\n",
      "Train loss: 0.0002 | Test loss: 0.4961 | Test acc: 82.8517\n",
      "Train loss: 0.0001 | Test loss: 0.4760 | Test acc: 83.7112\n",
      "Train loss: 0.0002 | Test loss: 0.5080 | Test acc: 82.8853\n",
      "Train loss: 0.0004 | Test loss: 0.4913 | Test acc: 83.0224\n",
      "Train loss: 0.0003 | Test loss: 0.4815 | Test acc: 83.3423\n",
      "Train loss: 0.0003 | Test loss: 0.4939 | Test acc: 82.8841\n",
      "Train loss: 0.0002 | Test loss: 0.5126 | Test acc: 82.3435\n",
      "Train loss: 0.0002 | Test loss: 0.5118 | Test acc: 82.6912\n",
      "Train loss: 0.0003 | Test loss: 0.5153 | Test acc: 82.0933\n",
      "Train loss: 0.0002 | Test loss: 0.5473 | Test acc: 81.4624\n",
      "Train loss: 0.0002 | Test loss: 0.5165 | Test acc: 82.4887\n",
      "Train loss: 0.0002 | Test loss: 0.5158 | Test acc: 82.4421\n",
      "Train loss: 0.0002 | Test loss: 0.5221 | Test acc: 81.9826\n",
      "Train loss: 0.0002 | Test loss: 0.5348 | Test acc: 82.0211\n",
      "Train loss: 0.0002 | Test loss: 0.5586 | Test acc: 81.3323\n",
      "Train loss: 0.0002 | Test loss: 0.5184 | Test acc: 82.6181\n",
      "Train loss: 0.0001 | Test loss: 0.5639 | Test acc: 80.9848\n",
      "Train loss: 0.0002 | Test loss: 0.5400 | Test acc: 81.2991\n",
      "Train loss: 0.0002 | Test loss: 0.5173 | Test acc: 82.3684\n",
      "Train loss: 0.0002 | Test loss: 0.4974 | Test acc: 82.9908\n",
      "Train loss: 0.0003 | Test loss: 0.5043 | Test acc: 82.8830\n",
      "Train loss: 0.0001 | Test loss: 0.5090 | Test acc: 82.5232\n",
      "Train loss: 0.0002 | Test loss: 0.5133 | Test acc: 83.0712\n",
      "Train loss: 0.0002 | Test loss: 0.5020 | Test acc: 83.2227\n",
      "Train loss: 0.0002 | Test loss: 0.5259 | Test acc: 82.3945\n",
      "Train loss: 0.0003 | Test loss: 0.5220 | Test acc: 82.0723\n",
      "Train loss: 0.0003 | Test loss: 0.4900 | Test acc: 83.5390\n",
      "Train loss: 0.0002 | Test loss: 0.5051 | Test acc: 82.7050\n",
      "Train loss: 0.0003 | Test loss: 0.5157 | Test acc: 81.5442\n",
      "Train loss: 0.0002 | Test loss: 0.5527 | Test acc: 80.6219\n",
      "Train loss: 0.0002 | Test loss: 0.5401 | Test acc: 80.2895\n",
      "Train loss: 0.0003 | Test loss: 0.5126 | Test acc: 81.6762\n",
      "Train loss: 0.0003 | Test loss: 0.4999 | Test acc: 81.9502\n",
      "Train loss: 0.0003 | Test loss: 0.4953 | Test acc: 83.4587\n",
      "Train loss: 0.0001 | Test loss: 0.4805 | Test acc: 83.5634\n",
      "Train loss: 0.0001 | Test loss: 0.4792 | Test acc: 83.6036\n",
      "Train loss: 0.0001 | Test loss: 0.5175 | Test acc: 81.7268\n",
      "Train loss: 0.0002 | Test loss: 0.5784 | Test acc: 80.3130\n",
      "Train loss: 0.0003 | Test loss: 0.5242 | Test acc: 81.5066\n",
      "Train loss: 0.0002 | Test loss: 0.4974 | Test acc: 82.9182\n",
      "Train loss: 0.0003 | Test loss: 0.5450 | Test acc: 80.4167\n",
      "Train loss: 0.0006 | Test loss: 0.6195 | Test acc: 79.5700\n",
      "Train loss: 0.0003 | Test loss: 0.5059 | Test acc: 83.1616\n",
      "Train loss: 0.0004 | Test loss: 0.5193 | Test acc: 81.7553\n",
      "Train loss: 0.0003 | Test loss: 0.5441 | Test acc: 81.2217\n",
      "Train loss: 0.0002 | Test loss: 0.4959 | Test acc: 82.7974\n",
      "Train loss: 0.0002 | Test loss: 0.4948 | Test acc: 83.1819\n",
      "Train loss: 0.0003 | Test loss: 0.4995 | Test acc: 82.9335\n",
      "Train loss: 0.0004 | Test loss: 0.5303 | Test acc: 81.7745\n",
      "Train loss: 0.0003 | Test loss: 0.5056 | Test acc: 82.4098\n",
      "Train loss: 0.0002 | Test loss: 0.4981 | Test acc: 82.8511\n",
      "Train loss: 0.0002 | Test loss: 0.4989 | Test acc: 83.1321\n",
      "Train loss: 0.0003 | Test loss: 0.5372 | Test acc: 82.1146\n",
      "Train loss: 0.0002 | Test loss: 0.5400 | Test acc: 81.7420\n",
      "Train loss: 0.0002 | Test loss: 0.5368 | Test acc: 81.8007\n",
      "Train loss: 0.0003 | Test loss: 0.5362 | Test acc: 81.4015\n",
      "Train loss: 0.0003 | Test loss: 0.5409 | Test acc: 80.0424\n",
      "Train loss: 0.0003 | Test loss: 0.5100 | Test acc: 82.3344\n",
      "Train loss: 0.0002 | Test loss: 0.5474 | Test acc: 81.0638\n",
      "Train loss: 0.0003 | Test loss: 0.5069 | Test acc: 82.2378\n",
      "Train loss: 0.0001 | Test loss: 0.5226 | Test acc: 81.6625\n",
      "Train loss: 0.0002 | Test loss: 0.4898 | Test acc: 82.9686\n",
      "Train loss: 0.0002 | Test loss: 0.4903 | Test acc: 82.8430\n",
      "Train loss: 0.0003 | Test loss: 0.5156 | Test acc: 81.9939\n",
      "Train loss: 0.0001 | Test loss: 0.5159 | Test acc: 81.8614\n",
      "Train loss: 0.0002 | Test loss: 0.4983 | Test acc: 82.6697\n",
      "Train loss: 0.0002 | Test loss: 0.5001 | Test acc: 82.5025\n",
      "Train loss: 0.0002 | Test loss: 0.4910 | Test acc: 82.8614\n",
      "Train loss: 0.0004 | Test loss: 0.5003 | Test acc: 82.4432\n",
      "Train loss: 0.0002 | Test loss: 0.4873 | Test acc: 82.9511\n",
      "Train loss: 0.0002 | Test loss: 0.4875 | Test acc: 82.9228\n",
      "Train loss: 0.0002 | Test loss: 0.4737 | Test acc: 83.4518\n",
      "Train loss: 0.0001 | Test loss: 0.4889 | Test acc: 83.0542\n",
      "Train loss: 0.0002 | Test loss: 0.4861 | Test acc: 82.9730\n",
      "Train loss: 0.0003 | Test loss: 0.5550 | Test acc: 81.2455\n",
      "Train loss: 0.0005 | Test loss: 0.4908 | Test acc: 83.3067\n",
      "Train loss: 0.0003 | Test loss: 0.5163 | Test acc: 82.1651\n",
      "Train loss: 0.0003 | Test loss: 0.5000 | Test acc: 83.0101\n",
      "Train loss: 0.0001 | Test loss: 0.4986 | Test acc: 83.0428\n",
      "Train loss: 0.0002 | Test loss: 0.4784 | Test acc: 83.4822\n",
      "Train loss: 0.0002 | Test loss: 0.4998 | Test acc: 82.3454\n",
      "Train loss: 0.0002 | Test loss: 0.5092 | Test acc: 82.4915\n",
      "Train loss: 0.0004 | Test loss: 0.5371 | Test acc: 80.9045\n",
      "Train loss: 0.0003 | Test loss: 0.5535 | Test acc: 81.0592\n",
      "Train loss: 0.0001 | Test loss: 0.5419 | Test acc: 81.4191\n",
      "Train loss: 0.0002 | Test loss: 0.5179 | Test acc: 82.0892\n",
      "Train loss: 0.0004 | Test loss: 0.6852 | Test acc: 75.5718\n",
      "Train loss: 0.0003 | Test loss: 0.5654 | Test acc: 80.2734\n",
      "Train loss: 0.0004 | Test loss: 0.5040 | Test acc: 82.5448\n",
      "Train loss: 0.0002 | Test loss: 0.4860 | Test acc: 83.5804\n",
      "Train loss: 0.0005 | Test loss: 0.4929 | Test acc: 82.7451\n",
      "Train loss: 0.0003 | Test loss: 0.5001 | Test acc: 82.7823\n",
      "Train loss: 0.0002 | Test loss: 0.5168 | Test acc: 82.2333\n",
      "Train loss: 0.0001 | Test loss: 0.5353 | Test acc: 81.6625\n",
      "Train loss: 0.0007 | Test loss: 0.6465 | Test acc: 77.8967\n",
      "Train loss: 0.0004 | Test loss: 0.4976 | Test acc: 82.7768\n",
      "Train loss: 0.0003 | Test loss: 0.5396 | Test acc: 79.8971\n",
      "Train loss: 0.0002 | Test loss: 0.4838 | Test acc: 83.4422\n",
      "Train loss: 0.0002 | Test loss: 0.5215 | Test acc: 81.3069\n",
      "Train loss: 0.0003 | Test loss: 0.5071 | Test acc: 82.4682\n",
      "Train loss: 0.0003 | Test loss: 0.5033 | Test acc: 82.8314\n",
      "Train loss: 0.0002 | Test loss: 0.5106 | Test acc: 82.5430\n",
      "Train loss: 0.0002 | Test loss: 0.5102 | Test acc: 82.2625\n",
      "Train loss: 0.0003 | Test loss: 0.5737 | Test acc: 79.0068\n",
      "Train loss: 0.0001 | Test loss: 0.5334 | Test acc: 81.0232\n",
      "Train loss: 0.0002 | Test loss: 0.5101 | Test acc: 81.9282\n",
      "Train loss: 0.0002 | Test loss: 0.5165 | Test acc: 81.9211\n",
      "Train loss: 0.0002 | Test loss: 0.5100 | Test acc: 82.3105\n",
      "Train loss: 0.0001 | Test loss: 0.5169 | Test acc: 82.1719\n",
      "Train loss: 0.0002 | Test loss: 0.5245 | Test acc: 81.3228\n",
      "Train loss: 0.0002 | Test loss: 0.5151 | Test acc: 82.0989\n",
      "Train loss: 0.0002 | Test loss: 0.4986 | Test acc: 82.8202\n",
      "Train loss: 0.0002 | Test loss: 0.5078 | Test acc: 82.6428\n",
      "Train loss: 0.0002 | Test loss: 0.5598 | Test acc: 80.6055\n",
      "Train loss: 0.0004 | Test loss: 0.5677 | Test acc: 79.8102\n",
      "Train loss: 0.0003 | Test loss: 0.4937 | Test acc: 83.0924\n",
      "Train loss: 0.0001 | Test loss: 0.4849 | Test acc: 83.5822\n",
      "Train loss: 0.0002 | Test loss: 0.4987 | Test acc: 82.2359\n",
      "Train loss: 0.0003 | Test loss: 0.5267 | Test acc: 81.9720\n",
      "Train loss: 0.0002 | Test loss: 0.5269 | Test acc: 82.3905\n",
      "Train loss: 0.0002 | Test loss: 0.5228 | Test acc: 82.1622\n",
      "Train loss: 0.0002 | Test loss: 0.5330 | Test acc: 81.9318\n",
      "Train loss: 0.0003 | Test loss: 0.5106 | Test acc: 82.2206\n",
      "Train loss: 0.0003 | Test loss: 0.5363 | Test acc: 80.3346\n",
      "Train loss: 0.0002 | Test loss: 0.5229 | Test acc: 81.3469\n",
      "Train loss: 0.0003 | Test loss: 0.5523 | Test acc: 81.0506\n",
      "Train loss: 0.0001 | Test loss: 0.5946 | Test acc: 79.5521\n",
      "Train loss: 0.0004 | Test loss: 0.5260 | Test acc: 82.1431\n",
      "Train loss: 0.0002 | Test loss: 0.5190 | Test acc: 82.3711\n",
      "Train loss: 0.0002 | Test loss: 0.4989 | Test acc: 83.1206\n",
      "Train loss: 0.0002 | Test loss: 0.5096 | Test acc: 82.6837\n",
      "Train loss: 0.0002 | Test loss: 0.5184 | Test acc: 81.7238\n",
      "Train loss: 0.0002 | Test loss: 0.5091 | Test acc: 82.1301\n",
      "Train loss: 0.0004 | Test loss: 0.5788 | Test acc: 78.6470\n",
      "Train loss: 0.0002 | Test loss: 0.4933 | Test acc: 83.2185\n",
      "Train loss: 0.0002 | Test loss: 0.5177 | Test acc: 81.8953\n",
      "Train loss: 0.0003 | Test loss: 0.5144 | Test acc: 82.4102\n",
      "Train loss: 0.0002 | Test loss: 0.5270 | Test acc: 81.8527\n",
      "Train loss: 0.0002 | Test loss: 0.5134 | Test acc: 82.4999\n",
      "Train loss: 0.0004 | Test loss: 0.5130 | Test acc: 82.2125\n",
      "Train loss: 0.0002 | Test loss: 0.5498 | Test acc: 80.8238\n",
      "Train loss: 0.0002 | Test loss: 0.4818 | Test acc: 83.0757\n",
      "Train loss: 0.0006 | Test loss: 0.4912 | Test acc: 83.1528\n",
      "Train loss: 0.0002 | Test loss: 0.5001 | Test acc: 82.9134\n",
      "Train loss: 0.0002 | Test loss: 0.4971 | Test acc: 83.0225\n",
      "Train loss: 0.0006 | Test loss: 0.5136 | Test acc: 82.6934\n",
      "Train loss: 0.0002 | Test loss: 0.5311 | Test acc: 82.4826\n",
      "Train loss: 0.0004 | Test loss: 0.5749 | Test acc: 80.7547\n",
      "Train loss: 0.0002 | Test loss: 0.5200 | Test acc: 82.6761\n",
      "Train loss: 0.0002 | Test loss: 0.5319 | Test acc: 82.5026\n",
      "Train loss: 0.0003 | Test loss: 0.5278 | Test acc: 81.7832\n",
      "Train loss: 0.0004 | Test loss: 0.4952 | Test acc: 83.0388\n",
      "Train loss: 0.0001 | Test loss: 0.5060 | Test acc: 82.3240\n",
      "Train loss: 0.0002 | Test loss: 0.5053 | Test acc: 82.7111\n",
      "Train loss: 0.0002 | Test loss: 0.5512 | Test acc: 81.0750\n",
      "Train loss: 0.0003 | Test loss: 0.5100 | Test acc: 82.5973\n",
      "Train loss: 0.0003 | Test loss: 0.5062 | Test acc: 81.8633\n",
      "Train loss: 0.0002 | Test loss: 0.5195 | Test acc: 81.6314\n",
      "Train loss: 0.0002 | Test loss: 0.4985 | Test acc: 82.5691\n",
      "Train loss: 0.0002 | Test loss: 0.5489 | Test acc: 81.0445\n",
      "Train loss: 0.0002 | Test loss: 0.5210 | Test acc: 82.2178\n",
      "Train loss: 0.0003 | Test loss: 0.5581 | Test acc: 79.5159\n",
      "Train loss: 0.0003 | Test loss: 0.5188 | Test acc: 82.3527\n",
      "Train loss: 0.0002 | Test loss: 0.5014 | Test acc: 83.0806\n",
      "Train loss: 0.0002 | Test loss: 0.4861 | Test acc: 83.1828\n",
      "Train loss: 0.0003 | Test loss: 0.4841 | Test acc: 83.2430\n",
      "Train loss: 0.0002 | Test loss: 0.5062 | Test acc: 82.9137\n",
      "Train loss: 0.0002 | Test loss: 0.5018 | Test acc: 83.2821\n",
      "Train loss: 0.0002 | Test loss: 0.5230 | Test acc: 81.5460\n",
      "Train loss: 0.0001 | Test loss: 0.4991 | Test acc: 82.5888\n",
      "Train loss: 0.0003 | Test loss: 0.5457 | Test acc: 81.3641\n",
      "Train loss: 0.0002 | Test loss: 0.5288 | Test acc: 82.2588\n",
      "Train loss: 0.0003 | Test loss: 0.5070 | Test acc: 82.8906\n",
      "Train loss: 0.0002 | Test loss: 0.4828 | Test acc: 83.3219\n",
      "Train loss: 0.0003 | Test loss: 0.4872 | Test acc: 82.8640\n",
      "Train loss: 0.0001 | Test loss: 0.4853 | Test acc: 83.3318\n",
      "Train loss: 0.0003 | Test loss: 0.4930 | Test acc: 83.1237\n",
      "Train loss: 0.0003 | Test loss: 0.6696 | Test acc: 74.7564\n",
      "Train loss: 0.0003 | Test loss: 0.5021 | Test acc: 82.6470\n",
      "Train loss: 0.0004 | Test loss: 0.4965 | Test acc: 82.9318\n",
      "Train loss: 0.0001 | Test loss: 0.4885 | Test acc: 83.3321\n",
      "Train loss: 0.0001 | Test loss: 0.4807 | Test acc: 83.7127\n",
      "Train loss: 0.0002 | Test loss: 0.4825 | Test acc: 83.3046\n",
      "Train loss: 0.0002 | Test loss: 0.4944 | Test acc: 83.1835\n",
      "Train loss: 0.0002 | Test loss: 0.4938 | Test acc: 82.7338\n",
      "Train loss: 0.0001 | Test loss: 0.4960 | Test acc: 82.7024\n",
      "Train loss: 0.0002 | Test loss: 0.4942 | Test acc: 83.0318\n",
      "Train loss: 0.0003 | Test loss: 0.5386 | Test acc: 80.6267\n",
      "Train loss: 0.0002 | Test loss: 0.5341 | Test acc: 81.2181\n",
      "Train loss: 0.0003 | Test loss: 0.4980 | Test acc: 82.8174\n",
      "Train loss: 0.0003 | Test loss: 0.4954 | Test acc: 82.6428\n",
      "Train loss: 0.0005 | Test loss: 0.5125 | Test acc: 81.6338\n",
      "Train loss: 0.0003 | Test loss: 0.5074 | Test acc: 82.2297\n",
      "Train loss: 0.0003 | Test loss: 0.5102 | Test acc: 82.0818\n",
      "Train loss: 0.0001 | Test loss: 0.5141 | Test acc: 81.6820\n",
      "Train loss: 0.0002 | Test loss: 0.4824 | Test acc: 83.3780\n",
      "Train loss: 0.0002 | Test loss: 0.5281 | Test acc: 80.9273\n",
      "Train loss: 0.0004 | Test loss: 0.5084 | Test acc: 82.3372\n",
      "Train loss: 0.0002 | Test loss: 0.5271 | Test acc: 81.4332\n",
      "Train loss: 0.0003 | Test loss: 0.5785 | Test acc: 80.4519\n",
      "Train loss: 0.0001 | Test loss: 0.5256 | Test acc: 81.9863\n",
      "Train loss: 0.0002 | Test loss: 0.5084 | Test acc: 82.7400\n",
      "Train loss: 0.0002 | Test loss: 0.4985 | Test acc: 82.8921\n",
      "Train loss: 0.0002 | Test loss: 0.5020 | Test acc: 82.5931\n",
      "Train loss: 0.0002 | Test loss: 0.5072 | Test acc: 83.0514\n",
      "Train loss: 0.0002 | Test loss: 0.4989 | Test acc: 82.9930\n",
      "Train loss: 0.0003 | Test loss: 0.5171 | Test acc: 81.9545\n",
      "Train loss: 0.0003 | Test loss: 0.5039 | Test acc: 82.6001\n",
      "Train loss: 0.0002 | Test loss: 0.4818 | Test acc: 83.5506\n",
      "Train loss: 0.0003 | Test loss: 0.5072 | Test acc: 83.1543\n",
      "Train loss: 0.0002 | Test loss: 0.5091 | Test acc: 82.1646\n",
      "Train loss: 0.0002 | Test loss: 0.5598 | Test acc: 79.8751\n",
      "Train loss: 0.0006 | Test loss: 0.5003 | Test acc: 82.3838\n",
      "Train loss: 0.0002 | Test loss: 0.5505 | Test acc: 79.7760\n",
      "Train loss: 0.0003 | Test loss: 0.5054 | Test acc: 82.6830\n",
      "Train loss: 0.0003 | Test loss: 0.5083 | Test acc: 82.0633\n",
      "Train loss: 0.0002 | Test loss: 0.5352 | Test acc: 80.7035\n",
      "Train loss: 0.0002 | Test loss: 0.4848 | Test acc: 83.1452\n",
      "Train loss: 0.0002 | Test loss: 0.4817 | Test acc: 83.5224\n",
      "Train loss: 0.0004 | Test loss: 0.4907 | Test acc: 83.0644\n",
      "Train loss: 0.0004 | Test loss: 0.5090 | Test acc: 81.8648\n",
      "Train loss: 0.0002 | Test loss: 0.5252 | Test acc: 81.3219\n",
      "Train loss: 0.0002 | Test loss: 0.5840 | Test acc: 80.0721\n",
      "Train loss: 0.0003 | Test loss: 0.4847 | Test acc: 83.3229\n",
      "Train loss: 0.0002 | Test loss: 0.4999 | Test acc: 82.4048\n",
      "Train loss: 0.0003 | Test loss: 0.5127 | Test acc: 82.0225\n",
      "Train loss: 0.0002 | Test loss: 0.4833 | Test acc: 83.5987\n",
      "Train loss: 0.0004 | Test loss: 0.4884 | Test acc: 83.5738\n",
      "Train loss: 0.0003 | Test loss: 0.5180 | Test acc: 81.8265\n",
      "Train loss: 0.0001 | Test loss: 0.5102 | Test acc: 81.8010\n",
      "Train loss: 0.0003 | Test loss: 0.5385 | Test acc: 81.8508\n",
      "Train loss: 0.0004 | Test loss: 0.5138 | Test acc: 81.8809\n",
      "Train loss: 0.0004 | Test loss: 0.5032 | Test acc: 82.8095\n",
      "Train loss: 0.0002 | Test loss: 0.4816 | Test acc: 83.4914\n",
      "Train loss: 0.0001 | Test loss: 0.4964 | Test acc: 82.7947\n",
      "Train loss: 0.0003 | Test loss: 0.5337 | Test acc: 81.0852\n",
      "Train loss: 0.0003 | Test loss: 0.4845 | Test acc: 83.4360\n",
      "Train loss: 0.0002 | Test loss: 0.5093 | Test acc: 82.2155\n",
      "Train loss: 0.0003 | Test loss: 0.5532 | Test acc: 80.8737\n",
      "Train loss: 0.0004 | Test loss: 0.5138 | Test acc: 82.1274\n",
      "Train loss: 0.0002 | Test loss: 0.5114 | Test acc: 82.2312\n",
      "Train loss: 0.0003 | Test loss: 0.5021 | Test acc: 82.5111\n",
      "Train loss: 0.0003 | Test loss: 0.5026 | Test acc: 82.8016\n",
      "Train loss: 0.0002 | Test loss: 0.5658 | Test acc: 80.0269\n",
      "Train loss: 0.0002 | Test loss: 0.5149 | Test acc: 81.8551\n",
      "Train loss: 0.0005 | Test loss: 0.5431 | Test acc: 81.5215\n",
      "Train loss: 0.0003 | Test loss: 0.4917 | Test acc: 83.2876\n",
      "Train loss: 0.0002 | Test loss: 0.5156 | Test acc: 81.9554\n",
      "Train loss: 0.0002 | Test loss: 0.4946 | Test acc: 82.9495\n",
      "Train loss: 0.0002 | Test loss: 0.5198 | Test acc: 82.6232\n",
      "Train loss: 0.0002 | Test loss: 0.5023 | Test acc: 82.8518\n",
      "Train loss: 0.0005 | Test loss: 0.5010 | Test acc: 82.9923\n",
      "Train loss: 0.0003 | Test loss: 0.4961 | Test acc: 82.9628\n",
      "Train loss: 0.0001 | Test loss: 0.4940 | Test acc: 83.1824\n",
      "Train loss: 0.0003 | Test loss: 0.5064 | Test acc: 82.4143\n",
      "Train loss: 0.0003 | Test loss: 0.5277 | Test acc: 81.4035\n",
      "Train loss: 0.0003 | Test loss: 0.5498 | Test acc: 80.0125\n",
      "Train loss: 0.0002 | Test loss: 0.5338 | Test acc: 81.3758\n",
      "Train loss: 0.0003 | Test loss: 0.4908 | Test acc: 82.8878\n",
      "Train loss: 0.0002 | Test loss: 0.4763 | Test acc: 83.4617\n",
      "Train loss: 0.0002 | Test loss: 0.4938 | Test acc: 83.0242\n",
      "Train loss: 0.0002 | Test loss: 0.4912 | Test acc: 83.2625\n",
      "Train loss: 0.0003 | Test loss: 0.4963 | Test acc: 83.2732\n",
      "Train loss: 0.0002 | Test loss: 0.5623 | Test acc: 80.3579\n",
      "Train loss: 0.0002 | Test loss: 0.4974 | Test acc: 83.0543\n",
      "Train loss: 0.0004 | Test loss: 0.5247 | Test acc: 82.5138\n",
      "Train loss: 0.0004 | Test loss: 0.5558 | Test acc: 81.1043\n",
      "Train loss: 0.0003 | Test loss: 0.5462 | Test acc: 81.5391\n",
      "Train loss: 0.0002 | Test loss: 0.5116 | Test acc: 82.4590\n",
      "Train loss: 0.0003 | Test loss: 0.5318 | Test acc: 81.6233\n",
      "Train loss: 0.0002 | Test loss: 0.5285 | Test acc: 81.9101\n",
      "Train loss: 0.0004 | Test loss: 0.5705 | Test acc: 79.0956\n",
      "Train loss: 0.0003 | Test loss: 0.5027 | Test acc: 82.6409\n",
      "Train loss: 0.0002 | Test loss: 0.5064 | Test acc: 82.6622\n",
      "Train loss: 0.0002 | Test loss: 0.5147 | Test acc: 82.6922\n",
      "Train loss: 0.0003 | Test loss: 0.5151 | Test acc: 81.8037\n",
      "Train loss: 0.0002 | Test loss: 0.4940 | Test acc: 83.1487\n",
      "Train loss: 0.0002 | Test loss: 0.4870 | Test acc: 83.1830\n",
      "Train loss: 0.0003 | Test loss: 0.5141 | Test acc: 82.3844\n",
      "Train loss: 0.0001 | Test loss: 0.5041 | Test acc: 82.2121\n",
      "Train loss: 0.0002 | Test loss: 0.5121 | Test acc: 82.2415\n",
      "Train loss: 0.0003 | Test loss: 0.5571 | Test acc: 80.7739\n",
      "Train loss: 0.0003 | Test loss: 0.4998 | Test acc: 82.4466\n",
      "Train loss: 0.0002 | Test loss: 0.4953 | Test acc: 82.9811\n",
      "Train loss: 0.0003 | Test loss: 0.5172 | Test acc: 82.1042\n",
      "Looked at 25600 / 60000 samples\n",
      "Train loss: 0.0003 | Test loss: 0.5255 | Test acc: 81.6022\n",
      "Train loss: 0.0003 | Test loss: 0.4904 | Test acc: 83.3378\n",
      "Train loss: 0.0003 | Test loss: 0.5145 | Test acc: 82.3749\n",
      "Train loss: 0.0002 | Test loss: 0.5294 | Test acc: 81.5232\n",
      "Train loss: 0.0002 | Test loss: 0.4989 | Test acc: 82.7085\n",
      "Train loss: 0.0003 | Test loss: 0.4801 | Test acc: 83.2714\n",
      "Train loss: 0.0003 | Test loss: 0.4865 | Test acc: 83.0835\n",
      "Train loss: 0.0002 | Test loss: 0.5550 | Test acc: 80.3972\n",
      "Train loss: 0.0005 | Test loss: 0.6028 | Test acc: 77.5132\n",
      "Train loss: 0.0002 | Test loss: 0.5723 | Test acc: 78.6422\n",
      "Train loss: 0.0002 | Test loss: 0.5309 | Test acc: 80.7225\n",
      "Train loss: 0.0002 | Test loss: 0.4870 | Test acc: 82.7759\n",
      "Train loss: 0.0003 | Test loss: 0.4945 | Test acc: 82.7625\n",
      "Train loss: 0.0003 | Test loss: 0.4760 | Test acc: 83.3115\n",
      "Train loss: 0.0004 | Test loss: 0.5433 | Test acc: 80.4479\n",
      "Train loss: 0.0003 | Test loss: 0.5082 | Test acc: 82.1260\n",
      "Train loss: 0.0001 | Test loss: 0.5006 | Test acc: 82.5407\n",
      "Train loss: 0.0002 | Test loss: 0.5253 | Test acc: 82.3723\n",
      "Train loss: 0.0003 | Test loss: 0.5155 | Test acc: 82.3818\n",
      "Train loss: 0.0002 | Test loss: 0.5269 | Test acc: 81.7728\n",
      "Train loss: 0.0003 | Test loss: 0.5074 | Test acc: 82.0005\n",
      "Train loss: 0.0004 | Test loss: 0.5499 | Test acc: 81.2125\n",
      "Train loss: 0.0004 | Test loss: 0.5341 | Test acc: 80.5410\n",
      "Train loss: 0.0004 | Test loss: 0.5857 | Test acc: 80.1695\n",
      "Train loss: 0.0004 | Test loss: 0.5456 | Test acc: 80.8971\n",
      "Train loss: 0.0001 | Test loss: 0.5597 | Test acc: 80.1606\n",
      "Train loss: 0.0003 | Test loss: 0.4959 | Test acc: 82.6443\n",
      "Train loss: 0.0003 | Test loss: 0.5388 | Test acc: 80.5556\n",
      "Train loss: 0.0003 | Test loss: 0.5366 | Test acc: 80.3592\n",
      "Train loss: 0.0001 | Test loss: 0.4817 | Test acc: 83.3438\n",
      "Train loss: 0.0003 | Test loss: 0.4821 | Test acc: 83.3833\n",
      "Train loss: 0.0002 | Test loss: 0.5089 | Test acc: 82.5348\n",
      "Train loss: 0.0004 | Test loss: 0.5125 | Test acc: 82.0428\n",
      "Train loss: 0.0001 | Test loss: 0.5203 | Test acc: 81.6219\n",
      "Train loss: 0.0003 | Test loss: 0.5019 | Test acc: 81.9800\n",
      "Train loss: 0.0002 | Test loss: 0.4820 | Test acc: 83.6185\n",
      "Train loss: 0.0002 | Test loss: 0.5004 | Test acc: 82.7252\n",
      "Train loss: 0.0002 | Test loss: 0.4959 | Test acc: 82.1633\n",
      "Train loss: 0.0002 | Test loss: 0.4824 | Test acc: 83.4794\n",
      "Train loss: 0.0002 | Test loss: 0.4859 | Test acc: 83.4536\n",
      "Train loss: 0.0002 | Test loss: 0.4952 | Test acc: 82.5350\n",
      "Train loss: 0.0004 | Test loss: 0.5017 | Test acc: 82.1427\n",
      "Train loss: 0.0002 | Test loss: 0.4957 | Test acc: 82.3511\n",
      "Train loss: 0.0002 | Test loss: 0.5065 | Test acc: 82.0123\n",
      "Train loss: 0.0002 | Test loss: 0.5231 | Test acc: 81.3623\n",
      "Train loss: 0.0002 | Test loss: 0.4805 | Test acc: 83.4768\n",
      "Train loss: 0.0002 | Test loss: 0.5373 | Test acc: 81.5167\n",
      "Train loss: 0.0003 | Test loss: 0.5030 | Test acc: 82.1694\n",
      "Train loss: 0.0003 | Test loss: 0.4773 | Test acc: 83.3795\n",
      "Train loss: 0.0001 | Test loss: 0.4901 | Test acc: 82.9840\n",
      "Train loss: 0.0001 | Test loss: 0.4724 | Test acc: 83.8813\n",
      "Train loss: 0.0002 | Test loss: 0.5009 | Test acc: 81.4980\n",
      "Train loss: 0.0003 | Test loss: 0.5160 | Test acc: 82.7085\n",
      "Train loss: 0.0001 | Test loss: 0.5045 | Test acc: 83.0418\n",
      "Train loss: 0.0003 | Test loss: 0.5180 | Test acc: 82.0445\n",
      "Train loss: 0.0004 | Test loss: 0.4858 | Test acc: 82.8600\n",
      "Train loss: 0.0002 | Test loss: 0.4904 | Test acc: 82.7228\n",
      "Train loss: 0.0003 | Test loss: 0.4725 | Test acc: 83.6808\n",
      "Train loss: 0.0002 | Test loss: 0.5048 | Test acc: 81.7470\n",
      "Train loss: 0.0003 | Test loss: 0.5110 | Test acc: 82.4896\n",
      "Train loss: 0.0001 | Test loss: 0.5533 | Test acc: 80.7947\n",
      "Train loss: 0.0002 | Test loss: 0.5775 | Test acc: 78.4730\n",
      "Train loss: 0.0003 | Test loss: 0.5072 | Test acc: 82.5590\n",
      "Train loss: 0.0003 | Test loss: 0.5372 | Test acc: 81.3640\n",
      "Train loss: 0.0004 | Test loss: 0.5246 | Test acc: 82.0990\n",
      "Train loss: 0.0002 | Test loss: 0.5026 | Test acc: 83.1696\n",
      "Train loss: 0.0002 | Test loss: 0.5002 | Test acc: 82.9834\n",
      "Train loss: 0.0002 | Test loss: 0.4883 | Test acc: 83.1525\n",
      "Train loss: 0.0002 | Test loss: 0.4997 | Test acc: 82.8835\n",
      "Train loss: 0.0002 | Test loss: 0.4944 | Test acc: 83.1023\n",
      "Train loss: 0.0004 | Test loss: 0.4964 | Test acc: 82.4640\n",
      "Train loss: 0.0002 | Test loss: 0.5234 | Test acc: 81.4835\n",
      "Train loss: 0.0002 | Test loss: 0.4874 | Test acc: 83.1976\n",
      "Train loss: 0.0002 | Test loss: 0.4935 | Test acc: 82.8137\n",
      "Train loss: 0.0002 | Test loss: 0.5032 | Test acc: 82.0238\n",
      "Train loss: 0.0002 | Test loss: 0.5014 | Test acc: 82.8899\n",
      "Train loss: 0.0002 | Test loss: 0.4816 | Test acc: 83.1023\n",
      "Train loss: 0.0003 | Test loss: 0.5705 | Test acc: 80.2775\n",
      "Train loss: 0.0002 | Test loss: 0.5049 | Test acc: 82.8643\n",
      "Train loss: 0.0001 | Test loss: 0.5180 | Test acc: 82.1837\n",
      "Train loss: 0.0002 | Test loss: 0.4868 | Test acc: 83.4994\n",
      "Train loss: 0.0002 | Test loss: 0.5086 | Test acc: 82.7448\n",
      "Train loss: 0.0002 | Test loss: 0.4900 | Test acc: 83.2715\n",
      "Train loss: 0.0002 | Test loss: 0.5233 | Test acc: 81.9154\n",
      "Train loss: 0.0002 | Test loss: 0.5419 | Test acc: 81.0724\n",
      "Train loss: 0.0002 | Test loss: 0.5035 | Test acc: 82.4275\n",
      "Train loss: 0.0003 | Test loss: 0.5100 | Test acc: 82.1224\n",
      "Train loss: 0.0002 | Test loss: 0.4872 | Test acc: 83.0499\n",
      "Train loss: 0.0001 | Test loss: 0.5091 | Test acc: 82.8432\n",
      "Train loss: 0.0002 | Test loss: 0.5202 | Test acc: 81.7044\n",
      "Train loss: 0.0002 | Test loss: 0.5087 | Test acc: 82.6892\n",
      "Train loss: 0.0002 | Test loss: 0.5180 | Test acc: 81.9635\n",
      "Train loss: 0.0003 | Test loss: 0.5233 | Test acc: 81.9512\n",
      "Train loss: 0.0002 | Test loss: 0.5412 | Test acc: 81.6816\n",
      "Train loss: 0.0003 | Test loss: 0.5263 | Test acc: 82.4295\n",
      "Train loss: 0.0003 | Test loss: 0.5767 | Test acc: 79.7761\n",
      "Train loss: 0.0004 | Test loss: 0.5007 | Test acc: 82.5232\n",
      "Train loss: 0.0002 | Test loss: 0.5018 | Test acc: 82.1327\n",
      "Train loss: 0.0002 | Test loss: 0.4789 | Test acc: 83.3894\n",
      "Train loss: 0.0002 | Test loss: 0.4872 | Test acc: 83.1638\n",
      "Train loss: 0.0003 | Test loss: 0.5090 | Test acc: 82.7537\n",
      "Train loss: 0.0005 | Test loss: 0.5253 | Test acc: 81.5643\n",
      "Train loss: 0.0003 | Test loss: 0.4990 | Test acc: 82.0897\n",
      "Train loss: 0.0002 | Test loss: 0.4973 | Test acc: 83.0997\n",
      "Train loss: 0.0003 | Test loss: 0.4797 | Test acc: 83.2627\n",
      "Train loss: 0.0003 | Test loss: 0.5022 | Test acc: 82.8139\n",
      "Train loss: 0.0004 | Test loss: 0.5438 | Test acc: 80.0869\n",
      "Train loss: 0.0004 | Test loss: 0.4836 | Test acc: 83.4627\n",
      "Train loss: 0.0002 | Test loss: 0.4838 | Test acc: 83.4236\n",
      "Train loss: 0.0002 | Test loss: 0.5117 | Test acc: 81.7462\n",
      "Train loss: 0.0004 | Test loss: 0.4837 | Test acc: 83.4281\n",
      "Train loss: 0.0003 | Test loss: 0.4918 | Test acc: 82.8744\n",
      "Train loss: 0.0002 | Test loss: 0.4870 | Test acc: 83.1522\n",
      "Train loss: 0.0001 | Test loss: 0.4796 | Test acc: 83.6822\n",
      "Train loss: 0.0001 | Test loss: 0.4770 | Test acc: 83.5142\n",
      "Train loss: 0.0004 | Test loss: 0.5557 | Test acc: 80.0791\n",
      "Train loss: 0.0003 | Test loss: 0.4790 | Test acc: 83.5925\n",
      "Train loss: 0.0002 | Test loss: 0.5015 | Test acc: 82.6852\n",
      "Train loss: 0.0001 | Test loss: 0.4928 | Test acc: 83.1615\n",
      "Train loss: 0.0003 | Test loss: 0.5205 | Test acc: 82.9234\n",
      "Train loss: 0.0002 | Test loss: 0.5155 | Test acc: 83.0724\n",
      "Train loss: 0.0004 | Test loss: 0.5001 | Test acc: 82.7634\n",
      "Train loss: 0.0005 | Test loss: 0.4868 | Test acc: 83.2516\n",
      "Train loss: 0.0003 | Test loss: 0.4984 | Test acc: 82.2348\n",
      "Train loss: 0.0003 | Test loss: 0.5044 | Test acc: 82.6110\n",
      "Train loss: 0.0003 | Test loss: 0.5019 | Test acc: 82.5922\n",
      "Train loss: 0.0003 | Test loss: 0.5223 | Test acc: 81.5538\n",
      "Train loss: 0.0002 | Test loss: 0.4925 | Test acc: 83.1280\n",
      "Train loss: 0.0004 | Test loss: 0.6111 | Test acc: 78.7300\n",
      "Train loss: 0.0004 | Test loss: 0.4818 | Test acc: 83.0690\n",
      "Train loss: 0.0002 | Test loss: 0.4744 | Test acc: 83.5422\n",
      "Train loss: 0.0002 | Test loss: 0.4763 | Test acc: 83.5536\n",
      "Train loss: 0.0002 | Test loss: 0.4874 | Test acc: 82.7150\n",
      "Train loss: 0.0005 | Test loss: 0.5021 | Test acc: 82.0334\n",
      "Train loss: 0.0003 | Test loss: 0.5079 | Test acc: 82.8200\n",
      "Train loss: 0.0002 | Test loss: 0.4874 | Test acc: 83.3417\n",
      "Train loss: 0.0003 | Test loss: 0.4907 | Test acc: 82.8541\n",
      "Train loss: 0.0002 | Test loss: 0.4725 | Test acc: 83.6114\n",
      "Train loss: 0.0002 | Test loss: 0.4738 | Test acc: 83.7735\n",
      "Train loss: 0.0003 | Test loss: 0.4861 | Test acc: 83.3447\n",
      "Train loss: 0.0002 | Test loss: 0.5056 | Test acc: 82.6744\n",
      "Train loss: 0.0003 | Test loss: 0.5081 | Test acc: 82.7122\n",
      "Train loss: 0.0002 | Test loss: 0.5098 | Test acc: 83.0518\n",
      "Train loss: 0.0003 | Test loss: 0.5659 | Test acc: 79.0593\n",
      "Train loss: 0.0003 | Test loss: 0.5488 | Test acc: 81.7422\n",
      "Train loss: 0.0002 | Test loss: 0.5489 | Test acc: 81.6310\n",
      "Train loss: 0.0002 | Test loss: 0.5023 | Test acc: 82.6889\n",
      "Train loss: 0.0004 | Test loss: 0.5435 | Test acc: 80.7654\n",
      "Train loss: 0.0003 | Test loss: 0.5364 | Test acc: 81.5580\n",
      "Train loss: 0.0003 | Test loss: 0.6171 | Test acc: 78.0162\n",
      "Train loss: 0.0003 | Test loss: 0.5301 | Test acc: 80.7405\n",
      "Train loss: 0.0002 | Test loss: 0.4797 | Test acc: 83.2052\n",
      "Train loss: 0.0004 | Test loss: 0.4783 | Test acc: 83.8122\n",
      "Train loss: 0.0002 | Test loss: 0.4944 | Test acc: 83.3448\n",
      "Train loss: 0.0002 | Test loss: 0.4864 | Test acc: 83.6628\n",
      "Train loss: 0.0000 | Test loss: 0.5041 | Test acc: 83.3344\n",
      "Train loss: 0.0001 | Test loss: 0.5379 | Test acc: 82.4847\n",
      "Train loss: 0.0002 | Test loss: 0.5304 | Test acc: 82.3821\n",
      "Train loss: 0.0003 | Test loss: 0.4906 | Test acc: 83.2804\n",
      "Train loss: 0.0002 | Test loss: 0.5105 | Test acc: 82.7641\n",
      "Train loss: 0.0001 | Test loss: 0.4942 | Test acc: 83.2916\n",
      "Train loss: 0.0002 | Test loss: 0.5253 | Test acc: 80.7473\n",
      "Train loss: 0.0002 | Test loss: 0.5163 | Test acc: 81.6577\n",
      "Train loss: 0.0002 | Test loss: 0.4742 | Test acc: 83.1383\n",
      "Train loss: 0.0003 | Test loss: 0.4879 | Test acc: 83.1730\n",
      "Train loss: 0.0003 | Test loss: 0.4946 | Test acc: 82.9235\n",
      "Train loss: 0.0003 | Test loss: 0.4966 | Test acc: 83.2022\n",
      "Train loss: 0.0004 | Test loss: 0.5402 | Test acc: 81.8253\n",
      "Train loss: 0.0003 | Test loss: 0.5064 | Test acc: 82.9591\n",
      "Train loss: 0.0003 | Test loss: 0.4980 | Test acc: 82.4036\n",
      "Train loss: 0.0001 | Test loss: 0.4822 | Test acc: 83.3104\n",
      "Train loss: 0.0002 | Test loss: 0.4838 | Test acc: 83.6428\n",
      "Train loss: 0.0002 | Test loss: 0.4955 | Test acc: 83.1047\n",
      "Train loss: 0.0001 | Test loss: 0.4764 | Test acc: 83.7020\n",
      "Train loss: 0.0003 | Test loss: 0.5525 | Test acc: 80.1396\n",
      "Train loss: 0.0002 | Test loss: 0.5418 | Test acc: 80.9270\n",
      "Train loss: 0.0003 | Test loss: 0.4801 | Test acc: 83.0760\n",
      "Train loss: 0.0002 | Test loss: 0.5103 | Test acc: 81.8249\n",
      "Train loss: 0.0003 | Test loss: 0.5239 | Test acc: 80.8026\n",
      "Train loss: 0.0003 | Test loss: 0.5476 | Test acc: 81.7677\n",
      "Train loss: 0.0001 | Test loss: 0.5263 | Test acc: 81.9805\n",
      "Train loss: 0.0004 | Test loss: 0.5177 | Test acc: 82.0910\n",
      "Train loss: 0.0003 | Test loss: 0.4902 | Test acc: 82.8401\n",
      "Train loss: 0.0002 | Test loss: 0.5150 | Test acc: 82.5430\n",
      "Train loss: 0.0004 | Test loss: 0.5715 | Test acc: 79.7665\n",
      "Train loss: 0.0003 | Test loss: 0.5310 | Test acc: 81.0556\n",
      "Train loss: 0.0004 | Test loss: 0.4998 | Test acc: 81.9782\n",
      "Train loss: 0.0001 | Test loss: 0.4886 | Test acc: 82.5902\n",
      "Train loss: 0.0002 | Test loss: 0.5067 | Test acc: 82.0430\n",
      "Train loss: 0.0003 | Test loss: 0.5049 | Test acc: 82.3108\n",
      "Train loss: 0.0004 | Test loss: 0.5499 | Test acc: 80.0054\n",
      "Train loss: 0.0003 | Test loss: 0.5681 | Test acc: 79.8283\n",
      "Train loss: 0.0004 | Test loss: 0.5509 | Test acc: 80.8361\n",
      "Train loss: 0.0004 | Test loss: 0.4893 | Test acc: 82.4967\n",
      "Train loss: 0.0005 | Test loss: 0.5123 | Test acc: 81.6633\n",
      "Train loss: 0.0004 | Test loss: 0.5065 | Test acc: 82.2797\n",
      "Train loss: 0.0004 | Test loss: 0.5445 | Test acc: 80.0752\n",
      "Train loss: 0.0003 | Test loss: 0.5353 | Test acc: 81.0266\n",
      "Train loss: 0.0004 | Test loss: 0.5013 | Test acc: 82.2277\n",
      "Train loss: 0.0002 | Test loss: 0.4867 | Test acc: 83.1201\n",
      "Train loss: 0.0002 | Test loss: 0.4763 | Test acc: 83.8618\n",
      "Train loss: 0.0002 | Test loss: 0.4941 | Test acc: 82.3266\n",
      "Train loss: 0.0002 | Test loss: 0.4732 | Test acc: 83.5498\n",
      "Train loss: 0.0002 | Test loss: 0.5188 | Test acc: 81.5768\n",
      "Train loss: 0.0002 | Test loss: 0.4913 | Test acc: 82.6688\n",
      "Train loss: 0.0003 | Test loss: 0.4675 | Test acc: 83.9502\n",
      "Train loss: 0.0003 | Test loss: 0.4849 | Test acc: 82.6464\n",
      "Train loss: 0.0003 | Test loss: 0.5432 | Test acc: 81.4442\n",
      "Train loss: 0.0002 | Test loss: 0.4809 | Test acc: 83.8265\n",
      "Train loss: 0.0003 | Test loss: 0.5369 | Test acc: 81.4679\n",
      "Train loss: 0.0004 | Test loss: 0.5190 | Test acc: 82.3789\n",
      "Train loss: 0.0003 | Test loss: 0.5505 | Test acc: 80.0555\n",
      "Train loss: 0.0002 | Test loss: 0.5269 | Test acc: 81.6555\n",
      "Train loss: 0.0002 | Test loss: 0.4901 | Test acc: 83.1483\n",
      "Train loss: 0.0005 | Test loss: 0.4902 | Test acc: 82.9434\n",
      "Train loss: 0.0001 | Test loss: 0.4721 | Test acc: 83.6616\n",
      "Train loss: 0.0005 | Test loss: 0.4958 | Test acc: 82.6954\n",
      "Train loss: 0.0003 | Test loss: 0.4844 | Test acc: 83.1116\n",
      "Train loss: 0.0001 | Test loss: 0.5086 | Test acc: 82.1246\n",
      "Train loss: 0.0002 | Test loss: 0.5426 | Test acc: 81.1430\n",
      "Train loss: 0.0003 | Test loss: 0.4985 | Test acc: 82.7672\n",
      "Train loss: 0.0002 | Test loss: 0.5015 | Test acc: 82.2732\n",
      "Train loss: 0.0002 | Test loss: 0.5306 | Test acc: 81.7325\n",
      "Train loss: 0.0003 | Test loss: 0.4841 | Test acc: 83.3182\n",
      "Train loss: 0.0003 | Test loss: 0.4997 | Test acc: 82.4347\n",
      "Train loss: 0.0003 | Test loss: 0.4846 | Test acc: 82.7115\n",
      "Train loss: 0.0003 | Test loss: 0.4766 | Test acc: 83.4512\n",
      "Train loss: 0.0002 | Test loss: 0.4834 | Test acc: 82.8944\n",
      "Train loss: 0.0002 | Test loss: 0.4885 | Test acc: 82.5033\n",
      "Train loss: 0.0004 | Test loss: 0.6414 | Test acc: 75.0539\n",
      "Train loss: 0.0004 | Test loss: 0.4691 | Test acc: 83.5864\n",
      "Train loss: 0.0001 | Test loss: 0.4850 | Test acc: 83.2043\n",
      "Train loss: 0.0002 | Test loss: 0.5137 | Test acc: 81.5757\n",
      "Train loss: 0.0002 | Test loss: 0.5179 | Test acc: 81.3708\n",
      "Train loss: 0.0002 | Test loss: 0.5034 | Test acc: 82.2688\n",
      "Train loss: 0.0002 | Test loss: 0.5026 | Test acc: 82.5212\n",
      "Train loss: 0.0003 | Test loss: 0.5110 | Test acc: 82.5320\n",
      "Train loss: 0.0002 | Test loss: 0.4958 | Test acc: 82.8116\n",
      "Train loss: 0.0002 | Test loss: 0.4807 | Test acc: 83.5214\n",
      "Train loss: 0.0002 | Test loss: 0.5137 | Test acc: 82.5552\n",
      "Train loss: 0.0004 | Test loss: 0.4825 | Test acc: 83.2909\n",
      "Train loss: 0.0004 | Test loss: 0.4910 | Test acc: 82.9738\n",
      "Train loss: 0.0001 | Test loss: 0.4882 | Test acc: 83.0127\n",
      "Train loss: 0.0002 | Test loss: 0.5187 | Test acc: 81.7748\n",
      "Train loss: 0.0003 | Test loss: 0.4999 | Test acc: 82.3300\n",
      "Train loss: 0.0003 | Test loss: 0.5038 | Test acc: 82.0622\n",
      "Train loss: 0.0003 | Test loss: 0.4888 | Test acc: 82.7202\n",
      "Train loss: 0.0002 | Test loss: 0.5056 | Test acc: 82.4029\n",
      "Train loss: 0.0002 | Test loss: 0.5249 | Test acc: 81.6131\n",
      "Train loss: 0.0002 | Test loss: 0.4799 | Test acc: 83.4177\n",
      "Train loss: 0.0004 | Test loss: 0.4940 | Test acc: 82.4350\n",
      "Train loss: 0.0002 | Test loss: 0.4967 | Test acc: 82.4019\n",
      "Train loss: 0.0002 | Test loss: 0.4767 | Test acc: 83.5101\n",
      "Train loss: 0.0002 | Test loss: 0.4842 | Test acc: 83.5136\n",
      "Train loss: 0.0003 | Test loss: 0.5436 | Test acc: 81.2173\n",
      "Train loss: 0.0003 | Test loss: 0.5151 | Test acc: 82.4779\n",
      "Train loss: 0.0002 | Test loss: 0.5070 | Test acc: 82.6617\n",
      "Train loss: 0.0004 | Test loss: 0.4957 | Test acc: 82.4426\n",
      "Train loss: 0.0002 | Test loss: 0.4899 | Test acc: 82.7814\n",
      "Train loss: 0.0003 | Test loss: 0.4914 | Test acc: 82.5528\n",
      "Train loss: 0.0002 | Test loss: 0.5291 | Test acc: 81.0545\n",
      "Train loss: 0.0003 | Test loss: 0.5032 | Test acc: 82.0980\n",
      "Train loss: 0.0002 | Test loss: 0.5065 | Test acc: 81.9716\n",
      "Train loss: 0.0002 | Test loss: 0.4881 | Test acc: 83.4588\n",
      "Train loss: 0.0003 | Test loss: 0.5194 | Test acc: 81.3269\n",
      "Train loss: 0.0002 | Test loss: 0.5052 | Test acc: 82.4184\n",
      "Train loss: 0.0003 | Test loss: 0.4890 | Test acc: 83.1507\n",
      "Train loss: 0.0002 | Test loss: 0.4889 | Test acc: 83.3627\n",
      "Train loss: 0.0003 | Test loss: 0.4880 | Test acc: 82.6146\n",
      "Train loss: 0.0003 | Test loss: 0.5445 | Test acc: 80.3558\n",
      "Train loss: 0.0004 | Test loss: 0.5550 | Test acc: 80.6281\n",
      "Train loss: 0.0002 | Test loss: 0.5652 | Test acc: 79.4309\n",
      "Train loss: 0.0004 | Test loss: 0.5105 | Test acc: 82.4323\n",
      "Train loss: 0.0003 | Test loss: 0.5424 | Test acc: 81.6631\n",
      "Train loss: 0.0004 | Test loss: 0.5147 | Test acc: 81.8903\n",
      "Train loss: 0.0002 | Test loss: 0.4901 | Test acc: 82.9993\n",
      "Train loss: 0.0003 | Test loss: 0.5107 | Test acc: 82.4437\n",
      "Train loss: 0.0004 | Test loss: 0.5529 | Test acc: 80.2255\n",
      "Train loss: 0.0004 | Test loss: 0.5117 | Test acc: 82.9141\n",
      "Train loss: 0.0002 | Test loss: 0.5002 | Test acc: 82.7829\n",
      "Train loss: 0.0001 | Test loss: 0.4870 | Test acc: 83.2317\n",
      "Train loss: 0.0004 | Test loss: 0.5383 | Test acc: 80.4177\n",
      "Train loss: 0.0002 | Test loss: 0.4914 | Test acc: 82.5752\n",
      "Train loss: 0.0003 | Test loss: 0.5018 | Test acc: 82.5122\n",
      "Train loss: 0.0002 | Test loss: 0.4838 | Test acc: 83.1011\n",
      "Train loss: 0.0003 | Test loss: 0.5273 | Test acc: 82.0047\n",
      "Train loss: 0.0001 | Test loss: 0.4941 | Test acc: 83.0296\n",
      "Train loss: 0.0004 | Test loss: 0.5800 | Test acc: 80.6267\n",
      "Train loss: 0.0002 | Test loss: 0.4995 | Test acc: 82.6358\n",
      "Train loss: 0.0001 | Test loss: 0.4828 | Test acc: 83.0516\n",
      "Train loss: 0.0001 | Test loss: 0.5090 | Test acc: 81.6851\n",
      "Train loss: 0.0004 | Test loss: 0.5320 | Test acc: 80.8720\n",
      "Train loss: 0.0002 | Test loss: 0.4988 | Test acc: 82.2771\n",
      "Train loss: 0.0002 | Test loss: 0.5273 | Test acc: 80.7740\n",
      "Train loss: 0.0002 | Test loss: 0.4989 | Test acc: 82.3767\n",
      "Train loss: 0.0002 | Test loss: 0.4778 | Test acc: 83.2903\n",
      "Train loss: 0.0002 | Test loss: 0.5014 | Test acc: 82.7541\n",
      "Train loss: 0.0003 | Test loss: 0.5348 | Test acc: 81.3946\n",
      "Train loss: 0.0002 | Test loss: 0.5072 | Test acc: 82.5783\n",
      "Train loss: 0.0004 | Test loss: 0.5020 | Test acc: 82.1129\n",
      "Train loss: 0.0002 | Test loss: 0.4941 | Test acc: 82.8302\n",
      "Train loss: 0.0002 | Test loss: 0.4832 | Test acc: 83.0422\n",
      "Train loss: 0.0001 | Test loss: 0.5126 | Test acc: 82.0844\n",
      "Train loss: 0.0003 | Test loss: 0.5219 | Test acc: 80.6536\n",
      "Train loss: 0.0004 | Test loss: 0.5199 | Test acc: 82.2165\n",
      "Train loss: 0.0002 | Test loss: 0.5130 | Test acc: 82.2116\n",
      "Train loss: 0.0001 | Test loss: 0.4805 | Test acc: 83.4496\n",
      "Train loss: 0.0003 | Test loss: 0.5362 | Test acc: 81.1772\n",
      "Train loss: 0.0002 | Test loss: 0.5327 | Test acc: 81.6891\n",
      "Train loss: 0.0003 | Test loss: 0.5368 | Test acc: 81.7506\n",
      "Train loss: 0.0002 | Test loss: 0.5883 | Test acc: 79.5843\n",
      "Train loss: 0.0003 | Test loss: 0.5188 | Test acc: 82.2431\n",
      "Train loss: 0.0002 | Test loss: 0.4861 | Test acc: 83.1102\n",
      "Train loss: 0.0002 | Test loss: 0.4871 | Test acc: 82.8534\n",
      "Train loss: 0.0003 | Test loss: 0.5575 | Test acc: 81.5946\n",
      "Train loss: 0.0003 | Test loss: 0.5324 | Test acc: 80.9715\n",
      "Train loss: 0.0002 | Test loss: 0.4756 | Test acc: 83.4256\n",
      "Train loss: 0.0002 | Test loss: 0.4908 | Test acc: 82.7745\n",
      "Train loss: 0.0002 | Test loss: 0.5119 | Test acc: 82.1335\n",
      "Train loss: 0.0003 | Test loss: 0.5190 | Test acc: 82.3211\n",
      "Train loss: 0.0003 | Test loss: 0.5132 | Test acc: 81.4831\n",
      "Train loss: 0.0003 | Test loss: 0.4954 | Test acc: 83.0778\n",
      "Train loss: 0.0004 | Test loss: 0.5128 | Test acc: 82.1145\n",
      "Train loss: 0.0002 | Test loss: 0.5073 | Test acc: 82.8203\n",
      "Train loss: 0.0004 | Test loss: 0.5308 | Test acc: 81.7642\n",
      "Train loss: 0.0002 | Test loss: 0.4908 | Test acc: 83.2784\n",
      "Train loss: 0.0002 | Test loss: 0.4937 | Test acc: 83.1834\n",
      "Train loss: 0.0002 | Test loss: 0.4915 | Test acc: 82.8936\n",
      "Train loss: 0.0004 | Test loss: 0.5360 | Test acc: 82.0440\n",
      "Train loss: 0.0004 | Test loss: 0.5174 | Test acc: 82.1012\n",
      "Train loss: 0.0003 | Test loss: 0.5445 | Test acc: 81.9017\n",
      "Train loss: 0.0005 | Test loss: 0.4890 | Test acc: 83.1890\n",
      "Train loss: 0.0003 | Test loss: 0.4845 | Test acc: 83.5326\n",
      "Train loss: 0.0002 | Test loss: 0.4891 | Test acc: 83.1942\n",
      "Train loss: 0.0003 | Test loss: 0.5050 | Test acc: 82.5442\n",
      "Train loss: 0.0002 | Test loss: 0.5011 | Test acc: 82.7018\n",
      "Train loss: 0.0003 | Test loss: 0.4960 | Test acc: 82.8920\n",
      "Train loss: 0.0001 | Test loss: 0.5052 | Test acc: 82.6830\n",
      "Train loss: 0.0004 | Test loss: 0.4958 | Test acc: 82.8820\n",
      "Train loss: 0.0002 | Test loss: 0.5054 | Test acc: 82.1538\n",
      "Train loss: 0.0004 | Test loss: 0.5123 | Test acc: 82.4210\n",
      "Train loss: 0.0002 | Test loss: 0.4755 | Test acc: 83.5700\n",
      "Train loss: 0.0002 | Test loss: 0.5488 | Test acc: 80.3289\n",
      "Train loss: 0.0002 | Test loss: 0.5103 | Test acc: 82.0058\n",
      "Train loss: 0.0002 | Test loss: 0.4832 | Test acc: 83.3590\n",
      "Train loss: 0.0002 | Test loss: 0.5026 | Test acc: 81.6661\n",
      "Train loss: 0.0003 | Test loss: 0.4730 | Test acc: 83.5976\n",
      "Train loss: 0.0003 | Test loss: 0.4752 | Test acc: 83.5738\n",
      "Train loss: 0.0002 | Test loss: 0.4809 | Test acc: 83.5937\n",
      "Train loss: 0.0002 | Test loss: 0.5161 | Test acc: 80.9580\n",
      "Train loss: 0.0004 | Test loss: 0.5024 | Test acc: 82.3273\n",
      "Train loss: 0.0004 | Test loss: 0.5143 | Test acc: 81.8225\n",
      "Train loss: 0.0003 | Test loss: 0.5026 | Test acc: 82.2702\n",
      "Train loss: 0.0003 | Test loss: 0.4816 | Test acc: 83.0504\n",
      "Train loss: 0.0004 | Test loss: 0.4998 | Test acc: 82.6935\n",
      "Train loss: 0.0003 | Test loss: 0.5440 | Test acc: 80.1464\n",
      "Train loss: 0.0003 | Test loss: 0.5543 | Test acc: 80.2980\n",
      "Train loss: 0.0003 | Test loss: 0.4836 | Test acc: 83.4135\n",
      "Train loss: 0.0003 | Test loss: 0.5141 | Test acc: 82.1056\n",
      "Train loss: 0.0002 | Test loss: 0.4921 | Test acc: 83.1497\n",
      "Train loss: 0.0003 | Test loss: 0.4856 | Test acc: 83.0931\n",
      "Train loss: 0.0002 | Test loss: 0.5014 | Test acc: 82.1744\n",
      "Train loss: 0.0001 | Test loss: 0.5019 | Test acc: 81.8620\n",
      "Train loss: 0.0002 | Test loss: 0.4963 | Test acc: 82.3901\n",
      "Train loss: 0.0003 | Test loss: 0.5102 | Test acc: 82.4817\n",
      "Train loss: 0.0002 | Test loss: 0.4838 | Test acc: 83.3406\n",
      "Train loss: 0.0002 | Test loss: 0.4992 | Test acc: 82.6345\n",
      "Train loss: 0.0007 | Test loss: 0.5099 | Test acc: 82.5623\n",
      "Train loss: 0.0002 | Test loss: 0.4767 | Test acc: 83.3109\n",
      "Train loss: 0.0004 | Test loss: 0.4958 | Test acc: 82.7043\n",
      "Train loss: 0.0002 | Test loss: 0.5126 | Test acc: 82.3329\n",
      "Train loss: 0.0005 | Test loss: 0.4993 | Test acc: 82.5714\n",
      "Train loss: 0.0002 | Test loss: 0.4971 | Test acc: 82.4922\n",
      "Train loss: 0.0003 | Test loss: 0.5048 | Test acc: 82.8614\n",
      "Train loss: 0.0002 | Test loss: 0.5353 | Test acc: 82.0139\n",
      "Train loss: 0.0005 | Test loss: 0.4819 | Test acc: 83.4889\n",
      "Train loss: 0.0005 | Test loss: 0.5929 | Test acc: 79.0107\n",
      "Train loss: 0.0003 | Test loss: 0.5256 | Test acc: 81.9916\n",
      "Train loss: 0.0003 | Test loss: 0.5164 | Test acc: 82.1609\n",
      "Train loss: 0.0003 | Test loss: 0.4920 | Test acc: 82.7106\n",
      "Train loss: 0.0002 | Test loss: 0.4746 | Test acc: 83.5210\n",
      "Train loss: 0.0002 | Test loss: 0.5018 | Test acc: 82.2557\n",
      "Train loss: 0.0003 | Test loss: 0.5168 | Test acc: 81.1534\n",
      "Train loss: 0.0002 | Test loss: 0.5090 | Test acc: 82.0085\n",
      "Train loss: 0.0002 | Test loss: 0.4980 | Test acc: 82.6202\n",
      "Train loss: 0.0002 | Test loss: 0.5102 | Test acc: 82.2328\n",
      "Train loss: 0.0001 | Test loss: 0.5114 | Test acc: 82.2915\n",
      "Train loss: 0.0002 | Test loss: 0.4943 | Test acc: 83.0804\n",
      "Train loss: 0.0002 | Test loss: 0.4934 | Test acc: 83.3126\n",
      "Train loss: 0.0001 | Test loss: 0.4889 | Test acc: 83.3732\n",
      "Train loss: 0.0002 | Test loss: 0.4931 | Test acc: 82.7544\n",
      "Train loss: 0.0002 | Test loss: 0.4803 | Test acc: 83.5911\n",
      "Train loss: 0.0002 | Test loss: 0.4933 | Test acc: 82.3158\n",
      "Train loss: 0.0003 | Test loss: 0.5081 | Test acc: 82.0122\n",
      "Train loss: 0.0003 | Test loss: 0.4756 | Test acc: 83.4190\n",
      "Train loss: 0.0003 | Test loss: 0.4806 | Test acc: 83.5033\n",
      "Train loss: 0.0002 | Test loss: 0.4874 | Test acc: 82.7348\n",
      "Train loss: 0.0002 | Test loss: 0.5052 | Test acc: 81.4345\n",
      "Train loss: 0.0002 | Test loss: 0.5152 | Test acc: 81.2905\n",
      "Train loss: 0.0003 | Test loss: 0.5666 | Test acc: 79.0936\n",
      "Looked at 38400 / 60000 samples\n",
      "Train loss: 0.0001 | Test loss: 0.4835 | Test acc: 83.0003\n",
      "Train loss: 0.0003 | Test loss: 0.4894 | Test acc: 82.8131\n",
      "Train loss: 0.0002 | Test loss: 0.4777 | Test acc: 83.4215\n",
      "Train loss: 0.0002 | Test loss: 0.4907 | Test acc: 83.2637\n",
      "Train loss: 0.0004 | Test loss: 0.5054 | Test acc: 82.3846\n",
      "Train loss: 0.0005 | Test loss: 0.5184 | Test acc: 81.6730\n",
      "Train loss: 0.0005 | Test loss: 0.5072 | Test acc: 82.4594\n",
      "Train loss: 0.0002 | Test loss: 0.4897 | Test acc: 82.7515\n",
      "Train loss: 0.0002 | Test loss: 0.4801 | Test acc: 82.9720\n",
      "Train loss: 0.0002 | Test loss: 0.5040 | Test acc: 82.9328\n",
      "Train loss: 0.0003 | Test loss: 0.5010 | Test acc: 82.6731\n",
      "Train loss: 0.0003 | Test loss: 0.5075 | Test acc: 82.0732\n",
      "Train loss: 0.0003 | Test loss: 0.4999 | Test acc: 82.1811\n",
      "Train loss: 0.0003 | Test loss: 0.5101 | Test acc: 81.7721\n",
      "Train loss: 0.0003 | Test loss: 0.4907 | Test acc: 83.3882\n",
      "Train loss: 0.0002 | Test loss: 0.4965 | Test acc: 82.5448\n",
      "Train loss: 0.0003 | Test loss: 0.5428 | Test acc: 81.6435\n",
      "Train loss: 0.0004 | Test loss: 0.5180 | Test acc: 81.2013\n",
      "Train loss: 0.0004 | Test loss: 0.5704 | Test acc: 80.1316\n",
      "Train loss: 0.0003 | Test loss: 0.5531 | Test acc: 80.4577\n",
      "Train loss: 0.0003 | Test loss: 0.5113 | Test acc: 81.0478\n",
      "Train loss: 0.0003 | Test loss: 0.4778 | Test acc: 83.0565\n",
      "Train loss: 0.0002 | Test loss: 0.4992 | Test acc: 82.5537\n",
      "Train loss: 0.0001 | Test loss: 0.4962 | Test acc: 82.6120\n",
      "Train loss: 0.0002 | Test loss: 0.4990 | Test acc: 82.2827\n",
      "Train loss: 0.0003 | Test loss: 0.4837 | Test acc: 82.9306\n",
      "Train loss: 0.0002 | Test loss: 0.4816 | Test acc: 83.0126\n",
      "Train loss: 0.0002 | Test loss: 0.5089 | Test acc: 82.1642\n",
      "Train loss: 0.0003 | Test loss: 0.4890 | Test acc: 82.3412\n",
      "Train loss: 0.0002 | Test loss: 0.4838 | Test acc: 82.7910\n",
      "Train loss: 0.0001 | Test loss: 0.4792 | Test acc: 83.4015\n",
      "Train loss: 0.0003 | Test loss: 0.4971 | Test acc: 82.6347\n",
      "Train loss: 0.0002 | Test loss: 0.5184 | Test acc: 81.5639\n",
      "Train loss: 0.0002 | Test loss: 0.5048 | Test acc: 82.1895\n",
      "Train loss: 0.0002 | Test loss: 0.4726 | Test acc: 83.7290\n",
      "Train loss: 0.0001 | Test loss: 0.4811 | Test acc: 83.5542\n",
      "Train loss: 0.0002 | Test loss: 0.4931 | Test acc: 82.8249\n",
      "Train loss: 0.0002 | Test loss: 0.4901 | Test acc: 83.2219\n",
      "Train loss: 0.0003 | Test loss: 0.4931 | Test acc: 83.2132\n",
      "Train loss: 0.0005 | Test loss: 0.5038 | Test acc: 81.9751\n",
      "Train loss: 0.0002 | Test loss: 0.4844 | Test acc: 82.9796\n",
      "Train loss: 0.0003 | Test loss: 0.4737 | Test acc: 83.6617\n",
      "Train loss: 0.0003 | Test loss: 0.5082 | Test acc: 81.8268\n",
      "Train loss: 0.0002 | Test loss: 0.4695 | Test acc: 83.5681\n",
      "Train loss: 0.0001 | Test loss: 0.4852 | Test acc: 83.0945\n",
      "Train loss: 0.0002 | Test loss: 0.4778 | Test acc: 83.4624\n",
      "Train loss: 0.0006 | Test loss: 0.5152 | Test acc: 81.7862\n",
      "Train loss: 0.0002 | Test loss: 0.5063 | Test acc: 81.9306\n",
      "Train loss: 0.0002 | Test loss: 0.5231 | Test acc: 81.6016\n",
      "Train loss: 0.0002 | Test loss: 0.4903 | Test acc: 83.0482\n",
      "Train loss: 0.0003 | Test loss: 0.5211 | Test acc: 82.2641\n",
      "Train loss: 0.0003 | Test loss: 0.4956 | Test acc: 82.8307\n",
      "Train loss: 0.0003 | Test loss: 0.5043 | Test acc: 82.3533\n",
      "Train loss: 0.0002 | Test loss: 0.5187 | Test acc: 82.2120\n",
      "Train loss: 0.0003 | Test loss: 0.5151 | Test acc: 81.5825\n",
      "Train loss: 0.0002 | Test loss: 0.4985 | Test acc: 82.2994\n",
      "Train loss: 0.0002 | Test loss: 0.5103 | Test acc: 82.2118\n",
      "Train loss: 0.0001 | Test loss: 0.4759 | Test acc: 83.4695\n",
      "Train loss: 0.0002 | Test loss: 0.4915 | Test acc: 82.8346\n",
      "Train loss: 0.0003 | Test loss: 0.5104 | Test acc: 82.3333\n",
      "Train loss: 0.0002 | Test loss: 0.4981 | Test acc: 82.4815\n",
      "Train loss: 0.0003 | Test loss: 0.4749 | Test acc: 83.5003\n",
      "Train loss: 0.0003 | Test loss: 0.4858 | Test acc: 82.8746\n",
      "Train loss: 0.0002 | Test loss: 0.4866 | Test acc: 83.2520\n",
      "Train loss: 0.0003 | Test loss: 0.4761 | Test acc: 83.5328\n",
      "Train loss: 0.0001 | Test loss: 0.4772 | Test acc: 83.5436\n",
      "Train loss: 0.0002 | Test loss: 0.4843 | Test acc: 83.3440\n",
      "Train loss: 0.0003 | Test loss: 0.4893 | Test acc: 82.9340\n",
      "Train loss: 0.0004 | Test loss: 0.4941 | Test acc: 82.7430\n",
      "Train loss: 0.0002 | Test loss: 0.4789 | Test acc: 83.2216\n",
      "Train loss: 0.0002 | Test loss: 0.4860 | Test acc: 82.7839\n",
      "Train loss: 0.0003 | Test loss: 0.5005 | Test acc: 82.3731\n",
      "Train loss: 0.0001 | Test loss: 0.5005 | Test acc: 82.2819\n",
      "Train loss: 0.0003 | Test loss: 0.4896 | Test acc: 83.2201\n",
      "Train loss: 0.0003 | Test loss: 0.5034 | Test acc: 82.9536\n",
      "Train loss: 0.0002 | Test loss: 0.5102 | Test acc: 81.9443\n",
      "Train loss: 0.0002 | Test loss: 0.4981 | Test acc: 83.3189\n",
      "Train loss: 0.0003 | Test loss: 0.5236 | Test acc: 82.0154\n",
      "Train loss: 0.0003 | Test loss: 0.5014 | Test acc: 82.8399\n",
      "Train loss: 0.0001 | Test loss: 0.5108 | Test acc: 82.2934\n",
      "Train loss: 0.0004 | Test loss: 0.5056 | Test acc: 81.9023\n",
      "Train loss: 0.0003 | Test loss: 0.5119 | Test acc: 81.6714\n",
      "Train loss: 0.0002 | Test loss: 0.5292 | Test acc: 81.7605\n",
      "Train loss: 0.0002 | Test loss: 0.5379 | Test acc: 81.2416\n",
      "Train loss: 0.0002 | Test loss: 0.5023 | Test acc: 82.8574\n",
      "Train loss: 0.0002 | Test loss: 0.5263 | Test acc: 81.3450\n",
      "Train loss: 0.0004 | Test loss: 0.5706 | Test acc: 81.0906\n",
      "Train loss: 0.0001 | Test loss: 0.5418 | Test acc: 81.5690\n",
      "Train loss: 0.0001 | Test loss: 0.5353 | Test acc: 81.6304\n",
      "Train loss: 0.0003 | Test loss: 0.5098 | Test acc: 82.4293\n",
      "Train loss: 0.0002 | Test loss: 0.4975 | Test acc: 83.4702\n",
      "Train loss: 0.0002 | Test loss: 0.4815 | Test acc: 83.4037\n",
      "Train loss: 0.0001 | Test loss: 0.4862 | Test acc: 83.0241\n",
      "Train loss: 0.0001 | Test loss: 0.5332 | Test acc: 81.2057\n",
      "Train loss: 0.0002 | Test loss: 0.5022 | Test acc: 82.3181\n",
      "Train loss: 0.0002 | Test loss: 0.5010 | Test acc: 83.0306\n",
      "Train loss: 0.0002 | Test loss: 0.4804 | Test acc: 83.6419\n",
      "Train loss: 0.0003 | Test loss: 0.4774 | Test acc: 83.6039\n",
      "Train loss: 0.0003 | Test loss: 0.4906 | Test acc: 83.2144\n",
      "Train loss: 0.0002 | Test loss: 0.5458 | Test acc: 80.5274\n",
      "Train loss: 0.0003 | Test loss: 0.4877 | Test acc: 83.5740\n",
      "Train loss: 0.0002 | Test loss: 0.5002 | Test acc: 83.2642\n",
      "Train loss: 0.0003 | Test loss: 0.5051 | Test acc: 82.5344\n",
      "Train loss: 0.0004 | Test loss: 0.4814 | Test acc: 83.2210\n",
      "Train loss: 0.0002 | Test loss: 0.4735 | Test acc: 83.7124\n",
      "Train loss: 0.0002 | Test loss: 0.5035 | Test acc: 82.4859\n",
      "Train loss: 0.0002 | Test loss: 0.4886 | Test acc: 83.2208\n",
      "Train loss: 0.0001 | Test loss: 0.4988 | Test acc: 82.9336\n",
      "Train loss: 0.0003 | Test loss: 0.4677 | Test acc: 83.9111\n",
      "Train loss: 0.0001 | Test loss: 0.4903 | Test acc: 83.2154\n",
      "Train loss: 0.0002 | Test loss: 0.4917 | Test acc: 83.2731\n",
      "Train loss: 0.0002 | Test loss: 0.4924 | Test acc: 83.0935\n",
      "Train loss: 0.0003 | Test loss: 0.5270 | Test acc: 82.9632\n",
      "Train loss: 0.0003 | Test loss: 0.4949 | Test acc: 83.2922\n",
      "Train loss: 0.0001 | Test loss: 0.4890 | Test acc: 83.2533\n",
      "Train loss: 0.0002 | Test loss: 0.4714 | Test acc: 83.8722\n",
      "Train loss: 0.0003 | Test loss: 0.4952 | Test acc: 83.0355\n",
      "Train loss: 0.0001 | Test loss: 0.5025 | Test acc: 82.7333\n",
      "Train loss: 0.0004 | Test loss: 0.4804 | Test acc: 83.4412\n",
      "Train loss: 0.0001 | Test loss: 0.4968 | Test acc: 82.8145\n",
      "Train loss: 0.0002 | Test loss: 0.5123 | Test acc: 81.9938\n",
      "Train loss: 0.0002 | Test loss: 0.4959 | Test acc: 83.1693\n",
      "Train loss: 0.0003 | Test loss: 0.5040 | Test acc: 82.6339\n",
      "Train loss: 0.0005 | Test loss: 0.5039 | Test acc: 82.8519\n",
      "Train loss: 0.0003 | Test loss: 0.4968 | Test acc: 83.0323\n",
      "Train loss: 0.0002 | Test loss: 0.4938 | Test acc: 83.3723\n",
      "Train loss: 0.0001 | Test loss: 0.5001 | Test acc: 82.7943\n",
      "Train loss: 0.0004 | Test loss: 0.4945 | Test acc: 83.5013\n",
      "Train loss: 0.0002 | Test loss: 0.4909 | Test acc: 83.3339\n",
      "Train loss: 0.0002 | Test loss: 0.4967 | Test acc: 82.6644\n",
      "Train loss: 0.0001 | Test loss: 0.4940 | Test acc: 82.5824\n",
      "Train loss: 0.0002 | Test loss: 0.5011 | Test acc: 82.6121\n",
      "Train loss: 0.0001 | Test loss: 0.4806 | Test acc: 83.7204\n",
      "Train loss: 0.0002 | Test loss: 0.5059 | Test acc: 82.8953\n",
      "Train loss: 0.0003 | Test loss: 0.5122 | Test acc: 82.7728\n",
      "Train loss: 0.0002 | Test loss: 0.5477 | Test acc: 80.0768\n",
      "Train loss: 0.0004 | Test loss: 0.5313 | Test acc: 82.6540\n",
      "Train loss: 0.0002 | Test loss: 0.5011 | Test acc: 83.1515\n",
      "Train loss: 0.0004 | Test loss: 0.4929 | Test acc: 82.9833\n",
      "Train loss: 0.0002 | Test loss: 0.4949 | Test acc: 83.1026\n",
      "Train loss: 0.0005 | Test loss: 0.5341 | Test acc: 80.6669\n",
      "Train loss: 0.0003 | Test loss: 0.4902 | Test acc: 83.0552\n",
      "Train loss: 0.0002 | Test loss: 0.5434 | Test acc: 81.4355\n",
      "Train loss: 0.0002 | Test loss: 0.5530 | Test acc: 81.4802\n",
      "Train loss: 0.0005 | Test loss: 0.5079 | Test acc: 81.9896\n",
      "Train loss: 0.0004 | Test loss: 0.5846 | Test acc: 79.8047\n",
      "Train loss: 0.0004 | Test loss: 0.4908 | Test acc: 83.2921\n",
      "Train loss: 0.0002 | Test loss: 0.5027 | Test acc: 82.7741\n",
      "Train loss: 0.0002 | Test loss: 0.4800 | Test acc: 83.7509\n",
      "Train loss: 0.0004 | Test loss: 0.4985 | Test acc: 82.9353\n",
      "Train loss: 0.0002 | Test loss: 0.4874 | Test acc: 83.3520\n",
      "Train loss: 0.0002 | Test loss: 0.4847 | Test acc: 83.4832\n",
      "Train loss: 0.0001 | Test loss: 0.5102 | Test acc: 82.1557\n",
      "Train loss: 0.0003 | Test loss: 0.5045 | Test acc: 82.6207\n",
      "Train loss: 0.0002 | Test loss: 0.5385 | Test acc: 81.4740\n",
      "Train loss: 0.0004 | Test loss: 0.5388 | Test acc: 81.4604\n",
      "Train loss: 0.0002 | Test loss: 0.5082 | Test acc: 83.1077\n",
      "Train loss: 0.0002 | Test loss: 0.5292 | Test acc: 82.5139\n",
      "Train loss: 0.0004 | Test loss: 0.4766 | Test acc: 83.6502\n",
      "Train loss: 0.0003 | Test loss: 0.5254 | Test acc: 81.2677\n",
      "Train loss: 0.0002 | Test loss: 0.5284 | Test acc: 81.1602\n",
      "Train loss: 0.0002 | Test loss: 0.5188 | Test acc: 81.5492\n",
      "Train loss: 0.0002 | Test loss: 0.5358 | Test acc: 80.9714\n",
      "Train loss: 0.0003 | Test loss: 0.5252 | Test acc: 81.2791\n",
      "Train loss: 0.0002 | Test loss: 0.5128 | Test acc: 81.8991\n",
      "Train loss: 0.0002 | Test loss: 0.5023 | Test acc: 82.5200\n",
      "Train loss: 0.0004 | Test loss: 0.5002 | Test acc: 82.9513\n",
      "Train loss: 0.0004 | Test loss: 0.4753 | Test acc: 83.4819\n",
      "Train loss: 0.0002 | Test loss: 0.4840 | Test acc: 82.8745\n",
      "Train loss: 0.0002 | Test loss: 0.4888 | Test acc: 83.0323\n",
      "Train loss: 0.0002 | Test loss: 0.5066 | Test acc: 82.3040\n",
      "Train loss: 0.0005 | Test loss: 0.5070 | Test acc: 82.5812\n",
      "Train loss: 0.0003 | Test loss: 0.4866 | Test acc: 83.3809\n",
      "Train loss: 0.0003 | Test loss: 0.4850 | Test acc: 83.0140\n",
      "Train loss: 0.0001 | Test loss: 0.4782 | Test acc: 83.8415\n",
      "Train loss: 0.0002 | Test loss: 0.5045 | Test acc: 83.0654\n",
      "Train loss: 0.0003 | Test loss: 0.4876 | Test acc: 83.5222\n",
      "Train loss: 0.0003 | Test loss: 0.5172 | Test acc: 82.0260\n",
      "Train loss: 0.0002 | Test loss: 0.4822 | Test acc: 83.5987\n",
      "Train loss: 0.0001 | Test loss: 0.5146 | Test acc: 82.4456\n",
      "Train loss: 0.0002 | Test loss: 0.4945 | Test acc: 82.9212\n",
      "Train loss: 0.0001 | Test loss: 0.5049 | Test acc: 82.3336\n",
      "Train loss: 0.0001 | Test loss: 0.5024 | Test acc: 82.4515\n",
      "Train loss: 0.0002 | Test loss: 0.4880 | Test acc: 83.0210\n",
      "Train loss: 0.0002 | Test loss: 0.4782 | Test acc: 83.2924\n",
      "Train loss: 0.0002 | Test loss: 0.5047 | Test acc: 81.9554\n",
      "Train loss: 0.0003 | Test loss: 0.4810 | Test acc: 82.9196\n",
      "Train loss: 0.0001 | Test loss: 0.4954 | Test acc: 82.1938\n",
      "Train loss: 0.0003 | Test loss: 0.5051 | Test acc: 82.8604\n",
      "Train loss: 0.0001 | Test loss: 0.4906 | Test acc: 83.3019\n",
      "Train loss: 0.0002 | Test loss: 0.4948 | Test acc: 83.0337\n",
      "Train loss: 0.0002 | Test loss: 0.4728 | Test acc: 83.7617\n",
      "Train loss: 0.0003 | Test loss: 0.4989 | Test acc: 81.8870\n",
      "Train loss: 0.0003 | Test loss: 0.4887 | Test acc: 83.0292\n",
      "Train loss: 0.0002 | Test loss: 0.4916 | Test acc: 82.6235\n",
      "Train loss: 0.0001 | Test loss: 0.4851 | Test acc: 82.7819\n",
      "Train loss: 0.0002 | Test loss: 0.4822 | Test acc: 83.5013\n",
      "Train loss: 0.0001 | Test loss: 0.4970 | Test acc: 82.6550\n",
      "Train loss: 0.0003 | Test loss: 0.4990 | Test acc: 82.3927\n",
      "Train loss: 0.0004 | Test loss: 0.5215 | Test acc: 81.1738\n",
      "Train loss: 0.0002 | Test loss: 0.4793 | Test acc: 83.5960\n",
      "Train loss: 0.0002 | Test loss: 0.4887 | Test acc: 82.9648\n",
      "Train loss: 0.0003 | Test loss: 0.4987 | Test acc: 83.2623\n",
      "Train loss: 0.0002 | Test loss: 0.5095 | Test acc: 83.0236\n",
      "Train loss: 0.0003 | Test loss: 0.4887 | Test acc: 82.8331\n",
      "Train loss: 0.0003 | Test loss: 0.4946 | Test acc: 82.9723\n",
      "Train loss: 0.0002 | Test loss: 0.5336 | Test acc: 80.5966\n",
      "Train loss: 0.0002 | Test loss: 0.5129 | Test acc: 81.1481\n",
      "Train loss: 0.0003 | Test loss: 0.4995 | Test acc: 82.5576\n",
      "Train loss: 0.0003 | Test loss: 0.4894 | Test acc: 82.8616\n",
      "Train loss: 0.0002 | Test loss: 0.5012 | Test acc: 82.1537\n",
      "Train loss: 0.0001 | Test loss: 0.5234 | Test acc: 80.8735\n",
      "Train loss: 0.0002 | Test loss: 0.4851 | Test acc: 82.8562\n",
      "Train loss: 0.0002 | Test loss: 0.4771 | Test acc: 83.3418\n",
      "Train loss: 0.0002 | Test loss: 0.5101 | Test acc: 82.0155\n",
      "Train loss: 0.0003 | Test loss: 0.4778 | Test acc: 83.3291\n",
      "Train loss: 0.0001 | Test loss: 0.4710 | Test acc: 83.8425\n",
      "Train loss: 0.0003 | Test loss: 0.4823 | Test acc: 83.4448\n",
      "Train loss: 0.0001 | Test loss: 0.4877 | Test acc: 83.1340\n",
      "Train loss: 0.0004 | Test loss: 0.6056 | Test acc: 77.9713\n",
      "Train loss: 0.0002 | Test loss: 0.5866 | Test acc: 78.6337\n",
      "Train loss: 0.0006 | Test loss: 0.4773 | Test acc: 83.2584\n",
      "Train loss: 0.0002 | Test loss: 0.4838 | Test acc: 82.8039\n",
      "Train loss: 0.0003 | Test loss: 0.4998 | Test acc: 82.2134\n",
      "Train loss: 0.0002 | Test loss: 0.4698 | Test acc: 83.5494\n",
      "Train loss: 0.0004 | Test loss: 0.5156 | Test acc: 82.6252\n",
      "Train loss: 0.0003 | Test loss: 0.5104 | Test acc: 82.7220\n",
      "Train loss: 0.0003 | Test loss: 0.5040 | Test acc: 82.8921\n",
      "Train loss: 0.0003 | Test loss: 0.5608 | Test acc: 81.3351\n",
      "Train loss: 0.0003 | Test loss: 0.4979 | Test acc: 83.0873\n",
      "Train loss: 0.0002 | Test loss: 0.4984 | Test acc: 82.8733\n",
      "Train loss: 0.0002 | Test loss: 0.4859 | Test acc: 82.8826\n",
      "Train loss: 0.0002 | Test loss: 0.4949 | Test acc: 82.8726\n",
      "Train loss: 0.0002 | Test loss: 0.4920 | Test acc: 83.1921\n",
      "Train loss: 0.0003 | Test loss: 0.4714 | Test acc: 83.7422\n",
      "Train loss: 0.0002 | Test loss: 0.5071 | Test acc: 82.4461\n",
      "Train loss: 0.0002 | Test loss: 0.4672 | Test acc: 83.7299\n",
      "Train loss: 0.0002 | Test loss: 0.4969 | Test acc: 83.3446\n",
      "Train loss: 0.0002 | Test loss: 0.4895 | Test acc: 83.2136\n",
      "Train loss: 0.0003 | Test loss: 0.4992 | Test acc: 82.8038\n",
      "Train loss: 0.0002 | Test loss: 0.5268 | Test acc: 81.2949\n",
      "Train loss: 0.0001 | Test loss: 0.5025 | Test acc: 82.4382\n",
      "Train loss: 0.0003 | Test loss: 0.4722 | Test acc: 83.6899\n",
      "Train loss: 0.0001 | Test loss: 0.4785 | Test acc: 83.3445\n",
      "Train loss: 0.0003 | Test loss: 0.4866 | Test acc: 82.9140\n",
      "Train loss: 0.0003 | Test loss: 0.5060 | Test acc: 82.4334\n",
      "Train loss: 0.0002 | Test loss: 0.5344 | Test acc: 81.6232\n",
      "Train loss: 0.0002 | Test loss: 0.5047 | Test acc: 83.0283\n",
      "Train loss: 0.0002 | Test loss: 0.5581 | Test acc: 80.5169\n",
      "Train loss: 0.0006 | Test loss: 0.5698 | Test acc: 78.8615\n",
      "Train loss: 0.0002 | Test loss: 0.5076 | Test acc: 81.8514\n",
      "Train loss: 0.0004 | Test loss: 0.4979 | Test acc: 82.7695\n",
      "Train loss: 0.0003 | Test loss: 0.5058 | Test acc: 82.2932\n",
      "Train loss: 0.0003 | Test loss: 0.5016 | Test acc: 82.5213\n",
      "Train loss: 0.0002 | Test loss: 0.4841 | Test acc: 83.6402\n",
      "Train loss: 0.0002 | Test loss: 0.4884 | Test acc: 82.4158\n",
      "Train loss: 0.0001 | Test loss: 0.4770 | Test acc: 83.4702\n",
      "Train loss: 0.0003 | Test loss: 0.5132 | Test acc: 81.8062\n",
      "Train loss: 0.0002 | Test loss: 0.4904 | Test acc: 82.9890\n",
      "Train loss: 0.0004 | Test loss: 0.4769 | Test acc: 83.4620\n",
      "Train loss: 0.0002 | Test loss: 0.4712 | Test acc: 83.6832\n",
      "Train loss: 0.0002 | Test loss: 0.4965 | Test acc: 82.4559\n",
      "Train loss: 0.0003 | Test loss: 0.4771 | Test acc: 83.2806\n",
      "Train loss: 0.0003 | Test loss: 0.4865 | Test acc: 82.9937\n",
      "Train loss: 0.0002 | Test loss: 0.4749 | Test acc: 83.2424\n",
      "Train loss: 0.0003 | Test loss: 0.4772 | Test acc: 83.4329\n",
      "Train loss: 0.0002 | Test loss: 0.4889 | Test acc: 82.7246\n",
      "Train loss: 0.0004 | Test loss: 0.4876 | Test acc: 82.5826\n",
      "Train loss: 0.0001 | Test loss: 0.4767 | Test acc: 83.2311\n",
      "Train loss: 0.0004 | Test loss: 0.6420 | Test acc: 76.3841\n",
      "Train loss: 0.0004 | Test loss: 0.5036 | Test acc: 82.2728\n",
      "Train loss: 0.0001 | Test loss: 0.4908 | Test acc: 82.6011\n",
      "Train loss: 0.0002 | Test loss: 0.4784 | Test acc: 83.5906\n",
      "Train loss: 0.0003 | Test loss: 0.4782 | Test acc: 83.3042\n",
      "Train loss: 0.0002 | Test loss: 0.5078 | Test acc: 81.7657\n",
      "Train loss: 0.0001 | Test loss: 0.4762 | Test acc: 83.5679\n",
      "Train loss: 0.0002 | Test loss: 0.4774 | Test acc: 83.6136\n",
      "Train loss: 0.0003 | Test loss: 0.4979 | Test acc: 82.8750\n",
      "Train loss: 0.0003 | Test loss: 0.5243 | Test acc: 80.6961\n",
      "Train loss: 0.0003 | Test loss: 0.4901 | Test acc: 83.0653\n",
      "Train loss: 0.0002 | Test loss: 0.4921 | Test acc: 82.9631\n",
      "Train loss: 0.0002 | Test loss: 0.4990 | Test acc: 82.8030\n",
      "Train loss: 0.0006 | Test loss: 0.5058 | Test acc: 81.8540\n",
      "Train loss: 0.0003 | Test loss: 0.4821 | Test acc: 83.1189\n",
      "Train loss: 0.0001 | Test loss: 0.4934 | Test acc: 82.9832\n",
      "Train loss: 0.0003 | Test loss: 0.5479 | Test acc: 79.4285\n",
      "Train loss: 0.0003 | Test loss: 0.4909 | Test acc: 82.8117\n",
      "Train loss: 0.0002 | Test loss: 0.4817 | Test acc: 83.2218\n",
      "Train loss: 0.0002 | Test loss: 0.4818 | Test acc: 83.2831\n",
      "Train loss: 0.0004 | Test loss: 0.4802 | Test acc: 83.1834\n",
      "Train loss: 0.0002 | Test loss: 0.4728 | Test acc: 83.4327\n",
      "Train loss: 0.0001 | Test loss: 0.4827 | Test acc: 82.7646\n",
      "Train loss: 0.0001 | Test loss: 0.4871 | Test acc: 82.7724\n",
      "Train loss: 0.0001 | Test loss: 0.4852 | Test acc: 83.1319\n",
      "Train loss: 0.0004 | Test loss: 0.5113 | Test acc: 82.3343\n",
      "Train loss: 0.0003 | Test loss: 0.5578 | Test acc: 80.7343\n",
      "Train loss: 0.0004 | Test loss: 0.5498 | Test acc: 80.8889\n",
      "Train loss: 0.0003 | Test loss: 0.5010 | Test acc: 82.2672\n",
      "Train loss: 0.0002 | Test loss: 0.4867 | Test acc: 83.1702\n",
      "Train loss: 0.0002 | Test loss: 0.5067 | Test acc: 82.1148\n",
      "Train loss: 0.0002 | Test loss: 0.5083 | Test acc: 81.4824\n",
      "Train loss: 0.0002 | Test loss: 0.5047 | Test acc: 81.7899\n",
      "Train loss: 0.0002 | Test loss: 0.4817 | Test acc: 83.3384\n",
      "Train loss: 0.0002 | Test loss: 0.4831 | Test acc: 83.1137\n",
      "Train loss: 0.0001 | Test loss: 0.4722 | Test acc: 83.6322\n",
      "Train loss: 0.0003 | Test loss: 0.4845 | Test acc: 83.2844\n",
      "Train loss: 0.0002 | Test loss: 0.4972 | Test acc: 82.7741\n",
      "Train loss: 0.0003 | Test loss: 0.4786 | Test acc: 83.0720\n",
      "Train loss: 0.0003 | Test loss: 0.4705 | Test acc: 83.8617\n",
      "Train loss: 0.0002 | Test loss: 0.4780 | Test acc: 83.5147\n",
      "Train loss: 0.0003 | Test loss: 0.5050 | Test acc: 82.5851\n",
      "Train loss: 0.0002 | Test loss: 0.4784 | Test acc: 83.3908\n",
      "Train loss: 0.0002 | Test loss: 0.4827 | Test acc: 83.4633\n",
      "Train loss: 0.0003 | Test loss: 0.5136 | Test acc: 82.4052\n",
      "Train loss: 0.0002 | Test loss: 0.5372 | Test acc: 81.6431\n",
      "Train loss: 0.0004 | Test loss: 0.4981 | Test acc: 82.3695\n",
      "Train loss: 0.0003 | Test loss: 0.4918 | Test acc: 82.4317\n",
      "Train loss: 0.0003 | Test loss: 0.5053 | Test acc: 82.4618\n",
      "Train loss: 0.0002 | Test loss: 0.4763 | Test acc: 83.4504\n",
      "Train loss: 0.0003 | Test loss: 0.5503 | Test acc: 80.4383\n",
      "Train loss: 0.0002 | Test loss: 0.5585 | Test acc: 80.0992\n",
      "Train loss: 0.0005 | Test loss: 0.5232 | Test acc: 81.7755\n",
      "Train loss: 0.0002 | Test loss: 0.4890 | Test acc: 83.1586\n",
      "Train loss: 0.0003 | Test loss: 0.5039 | Test acc: 82.6239\n",
      "Train loss: 0.0003 | Test loss: 0.4951 | Test acc: 82.8618\n",
      "Train loss: 0.0003 | Test loss: 0.4780 | Test acc: 83.4317\n",
      "Train loss: 0.0002 | Test loss: 0.4826 | Test acc: 82.9043\n",
      "Train loss: 0.0001 | Test loss: 0.4804 | Test acc: 83.3020\n",
      "Train loss: 0.0004 | Test loss: 0.5337 | Test acc: 82.2450\n",
      "Train loss: 0.0002 | Test loss: 0.4946 | Test acc: 83.0803\n",
      "Train loss: 0.0004 | Test loss: 0.4961 | Test acc: 82.7734\n",
      "Train loss: 0.0002 | Test loss: 0.4816 | Test acc: 83.4014\n",
      "Train loss: 0.0003 | Test loss: 0.5255 | Test acc: 81.1171\n",
      "Train loss: 0.0001 | Test loss: 0.5496 | Test acc: 80.3510\n",
      "Train loss: 0.0002 | Test loss: 0.5075 | Test acc: 82.2056\n",
      "Train loss: 0.0002 | Test loss: 0.4861 | Test acc: 83.6392\n",
      "Train loss: 0.0002 | Test loss: 0.5054 | Test acc: 83.0747\n",
      "Train loss: 0.0003 | Test loss: 0.4626 | Test acc: 84.0913\n",
      "Train loss: 0.0002 | Test loss: 0.4831 | Test acc: 82.9663\n",
      "Train loss: 0.0002 | Test loss: 0.4856 | Test acc: 83.1325\n",
      "Train loss: 0.0003 | Test loss: 0.4919 | Test acc: 82.9833\n",
      "Train loss: 0.0003 | Test loss: 0.5226 | Test acc: 82.5335\n",
      "Train loss: 0.0002 | Test loss: 0.5142 | Test acc: 82.1527\n",
      "Train loss: 0.0001 | Test loss: 0.4977 | Test acc: 82.6307\n",
      "Train loss: 0.0002 | Test loss: 0.4881 | Test acc: 82.8618\n",
      "Train loss: 0.0002 | Test loss: 0.4940 | Test acc: 83.0423\n",
      "Train loss: 0.0002 | Test loss: 0.4887 | Test acc: 82.9630\n",
      "Train loss: 0.0004 | Test loss: 0.4782 | Test acc: 83.5218\n",
      "Train loss: 0.0002 | Test loss: 0.4689 | Test acc: 83.5736\n",
      "Train loss: 0.0001 | Test loss: 0.4899 | Test acc: 82.2758\n",
      "Train loss: 0.0001 | Test loss: 0.4712 | Test acc: 83.6295\n",
      "Train loss: 0.0003 | Test loss: 0.5004 | Test acc: 82.7452\n",
      "Train loss: 0.0003 | Test loss: 0.4862 | Test acc: 83.3514\n",
      "Train loss: 0.0003 | Test loss: 0.4943 | Test acc: 81.8458\n",
      "Train loss: 0.0002 | Test loss: 0.5192 | Test acc: 81.5714\n",
      "Train loss: 0.0002 | Test loss: 0.5192 | Test acc: 81.1113\n",
      "Train loss: 0.0002 | Test loss: 0.4905 | Test acc: 82.9468\n",
      "Train loss: 0.0003 | Test loss: 0.5007 | Test acc: 82.9727\n",
      "Train loss: 0.0002 | Test loss: 0.4839 | Test acc: 83.2423\n",
      "Train loss: 0.0002 | Test loss: 0.4889 | Test acc: 83.2632\n",
      "Train loss: 0.0002 | Test loss: 0.4870 | Test acc: 82.7241\n",
      "Train loss: 0.0002 | Test loss: 0.4818 | Test acc: 83.1117\n",
      "Train loss: 0.0002 | Test loss: 0.4820 | Test acc: 83.2028\n",
      "Train loss: 0.0002 | Test loss: 0.4799 | Test acc: 83.3529\n",
      "Train loss: 0.0002 | Test loss: 0.4752 | Test acc: 83.4133\n",
      "Train loss: 0.0004 | Test loss: 0.5101 | Test acc: 82.0456\n",
      "Train loss: 0.0001 | Test loss: 0.4789 | Test acc: 83.4191\n",
      "Train loss: 0.0002 | Test loss: 0.4885 | Test acc: 83.5033\n",
      "Train loss: 0.0002 | Test loss: 0.4802 | Test acc: 83.1741\n",
      "Train loss: 0.0002 | Test loss: 0.5104 | Test acc: 82.1347\n",
      "Train loss: 0.0004 | Test loss: 0.4747 | Test acc: 83.6290\n",
      "Train loss: 0.0002 | Test loss: 0.4833 | Test acc: 83.1246\n",
      "Train loss: 0.0002 | Test loss: 0.4889 | Test acc: 83.0232\n",
      "Train loss: 0.0002 | Test loss: 0.4978 | Test acc: 83.0029\n",
      "Train loss: 0.0002 | Test loss: 0.5156 | Test acc: 82.2740\n",
      "Train loss: 0.0002 | Test loss: 0.4891 | Test acc: 83.1902\n",
      "Train loss: 0.0002 | Test loss: 0.4773 | Test acc: 83.6823\n",
      "Train loss: 0.0003 | Test loss: 0.5369 | Test acc: 80.1096\n",
      "Train loss: 0.0004 | Test loss: 0.5238 | Test acc: 81.1765\n",
      "Train loss: 0.0003 | Test loss: 0.5274 | Test acc: 81.8189\n",
      "Train loss: 0.0003 | Test loss: 0.4938 | Test acc: 82.8393\n",
      "Train loss: 0.0003 | Test loss: 0.4966 | Test acc: 83.0522\n",
      "Train loss: 0.0001 | Test loss: 0.5035 | Test acc: 82.9131\n",
      "Train loss: 0.0003 | Test loss: 0.5236 | Test acc: 81.8643\n",
      "Train loss: 0.0002 | Test loss: 0.4823 | Test acc: 83.4684\n",
      "Train loss: 0.0002 | Test loss: 0.4769 | Test acc: 83.5933\n",
      "Train loss: 0.0004 | Test loss: 0.4891 | Test acc: 83.1345\n",
      "Train loss: 0.0003 | Test loss: 0.5006 | Test acc: 82.2844\n",
      "Train loss: 0.0002 | Test loss: 0.4951 | Test acc: 83.2701\n",
      "Train loss: 0.0004 | Test loss: 0.5271 | Test acc: 81.3563\n",
      "Train loss: 0.0003 | Test loss: 0.5274 | Test acc: 81.4301\n",
      "Train loss: 0.0004 | Test loss: 0.4940 | Test acc: 82.6983\n",
      "Train loss: 0.0003 | Test loss: 0.5124 | Test acc: 81.5941\n",
      "Train loss: 0.0001 | Test loss: 0.4904 | Test acc: 82.9284\n",
      "Train loss: 0.0001 | Test loss: 0.4790 | Test acc: 83.4219\n",
      "Train loss: 0.0002 | Test loss: 0.4851 | Test acc: 83.4734\n",
      "Train loss: 0.0003 | Test loss: 0.5098 | Test acc: 81.9660\n",
      "Train loss: 0.0002 | Test loss: 0.5006 | Test acc: 82.7299\n",
      "Train loss: 0.0003 | Test loss: 0.5083 | Test acc: 82.5327\n",
      "Train loss: 0.0002 | Test loss: 0.4860 | Test acc: 83.1411\n",
      "Looked at 51200 / 60000 samples\n",
      "Train loss: 0.0002 | Test loss: 0.4914 | Test acc: 83.1131\n",
      "Train loss: 0.0004 | Test loss: 0.4913 | Test acc: 82.7735\n",
      "Train loss: 0.0003 | Test loss: 0.5268 | Test acc: 80.9853\n",
      "Train loss: 0.0004 | Test loss: 0.5675 | Test acc: 78.7432\n",
      "Train loss: 0.0003 | Test loss: 0.5408 | Test acc: 80.7328\n",
      "Train loss: 0.0003 | Test loss: 0.4891 | Test acc: 83.0754\n",
      "Train loss: 0.0003 | Test loss: 0.4805 | Test acc: 83.2127\n",
      "Train loss: 0.0001 | Test loss: 0.4946 | Test acc: 82.4943\n",
      "Train loss: 0.0002 | Test loss: 0.4768 | Test acc: 83.6701\n",
      "Train loss: 0.0001 | Test loss: 0.4924 | Test acc: 82.9450\n",
      "Train loss: 0.0003 | Test loss: 0.5162 | Test acc: 81.4950\n",
      "Train loss: 0.0003 | Test loss: 0.4859 | Test acc: 83.1577\n",
      "Train loss: 0.0001 | Test loss: 0.4808 | Test acc: 83.4725\n",
      "Train loss: 0.0003 | Test loss: 0.4908 | Test acc: 82.8745\n",
      "Train loss: 0.0002 | Test loss: 0.4934 | Test acc: 82.4034\n",
      "Train loss: 0.0002 | Test loss: 0.4855 | Test acc: 83.1007\n",
      "Train loss: 0.0004 | Test loss: 0.5074 | Test acc: 82.4440\n",
      "Train loss: 0.0004 | Test loss: 0.4986 | Test acc: 82.0126\n",
      "Train loss: 0.0002 | Test loss: 0.4780 | Test acc: 83.0396\n",
      "Train loss: 0.0003 | Test loss: 0.5200 | Test acc: 80.5369\n",
      "Train loss: 0.0002 | Test loss: 0.4746 | Test acc: 83.5141\n",
      "Train loss: 0.0002 | Test loss: 0.4899 | Test acc: 83.1542\n",
      "Train loss: 0.0003 | Test loss: 0.4883 | Test acc: 83.8919\n",
      "Train loss: 0.0003 | Test loss: 0.5167 | Test acc: 82.7660\n",
      "Train loss: 0.0003 | Test loss: 0.5169 | Test acc: 82.1834\n",
      "Train loss: 0.0003 | Test loss: 0.5038 | Test acc: 82.7706\n",
      "Train loss: 0.0002 | Test loss: 0.5150 | Test acc: 83.0819\n",
      "Train loss: 0.0003 | Test loss: 0.5186 | Test acc: 82.3042\n",
      "Train loss: 0.0003 | Test loss: 0.4759 | Test acc: 83.8093\n",
      "Train loss: 0.0001 | Test loss: 0.4801 | Test acc: 83.4946\n",
      "Train loss: 0.0003 | Test loss: 0.4940 | Test acc: 82.5950\n",
      "Train loss: 0.0002 | Test loss: 0.4993 | Test acc: 82.5522\n",
      "Train loss: 0.0001 | Test loss: 0.4820 | Test acc: 83.2310\n",
      "Train loss: 0.0002 | Test loss: 0.4732 | Test acc: 83.8422\n",
      "Train loss: 0.0003 | Test loss: 0.5159 | Test acc: 81.6976\n",
      "Train loss: 0.0002 | Test loss: 0.5170 | Test acc: 82.3996\n",
      "Train loss: 0.0004 | Test loss: 0.6270 | Test acc: 79.0971\n",
      "Train loss: 0.0002 | Test loss: 0.5946 | Test acc: 80.3446\n",
      "Train loss: 0.0007 | Test loss: 0.5010 | Test acc: 82.3953\n",
      "Train loss: 0.0003 | Test loss: 0.5022 | Test acc: 82.6215\n",
      "Train loss: 0.0003 | Test loss: 0.4982 | Test acc: 82.6921\n",
      "Train loss: 0.0003 | Test loss: 0.4795 | Test acc: 83.5210\n",
      "Train loss: 0.0004 | Test loss: 0.5490 | Test acc: 80.1191\n",
      "Train loss: 0.0007 | Test loss: 0.5456 | Test acc: 81.1565\n",
      "Train loss: 0.0001 | Test loss: 0.5380 | Test acc: 81.2297\n",
      "Train loss: 0.0002 | Test loss: 0.4901 | Test acc: 82.9572\n",
      "Train loss: 0.0004 | Test loss: 0.4961 | Test acc: 81.8445\n",
      "Train loss: 0.0002 | Test loss: 0.4848 | Test acc: 82.7994\n",
      "Train loss: 0.0003 | Test loss: 0.5189 | Test acc: 81.3847\n",
      "Train loss: 0.0003 | Test loss: 0.4852 | Test acc: 82.9477\n",
      "Train loss: 0.0001 | Test loss: 0.4812 | Test acc: 83.1923\n",
      "Train loss: 0.0003 | Test loss: 0.4853 | Test acc: 83.2530\n",
      "Train loss: 0.0004 | Test loss: 0.4795 | Test acc: 83.2632\n",
      "Train loss: 0.0004 | Test loss: 0.5068 | Test acc: 81.9653\n",
      "Train loss: 0.0002 | Test loss: 0.5035 | Test acc: 82.2806\n",
      "Train loss: 0.0002 | Test loss: 0.5445 | Test acc: 80.3447\n",
      "Train loss: 0.0004 | Test loss: 0.4946 | Test acc: 82.9344\n",
      "Train loss: 0.0002 | Test loss: 0.4780 | Test acc: 83.4918\n",
      "Train loss: 0.0001 | Test loss: 0.4851 | Test acc: 83.2340\n",
      "Train loss: 0.0003 | Test loss: 0.4810 | Test acc: 83.1833\n",
      "Train loss: 0.0003 | Test loss: 0.4979 | Test acc: 82.9135\n",
      "Train loss: 0.0004 | Test loss: 0.5072 | Test acc: 82.0840\n",
      "Train loss: 0.0003 | Test loss: 0.4914 | Test acc: 82.7902\n",
      "Train loss: 0.0005 | Test loss: 0.5053 | Test acc: 82.7026\n",
      "Train loss: 0.0002 | Test loss: 0.5215 | Test acc: 81.9036\n",
      "Train loss: 0.0003 | Test loss: 0.5247 | Test acc: 82.1207\n",
      "Train loss: 0.0002 | Test loss: 0.4982 | Test acc: 83.0499\n",
      "Train loss: 0.0004 | Test loss: 0.4778 | Test acc: 83.3624\n",
      "Train loss: 0.0002 | Test loss: 0.4896 | Test acc: 82.8941\n",
      "Train loss: 0.0004 | Test loss: 0.5174 | Test acc: 81.2053\n",
      "Train loss: 0.0003 | Test loss: 0.4862 | Test acc: 83.5162\n",
      "Train loss: 0.0003 | Test loss: 0.4945 | Test acc: 82.8147\n",
      "Train loss: 0.0002 | Test loss: 0.4909 | Test acc: 83.2219\n",
      "Train loss: 0.0002 | Test loss: 0.5363 | Test acc: 81.8753\n",
      "Train loss: 0.0003 | Test loss: 0.5671 | Test acc: 79.7943\n",
      "Train loss: 0.0005 | Test loss: 0.5630 | Test acc: 80.6663\n",
      "Train loss: 0.0002 | Test loss: 0.5011 | Test acc: 82.6060\n",
      "Train loss: 0.0001 | Test loss: 0.4947 | Test acc: 82.9516\n",
      "Train loss: 0.0002 | Test loss: 0.5220 | Test acc: 82.4036\n",
      "Train loss: 0.0002 | Test loss: 0.4811 | Test acc: 83.5001\n",
      "Train loss: 0.0003 | Test loss: 0.4725 | Test acc: 83.2839\n",
      "Train loss: 0.0002 | Test loss: 0.4825 | Test acc: 83.1634\n",
      "Train loss: 0.0003 | Test loss: 0.4907 | Test acc: 82.4642\n",
      "Train loss: 0.0002 | Test loss: 0.4631 | Test acc: 83.9895\n",
      "Train loss: 0.0001 | Test loss: 0.5054 | Test acc: 81.9676\n",
      "Train loss: 0.0002 | Test loss: 0.4741 | Test acc: 83.6584\n",
      "Train loss: 0.0003 | Test loss: 0.4966 | Test acc: 83.0049\n",
      "Train loss: 0.0003 | Test loss: 0.5054 | Test acc: 81.4253\n",
      "Train loss: 0.0002 | Test loss: 0.4866 | Test acc: 83.3871\n",
      "Train loss: 0.0006 | Test loss: 0.5482 | Test acc: 79.4897\n",
      "Train loss: 0.0004 | Test loss: 0.4862 | Test acc: 83.1114\n",
      "Train loss: 0.0002 | Test loss: 0.4816 | Test acc: 83.4325\n",
      "Train loss: 0.0003 | Test loss: 0.4762 | Test acc: 83.4834\n",
      "Train loss: 0.0002 | Test loss: 0.4866 | Test acc: 82.8546\n",
      "Train loss: 0.0004 | Test loss: 0.4733 | Test acc: 83.7811\n",
      "Train loss: 0.0002 | Test loss: 0.4709 | Test acc: 83.7541\n",
      "Train loss: 0.0002 | Test loss: 0.4997 | Test acc: 83.1450\n",
      "Train loss: 0.0003 | Test loss: 0.4886 | Test acc: 82.8335\n",
      "Train loss: 0.0001 | Test loss: 0.4903 | Test acc: 82.7227\n",
      "Train loss: 0.0003 | Test loss: 0.4691 | Test acc: 83.8106\n",
      "Train loss: 0.0002 | Test loss: 0.4804 | Test acc: 83.1452\n",
      "Train loss: 0.0001 | Test loss: 0.4795 | Test acc: 83.2129\n",
      "Train loss: 0.0002 | Test loss: 0.4857 | Test acc: 83.0434\n",
      "Train loss: 0.0002 | Test loss: 0.4757 | Test acc: 83.2925\n",
      "Train loss: 0.0002 | Test loss: 0.5376 | Test acc: 80.4279\n",
      "Train loss: 0.0003 | Test loss: 0.5079 | Test acc: 82.4455\n",
      "Train loss: 0.0002 | Test loss: 0.4889 | Test acc: 83.2107\n",
      "Train loss: 0.0003 | Test loss: 0.5020 | Test acc: 82.3944\n",
      "Train loss: 0.0002 | Test loss: 0.4896 | Test acc: 83.2405\n",
      "Train loss: 0.0003 | Test loss: 0.4896 | Test acc: 83.1234\n",
      "Train loss: 0.0002 | Test loss: 0.4745 | Test acc: 83.7220\n",
      "Train loss: 0.0002 | Test loss: 0.4796 | Test acc: 83.4144\n",
      "Train loss: 0.0002 | Test loss: 0.5042 | Test acc: 82.3152\n",
      "Train loss: 0.0003 | Test loss: 0.5101 | Test acc: 81.8624\n",
      "Train loss: 0.0004 | Test loss: 0.4841 | Test acc: 83.4884\n",
      "Train loss: 0.0004 | Test loss: 0.5100 | Test acc: 82.2855\n",
      "Train loss: 0.0004 | Test loss: 0.5177 | Test acc: 81.7226\n",
      "Train loss: 0.0003 | Test loss: 0.5148 | Test acc: 81.9105\n",
      "Train loss: 0.0003 | Test loss: 0.5169 | Test acc: 81.7214\n",
      "Train loss: 0.0001 | Test loss: 0.5178 | Test acc: 81.8505\n",
      "Train loss: 0.0001 | Test loss: 0.4976 | Test acc: 82.5099\n",
      "Train loss: 0.0003 | Test loss: 0.5322 | Test acc: 80.5052\n",
      "Train loss: 0.0001 | Test loss: 0.4987 | Test acc: 82.1362\n",
      "Train loss: 0.0002 | Test loss: 0.4866 | Test acc: 82.9601\n",
      "Train loss: 0.0002 | Test loss: 0.5011 | Test acc: 82.7431\n",
      "Train loss: 0.0003 | Test loss: 0.5166 | Test acc: 81.4445\n",
      "Train loss: 0.0003 | Test loss: 0.5105 | Test acc: 82.1492\n",
      "Train loss: 0.0004 | Test loss: 0.4798 | Test acc: 83.1698\n",
      "Train loss: 0.0003 | Test loss: 0.5014 | Test acc: 82.6239\n",
      "Train loss: 0.0002 | Test loss: 0.4775 | Test acc: 83.5407\n",
      "Train loss: 0.0001 | Test loss: 0.4723 | Test acc: 83.8631\n",
      "Train loss: 0.0003 | Test loss: 0.5184 | Test acc: 81.9273\n",
      "Train loss: 0.0002 | Test loss: 0.5196 | Test acc: 81.9011\n",
      "Train loss: 0.0004 | Test loss: 0.5498 | Test acc: 79.8144\n",
      "Train loss: 0.0003 | Test loss: 0.4688 | Test acc: 84.1008\n",
      "Train loss: 0.0002 | Test loss: 0.4711 | Test acc: 83.8550\n",
      "Train loss: 0.0003 | Test loss: 0.5056 | Test acc: 82.3366\n",
      "Train loss: 0.0002 | Test loss: 0.4980 | Test acc: 82.7810\n",
      "Train loss: 0.0003 | Test loss: 0.4834 | Test acc: 83.2816\n",
      "Train loss: 0.0002 | Test loss: 0.5058 | Test acc: 82.3647\n",
      "Train loss: 0.0002 | Test loss: 0.4922 | Test acc: 82.7811\n",
      "Train loss: 0.0002 | Test loss: 0.4879 | Test acc: 82.9522\n",
      "Train loss: 0.0004 | Test loss: 0.5266 | Test acc: 82.1840\n",
      "Train loss: 0.0001 | Test loss: 0.5291 | Test acc: 81.5825\n",
      "Train loss: 0.0002 | Test loss: 0.5276 | Test acc: 82.2594\n",
      "Train loss: 0.0001 | Test loss: 0.5260 | Test acc: 82.2017\n",
      "Train loss: 0.0004 | Test loss: 0.4680 | Test acc: 83.7790\n",
      "Train loss: 0.0003 | Test loss: 0.4973 | Test acc: 82.6359\n",
      "Train loss: 0.0001 | Test loss: 0.4863 | Test acc: 83.2412\n",
      "Train loss: 0.0003 | Test loss: 0.4905 | Test acc: 82.8139\n",
      "Train loss: 0.0004 | Test loss: 0.5016 | Test acc: 82.5629\n",
      "Train loss: 0.0003 | Test loss: 0.5581 | Test acc: 80.1060\n",
      "Train loss: 0.0003 | Test loss: 0.5170 | Test acc: 81.7056\n",
      "Train loss: 0.0001 | Test loss: 0.4984 | Test acc: 82.6392\n",
      "Train loss: 0.0003 | Test loss: 0.4786 | Test acc: 83.7305\n",
      "Train loss: 0.0003 | Test loss: 0.4867 | Test acc: 83.2148\n",
      "Train loss: 0.0002 | Test loss: 0.4844 | Test acc: 83.0734\n",
      "Train loss: 0.0001 | Test loss: 0.4855 | Test acc: 83.1628\n",
      "Train loss: 0.0003 | Test loss: 0.5510 | Test acc: 79.1495\n",
      "Train loss: 0.0002 | Test loss: 0.4750 | Test acc: 83.5097\n",
      "Train loss: 0.0003 | Test loss: 0.5242 | Test acc: 82.7049\n",
      "Train loss: 0.0004 | Test loss: 0.5335 | Test acc: 82.1931\n",
      "Train loss: 0.0002 | Test loss: 0.4952 | Test acc: 82.7906\n",
      "Train loss: 0.0003 | Test loss: 0.5188 | Test acc: 82.2034\n",
      "Train loss: 0.0003 | Test loss: 0.4894 | Test acc: 82.8705\n",
      "Train loss: 0.0003 | Test loss: 0.4873 | Test acc: 83.1122\n",
      "Train loss: 0.0002 | Test loss: 0.4675 | Test acc: 84.0115\n",
      "Train loss: 0.0003 | Test loss: 0.4760 | Test acc: 83.6750\n",
      "Train loss: 0.0002 | Test loss: 0.4750 | Test acc: 84.0832\n",
      "Train loss: 0.0002 | Test loss: 0.4729 | Test acc: 83.5654\n",
      "Train loss: 0.0002 | Test loss: 0.4976 | Test acc: 81.9263\n",
      "Train loss: 0.0003 | Test loss: 0.4946 | Test acc: 82.1108\n",
      "Train loss: 0.0003 | Test loss: 0.5301 | Test acc: 80.8833\n",
      "Train loss: 0.0001 | Test loss: 0.5139 | Test acc: 82.1773\n",
      "Train loss: 0.0002 | Test loss: 0.4904 | Test acc: 83.4494\n",
      "Train loss: 0.0003 | Test loss: 0.4907 | Test acc: 82.9942\n",
      "Train loss: 0.0002 | Test loss: 0.5062 | Test acc: 83.1625\n",
      "Train loss: 0.0002 | Test loss: 0.4935 | Test acc: 83.2629\n",
      "Train loss: 0.0003 | Test loss: 0.4975 | Test acc: 82.4146\n",
      "Train loss: 0.0002 | Test loss: 0.5263 | Test acc: 81.8228\n",
      "Train loss: 0.0003 | Test loss: 0.4926 | Test acc: 82.7594\n",
      "Train loss: 0.0003 | Test loss: 0.4828 | Test acc: 83.6410\n",
      "Train loss: 0.0003 | Test loss: 0.4773 | Test acc: 83.5939\n",
      "Train loss: 0.0002 | Test loss: 0.5152 | Test acc: 82.7351\n",
      "Train loss: 0.0002 | Test loss: 0.4888 | Test acc: 83.6908\n",
      "Train loss: 0.0002 | Test loss: 0.4685 | Test acc: 83.9834\n",
      "Train loss: 0.0005 | Test loss: 0.5118 | Test acc: 82.6166\n",
      "Train loss: 0.0004 | Test loss: 0.4997 | Test acc: 82.9517\n",
      "Train loss: 0.0003 | Test loss: 0.4810 | Test acc: 83.3621\n",
      "Train loss: 0.0003 | Test loss: 0.5129 | Test acc: 81.2767\n",
      "Train loss: 0.0002 | Test loss: 0.5311 | Test acc: 81.3998\n",
      "Train loss: 0.0002 | Test loss: 0.5133 | Test acc: 82.1790\n",
      "Train loss: 0.0002 | Test loss: 0.5150 | Test acc: 81.6224\n",
      "Train loss: 0.0001 | Test loss: 0.5009 | Test acc: 82.3494\n",
      "Train loss: 0.0003 | Test loss: 0.4746 | Test acc: 83.3601\n",
      "Train loss: 0.0002 | Test loss: 0.4835 | Test acc: 83.3434\n",
      "Train loss: 0.0003 | Test loss: 0.4765 | Test acc: 83.3334\n",
      "Train loss: 0.0002 | Test loss: 0.5247 | Test acc: 82.1053\n",
      "Train loss: 0.0003 | Test loss: 0.4757 | Test acc: 83.2795\n",
      "Train loss: 0.0003 | Test loss: 0.4834 | Test acc: 82.9538\n",
      "Train loss: 0.0002 | Test loss: 0.5025 | Test acc: 82.2838\n",
      "Train loss: 0.0002 | Test loss: 0.4629 | Test acc: 84.1087\n",
      "Train loss: 0.0001 | Test loss: 0.4762 | Test acc: 83.8150\n",
      "Train loss: 0.0002 | Test loss: 0.4646 | Test acc: 84.1436\n",
      "Train loss: 0.0002 | Test loss: 0.4981 | Test acc: 83.0064\n",
      "Train loss: 0.0002 | Test loss: 0.5763 | Test acc: 79.2189\n",
      "Train loss: 0.0003 | Test loss: 0.4997 | Test acc: 82.9408\n",
      "Train loss: 0.0001 | Test loss: 0.4977 | Test acc: 82.9028\n",
      "Train loss: 0.0001 | Test loss: 0.4994 | Test acc: 82.8527\n",
      "Train loss: 0.0003 | Test loss: 0.4720 | Test acc: 83.8410\n",
      "Train loss: 0.0002 | Test loss: 0.4924 | Test acc: 83.4747\n",
      "Train loss: 0.0003 | Test loss: 0.4893 | Test acc: 83.9228\n",
      "Train loss: 0.0002 | Test loss: 0.4917 | Test acc: 83.7346\n",
      "Train loss: 0.0003 | Test loss: 0.4702 | Test acc: 83.7539\n",
      "Train loss: 0.0002 | Test loss: 0.4792 | Test acc: 83.5443\n",
      "Train loss: 0.0001 | Test loss: 0.4916 | Test acc: 82.8248\n",
      "Train loss: 0.0004 | Test loss: 0.4740 | Test acc: 83.6911\n",
      "Train loss: 0.0003 | Test loss: 0.5246 | Test acc: 81.5174\n",
      "Train loss: 0.0003 | Test loss: 0.5146 | Test acc: 82.2193\n",
      "Train loss: 0.0002 | Test loss: 0.4931 | Test acc: 82.8805\n",
      "Train loss: 0.0004 | Test loss: 0.5197 | Test acc: 81.8143\n",
      "Train loss: 0.0003 | Test loss: 0.4741 | Test acc: 83.4283\n",
      "Train loss: 0.0002 | Test loss: 0.4779 | Test acc: 83.2438\n",
      "Train loss: 0.0002 | Test loss: 0.4845 | Test acc: 82.7340\n",
      "Train loss: 0.0003 | Test loss: 0.5176 | Test acc: 82.4229\n",
      "Train loss: 0.0001 | Test loss: 0.4783 | Test acc: 83.8496\n",
      "Train loss: 0.0003 | Test loss: 0.4873 | Test acc: 83.3050\n",
      "Train loss: 0.0004 | Test loss: 0.4869 | Test acc: 83.3233\n",
      "Train loss: 0.0002 | Test loss: 0.4716 | Test acc: 83.9124\n",
      "Train loss: 0.0002 | Test loss: 0.4901 | Test acc: 83.0556\n",
      "Train loss: 0.0004 | Test loss: 0.4855 | Test acc: 82.7334\n",
      "Train loss: 0.0001 | Test loss: 0.4788 | Test acc: 83.1317\n",
      "Train loss: 0.0002 | Test loss: 0.5219 | Test acc: 80.9864\n",
      "Train loss: 0.0002 | Test loss: 0.4950 | Test acc: 82.7068\n",
      "Train loss: 0.0002 | Test loss: 0.5301 | Test acc: 82.1832\n",
      "Train loss: 0.0001 | Test loss: 0.5105 | Test acc: 82.7406\n",
      "Train loss: 0.0002 | Test loss: 0.4778 | Test acc: 83.6609\n",
      "Train loss: 0.0002 | Test loss: 0.5070 | Test acc: 82.7154\n",
      "Train loss: 0.0002 | Test loss: 0.5393 | Test acc: 81.8537\n",
      "Train loss: 0.0002 | Test loss: 0.4756 | Test acc: 83.9177\n",
      "Train loss: 0.0001 | Test loss: 0.4876 | Test acc: 83.6148\n",
      "Train loss: 0.0002 | Test loss: 0.4944 | Test acc: 82.9149\n",
      "Train loss: 0.0002 | Test loss: 0.4652 | Test acc: 84.1108\n",
      "Train loss: 0.0003 | Test loss: 0.4988 | Test acc: 83.2160\n",
      "Train loss: 0.0003 | Test loss: 0.5006 | Test acc: 82.4444\n",
      "Train loss: 0.0002 | Test loss: 0.4814 | Test acc: 83.5601\n",
      "Train loss: 0.0003 | Test loss: 0.5271 | Test acc: 81.1176\n",
      "Train loss: 0.0003 | Test loss: 0.4841 | Test acc: 83.7156\n",
      "Train loss: 0.0003 | Test loss: 0.4700 | Test acc: 83.8737\n",
      "Train loss: 0.0003 | Test loss: 0.4904 | Test acc: 83.0455\n",
      "Train loss: 0.0003 | Test loss: 0.4680 | Test acc: 83.9015\n",
      "Train loss: 0.0001 | Test loss: 0.4730 | Test acc: 83.6447\n",
      "Train loss: 0.0001 | Test loss: 0.4704 | Test acc: 83.6239\n",
      "Train loss: 0.0001 | Test loss: 0.4953 | Test acc: 82.4657\n",
      "Train loss: 0.0002 | Test loss: 0.4974 | Test acc: 82.0027\n",
      "Train loss: 0.0002 | Test loss: 0.5326 | Test acc: 80.6034\n",
      "Train loss: 0.0001 | Test loss: 0.4742 | Test acc: 83.6441\n",
      "Train loss: 0.0003 | Test loss: 0.5246 | Test acc: 81.4374\n",
      "Train loss: 0.0003 | Test loss: 0.4698 | Test acc: 83.8165\n",
      "Train loss: 0.0001 | Test loss: 0.4788 | Test acc: 83.5445\n",
      "Train loss: 0.0002 | Test loss: 0.4942 | Test acc: 82.9047\n",
      "Train loss: 0.0002 | Test loss: 0.4929 | Test acc: 83.0524\n",
      "Train loss: 0.0002 | Test loss: 0.4674 | Test acc: 83.8915\n",
      "Train loss: 0.0002 | Test loss: 0.4907 | Test acc: 82.6163\n",
      "Train loss: 0.0003 | Test loss: 0.4822 | Test acc: 83.3410\n",
      "Train loss: 0.0003 | Test loss: 0.4865 | Test acc: 83.1037\n",
      "Train loss: 0.0003 | Test loss: 0.5046 | Test acc: 82.2344\n",
      "Train loss: 0.0002 | Test loss: 0.5164 | Test acc: 81.6525\n",
      "Train loss: 0.0003 | Test loss: 0.4876 | Test acc: 83.2581\n",
      "Train loss: 0.0002 | Test loss: 0.4869 | Test acc: 83.2432\n",
      "Train loss: 0.0001 | Test loss: 0.5023 | Test acc: 83.0934\n",
      "Train loss: 0.0002 | Test loss: 0.5045 | Test acc: 82.6836\n",
      "Train loss: 0.0001 | Test loss: 0.5047 | Test acc: 82.6823\n",
      "Train loss: 0.0005 | Test loss: 0.5243 | Test acc: 81.5341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|                                              | 2/3 [57:30<28:45, 1725.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0003 | Test loss: 0.4817 | Test acc: 83.7769\n",
      "Train time on cpu: 3450.78 seconds\n",
      "Epoch: 2\n",
      "-----\n",
      "Looked at 0 / 60000 samples\n",
      "Train loss: 0.0002 | Test loss: 0.4836 | Test acc: 83.3966\n",
      "Train loss: 0.0003 | Test loss: 0.5358 | Test acc: 81.5364\n",
      "Train loss: 0.0004 | Test loss: 0.4973 | Test acc: 82.6487\n",
      "Train loss: 0.0003 | Test loss: 0.4769 | Test acc: 83.6207\n",
      "Train loss: 0.0003 | Test loss: 0.4666 | Test acc: 83.9433\n",
      "Train loss: 0.0003 | Test loss: 0.5639 | Test acc: 80.7694\n",
      "Train loss: 0.0003 | Test loss: 0.4765 | Test acc: 83.2952\n",
      "Train loss: 0.0002 | Test loss: 0.4865 | Test acc: 83.3731\n",
      "Train loss: 0.0003 | Test loss: 0.4741 | Test acc: 83.4433\n",
      "Train loss: 0.0002 | Test loss: 0.4905 | Test acc: 83.4535\n",
      "Train loss: 0.0001 | Test loss: 0.4723 | Test acc: 83.9927\n",
      "Train loss: 0.0004 | Test loss: 0.4764 | Test acc: 83.7148\n",
      "Train loss: 0.0003 | Test loss: 0.4993 | Test acc: 83.0250\n",
      "Train loss: 0.0002 | Test loss: 0.5049 | Test acc: 82.7533\n",
      "Train loss: 0.0002 | Test loss: 0.4809 | Test acc: 83.2915\n",
      "Train loss: 0.0003 | Test loss: 0.4936 | Test acc: 83.1834\n",
      "Train loss: 0.0003 | Test loss: 0.4884 | Test acc: 83.4127\n",
      "Train loss: 0.0002 | Test loss: 0.4987 | Test acc: 83.4534\n",
      "Train loss: 0.0003 | Test loss: 0.4806 | Test acc: 83.4735\n",
      "Train loss: 0.0003 | Test loss: 0.4873 | Test acc: 83.1241\n",
      "Train loss: 0.0001 | Test loss: 0.4816 | Test acc: 83.7320\n",
      "Train loss: 0.0002 | Test loss: 0.5263 | Test acc: 81.5874\n",
      "Train loss: 0.0001 | Test loss: 0.5332 | Test acc: 82.1696\n",
      "Train loss: 0.0004 | Test loss: 0.5158 | Test acc: 82.0017\n",
      "Train loss: 0.0001 | Test loss: 0.5009 | Test acc: 82.4405\n",
      "Train loss: 0.0002 | Test loss: 0.4838 | Test acc: 83.5102\n",
      "Train loss: 0.0002 | Test loss: 0.4797 | Test acc: 83.4737\n",
      "Train loss: 0.0003 | Test loss: 0.5058 | Test acc: 82.4552\n",
      "Train loss: 0.0002 | Test loss: 0.4765 | Test acc: 83.8796\n",
      "Train loss: 0.0002 | Test loss: 0.5040 | Test acc: 82.9357\n",
      "Train loss: 0.0003 | Test loss: 0.4737 | Test acc: 83.5817\n",
      "Train loss: 0.0002 | Test loss: 0.4952 | Test acc: 82.8150\n",
      "Train loss: 0.0003 | Test loss: 0.4731 | Test acc: 83.4016\n",
      "Train loss: 0.0002 | Test loss: 0.4648 | Test acc: 83.9925\n",
      "Train loss: 0.0002 | Test loss: 0.4900 | Test acc: 83.3055\n",
      "Train loss: 0.0003 | Test loss: 0.4814 | Test acc: 83.2234\n",
      "Train loss: 0.0002 | Test loss: 0.4999 | Test acc: 83.3030\n",
      "Train loss: 0.0003 | Test loss: 0.5355 | Test acc: 80.7973\n",
      "Train loss: 0.0002 | Test loss: 0.5158 | Test acc: 82.1072\n",
      "Train loss: 0.0003 | Test loss: 0.4730 | Test acc: 84.0982\n",
      "Train loss: 0.0004 | Test loss: 0.4875 | Test acc: 83.5155\n",
      "Train loss: 0.0002 | Test loss: 0.5284 | Test acc: 82.4553\n",
      "Train loss: 0.0002 | Test loss: 0.5143 | Test acc: 82.8912\n",
      "Train loss: 0.0002 | Test loss: 0.5031 | Test acc: 82.8826\n",
      "Train loss: 0.0002 | Test loss: 0.4915 | Test acc: 83.1721\n",
      "Train loss: 0.0004 | Test loss: 0.4737 | Test acc: 83.7721\n",
      "Train loss: 0.0002 | Test loss: 0.4930 | Test acc: 83.0851\n",
      "Train loss: 0.0003 | Test loss: 0.4735 | Test acc: 83.4723\n",
      "Train loss: 0.0002 | Test loss: 0.4646 | Test acc: 83.8330\n",
      "Train loss: 0.0003 | Test loss: 0.5165 | Test acc: 81.7874\n",
      "Train loss: 0.0006 | Test loss: 0.4644 | Test acc: 83.9574\n",
      "Train loss: 0.0001 | Test loss: 0.4841 | Test acc: 83.3253\n",
      "Train loss: 0.0004 | Test loss: 0.4920 | Test acc: 82.7642\n",
      "Train loss: 0.0002 | Test loss: 0.4963 | Test acc: 82.5727\n",
      "Train loss: 0.0001 | Test loss: 0.5110 | Test acc: 81.6037\n",
      "Train loss: 0.0002 | Test loss: 0.4857 | Test acc: 83.2479\n",
      "Train loss: 0.0002 | Test loss: 0.4770 | Test acc: 83.2931\n",
      "Train loss: 0.0001 | Test loss: 0.4927 | Test acc: 83.2034\n",
      "Train loss: 0.0002 | Test loss: 0.4684 | Test acc: 83.8022\n",
      "Train loss: 0.0002 | Test loss: 0.4665 | Test acc: 83.9339\n",
      "Train loss: 0.0001 | Test loss: 0.4789 | Test acc: 83.1156\n",
      "Train loss: 0.0003 | Test loss: 0.4808 | Test acc: 83.5323\n",
      "Train loss: 0.0002 | Test loss: 0.5175 | Test acc: 81.5768\n",
      "Train loss: 0.0003 | Test loss: 0.4753 | Test acc: 83.6772\n",
      "Train loss: 0.0001 | Test loss: 0.4747 | Test acc: 83.7038\n",
      "Train loss: 0.0004 | Test loss: 0.4735 | Test acc: 83.5342\n",
      "Train loss: 0.0001 | Test loss: 0.4738 | Test acc: 83.3739\n",
      "Train loss: 0.0002 | Test loss: 0.5002 | Test acc: 82.2352\n",
      "Train loss: 0.0003 | Test loss: 0.4906 | Test acc: 83.2599\n",
      "Train loss: 0.0001 | Test loss: 0.4846 | Test acc: 83.3631\n",
      "Train loss: 0.0002 | Test loss: 0.4824 | Test acc: 83.2236\n",
      "Train loss: 0.0002 | Test loss: 0.4690 | Test acc: 83.7323\n",
      "Train loss: 0.0002 | Test loss: 0.5051 | Test acc: 81.7971\n",
      "Train loss: 0.0006 | Test loss: 0.6055 | Test acc: 78.3963\n",
      "Train loss: 0.0003 | Test loss: 0.4996 | Test acc: 82.9482\n",
      "Train loss: 0.0002 | Test loss: 0.4880 | Test acc: 83.1025\n",
      "Train loss: 0.0002 | Test loss: 0.4961 | Test acc: 83.1229\n",
      "Train loss: 0.0004 | Test loss: 0.5232 | Test acc: 81.5655\n",
      "Train loss: 0.0001 | Test loss: 0.5294 | Test acc: 81.1012\n",
      "Train loss: 0.0004 | Test loss: 0.4905 | Test acc: 82.8370\n",
      "Train loss: 0.0003 | Test loss: 0.5761 | Test acc: 79.4480\n",
      "Train loss: 0.0004 | Test loss: 0.5545 | Test acc: 80.0162\n",
      "Train loss: 0.0000 | Test loss: 0.5532 | Test acc: 80.2676\n",
      "Train loss: 0.0003 | Test loss: 0.5141 | Test acc: 82.2153\n",
      "Train loss: 0.0003 | Test loss: 0.5464 | Test acc: 80.4643\n",
      "Train loss: 0.0002 | Test loss: 0.5083 | Test acc: 82.1361\n",
      "Train loss: 0.0002 | Test loss: 0.4918 | Test acc: 82.5707\n",
      "Train loss: 0.0002 | Test loss: 0.4960 | Test acc: 83.2910\n",
      "Train loss: 0.0004 | Test loss: 0.4876 | Test acc: 83.5329\n",
      "Train loss: 0.0001 | Test loss: 0.4841 | Test acc: 83.4737\n",
      "Train loss: 0.0002 | Test loss: 0.5126 | Test acc: 82.1657\n",
      "Train loss: 0.0002 | Test loss: 0.5356 | Test acc: 82.1914\n",
      "Train loss: 0.0005 | Test loss: 0.5278 | Test acc: 82.1216\n",
      "Train loss: 0.0002 | Test loss: 0.5486 | Test acc: 81.4225\n",
      "Train loss: 0.0003 | Test loss: 0.4924 | Test acc: 83.2074\n",
      "Train loss: 0.0003 | Test loss: 0.5046 | Test acc: 82.3645\n",
      "Train loss: 0.0003 | Test loss: 0.4891 | Test acc: 83.3402\n",
      "Train loss: 0.0003 | Test loss: 0.5150 | Test acc: 81.5063\n",
      "Train loss: 0.0002 | Test loss: 0.4995 | Test acc: 82.3990\n",
      "Train loss: 0.0001 | Test loss: 0.4921 | Test acc: 82.4817\n",
      "Train loss: 0.0003 | Test loss: 0.4706 | Test acc: 83.7599\n",
      "Train loss: 0.0003 | Test loss: 0.5163 | Test acc: 82.2464\n",
      "Train loss: 0.0005 | Test loss: 0.5523 | Test acc: 80.8938\n",
      "Train loss: 0.0002 | Test loss: 0.4982 | Test acc: 82.7864\n",
      "Train loss: 0.0003 | Test loss: 0.5018 | Test acc: 82.9222\n",
      "Train loss: 0.0002 | Test loss: 0.5093 | Test acc: 82.1240\n",
      "Train loss: 0.0003 | Test loss: 0.5049 | Test acc: 82.6805\n",
      "Train loss: 0.0002 | Test loss: 0.4935 | Test acc: 82.8320\n",
      "Train loss: 0.0002 | Test loss: 0.4922 | Test acc: 82.8325\n",
      "Train loss: 0.0001 | Test loss: 0.4894 | Test acc: 82.6029\n",
      "Train loss: 0.0002 | Test loss: 0.4936 | Test acc: 83.1114\n",
      "Train loss: 0.0003 | Test loss: 0.5148 | Test acc: 81.4456\n",
      "Train loss: 0.0002 | Test loss: 0.5066 | Test acc: 82.7782\n",
      "Train loss: 0.0002 | Test loss: 0.4772 | Test acc: 83.7110\n",
      "Train loss: 0.0002 | Test loss: 0.4698 | Test acc: 83.8337\n",
      "Train loss: 0.0002 | Test loss: 0.4726 | Test acc: 83.6444\n",
      "Train loss: 0.0003 | Test loss: 0.5036 | Test acc: 82.6255\n",
      "Train loss: 0.0003 | Test loss: 0.5085 | Test acc: 82.6522\n",
      "Train loss: 0.0002 | Test loss: 0.5056 | Test acc: 82.9717\n",
      "Train loss: 0.0003 | Test loss: 0.4888 | Test acc: 83.5319\n",
      "Train loss: 0.0002 | Test loss: 0.4995 | Test acc: 82.4753\n",
      "Train loss: 0.0003 | Test loss: 0.4827 | Test acc: 83.4105\n",
      "Train loss: 0.0002 | Test loss: 0.5355 | Test acc: 80.9174\n",
      "Train loss: 0.0004 | Test loss: 0.5253 | Test acc: 82.4271\n",
      "Train loss: 0.0001 | Test loss: 0.5285 | Test acc: 82.0924\n",
      "Train loss: 0.0002 | Test loss: 0.5276 | Test acc: 82.2511\n",
      "Train loss: 0.0002 | Test loss: 0.4810 | Test acc: 83.5495\n",
      "Train loss: 0.0002 | Test loss: 0.4875 | Test acc: 83.5237\n",
      "Train loss: 0.0002 | Test loss: 0.4909 | Test acc: 83.2641\n",
      "Train loss: 0.0002 | Test loss: 0.4839 | Test acc: 83.2133\n",
      "Train loss: 0.0003 | Test loss: 0.5358 | Test acc: 81.2064\n",
      "Train loss: 0.0003 | Test loss: 0.5016 | Test acc: 81.8689\n",
      "Train loss: 0.0003 | Test loss: 0.4933 | Test acc: 82.4800\n",
      "Train loss: 0.0003 | Test loss: 0.4687 | Test acc: 83.8897\n",
      "Train loss: 0.0001 | Test loss: 0.4838 | Test acc: 83.3151\n",
      "Train loss: 0.0002 | Test loss: 0.4777 | Test acc: 83.7326\n",
      "Train loss: 0.0002 | Test loss: 0.4689 | Test acc: 83.9836\n",
      "Train loss: 0.0002 | Test loss: 0.4953 | Test acc: 82.9360\n",
      "Train loss: 0.0003 | Test loss: 0.4844 | Test acc: 83.4619\n",
      "Train loss: 0.0003 | Test loss: 0.4868 | Test acc: 83.2738\n",
      "Train loss: 0.0001 | Test loss: 0.4674 | Test acc: 83.8523\n",
      "Train loss: 0.0004 | Test loss: 0.5013 | Test acc: 82.2168\n",
      "Train loss: 0.0002 | Test loss: 0.4816 | Test acc: 83.5594\n",
      "Train loss: 0.0003 | Test loss: 0.5346 | Test acc: 81.4471\n",
      "Train loss: 0.0001 | Test loss: 0.5608 | Test acc: 80.4120\n",
      "Train loss: 0.0003 | Test loss: 0.4983 | Test acc: 82.8647\n",
      "Train loss: 0.0002 | Test loss: 0.4805 | Test acc: 83.3418\n",
      "Train loss: 0.0002 | Test loss: 0.4737 | Test acc: 83.5630\n",
      "Train loss: 0.0002 | Test loss: 0.4804 | Test acc: 83.3041\n",
      "Train loss: 0.0003 | Test loss: 0.4824 | Test acc: 83.4830\n",
      "Train loss: 0.0002 | Test loss: 0.4846 | Test acc: 83.4936\n",
      "Train loss: 0.0002 | Test loss: 0.5096 | Test acc: 81.8163\n",
      "Train loss: 0.0003 | Test loss: 0.5221 | Test acc: 81.3916\n",
      "Train loss: 0.0002 | Test loss: 0.5206 | Test acc: 81.4901\n",
      "Train loss: 0.0003 | Test loss: 0.4842 | Test acc: 83.3674\n",
      "Train loss: 0.0003 | Test loss: 0.5242 | Test acc: 81.3267\n",
      "Train loss: 0.0002 | Test loss: 0.4842 | Test acc: 83.6364\n",
      "Train loss: 0.0001 | Test loss: 0.4779 | Test acc: 83.6238\n",
      "Train loss: 0.0003 | Test loss: 0.4802 | Test acc: 83.4641\n",
      "Train loss: 0.0002 | Test loss: 0.5127 | Test acc: 82.0159\n",
      "Train loss: 0.0001 | Test loss: 0.5027 | Test acc: 82.8000\n",
      "Train loss: 0.0003 | Test loss: 0.5252 | Test acc: 81.7142\n",
      "Train loss: 0.0002 | Test loss: 0.5111 | Test acc: 82.2699\n",
      "Train loss: 0.0003 | Test loss: 0.5221 | Test acc: 81.6127\n",
      "Train loss: 0.0002 | Test loss: 0.4878 | Test acc: 82.9884\n",
      "Train loss: 0.0004 | Test loss: 0.4731 | Test acc: 83.9013\n",
      "Train loss: 0.0003 | Test loss: 0.5297 | Test acc: 81.8675\n",
      "Train loss: 0.0001 | Test loss: 0.5421 | Test acc: 81.1521\n",
      "Train loss: 0.0003 | Test loss: 0.5106 | Test acc: 82.0684\n",
      "Train loss: 0.0003 | Test loss: 0.4813 | Test acc: 83.6787\n",
      "Train loss: 0.0003 | Test loss: 0.5371 | Test acc: 81.3177\n",
      "Train loss: 0.0003 | Test loss: 0.5107 | Test acc: 82.5282\n",
      "Train loss: 0.0001 | Test loss: 0.4947 | Test acc: 83.0911\n",
      "Train loss: 0.0003 | Test loss: 0.5045 | Test acc: 83.1129\n",
      "Train loss: 0.0003 | Test loss: 0.4911 | Test acc: 83.2627\n",
      "Train loss: 0.0002 | Test loss: 0.4826 | Test acc: 83.8822\n",
      "Train loss: 0.0002 | Test loss: 0.5249 | Test acc: 82.3167\n",
      "Train loss: 0.0004 | Test loss: 0.5248 | Test acc: 82.2418\n",
      "Train loss: 0.0001 | Test loss: 0.4956 | Test acc: 83.1501\n",
      "Train loss: 0.0002 | Test loss: 0.4864 | Test acc: 83.4625\n",
      "Train loss: 0.0002 | Test loss: 0.5013 | Test acc: 82.5051\n",
      "Train loss: 0.0003 | Test loss: 0.4910 | Test acc: 82.7416\n",
      "Train loss: 0.0003 | Test loss: 0.5024 | Test acc: 82.4429\n",
      "Train loss: 0.0002 | Test loss: 0.4688 | Test acc: 83.8497\n",
      "Train loss: 0.0004 | Test loss: 0.4904 | Test acc: 83.1353\n",
      "Train loss: 0.0003 | Test loss: 0.4820 | Test acc: 83.6023\n",
      "Train loss: 0.0001 | Test loss: 0.4847 | Test acc: 83.3142\n",
      "Train loss: 0.0004 | Test loss: 0.4875 | Test acc: 82.8441\n",
      "Train loss: 0.0001 | Test loss: 0.4807 | Test acc: 83.0722\n",
      "Train loss: 0.0002 | Test loss: 0.4847 | Test acc: 83.2127\n",
      "Train loss: 0.0002 | Test loss: 0.4889 | Test acc: 82.5841\n",
      "Train loss: 0.0002 | Test loss: 0.4961 | Test acc: 82.4324\n",
      "Train loss: 0.0002 | Test loss: 0.5587 | Test acc: 79.7761\n",
      "Train loss: 0.0001 | Test loss: 0.5056 | Test acc: 82.2637\n",
      "Train loss: 0.0003 | Test loss: 0.4797 | Test acc: 83.4098\n",
      "Train loss: 0.0002 | Test loss: 0.4698 | Test acc: 83.7429\n",
      "Train loss: 0.0003 | Test loss: 0.4967 | Test acc: 82.8354\n",
      "Train loss: 0.0003 | Test loss: 0.5200 | Test acc: 81.9340\n",
      "Train loss: 0.0003 | Test loss: 0.4838 | Test acc: 83.1991\n",
      "Train loss: 0.0003 | Test loss: 0.4844 | Test acc: 83.6224\n",
      "Train loss: 0.0002 | Test loss: 0.4893 | Test acc: 83.4041\n",
      "Train loss: 0.0002 | Test loss: 0.4776 | Test acc: 83.6231\n",
      "Train loss: 0.0003 | Test loss: 0.4773 | Test acc: 83.5739\n",
      "Train loss: 0.0002 | Test loss: 0.4805 | Test acc: 83.6436\n",
      "Train loss: 0.0001 | Test loss: 0.4861 | Test acc: 83.3643\n",
      "Train loss: 0.0003 | Test loss: 0.5109 | Test acc: 82.6445\n",
      "Train loss: 0.0004 | Test loss: 0.5576 | Test acc: 80.3259\n",
      "Train loss: 0.0002 | Test loss: 0.4878 | Test acc: 83.1041\n",
      "Train loss: 0.0001 | Test loss: 0.4818 | Test acc: 83.1229\n",
      "Train loss: 0.0004 | Test loss: 0.5017 | Test acc: 82.8335\n",
      "Train loss: 0.0001 | Test loss: 0.4693 | Test acc: 83.7610\n",
      "Train loss: 0.0003 | Test loss: 0.4756 | Test acc: 83.6941\n",
      "Train loss: 0.0003 | Test loss: 0.4840 | Test acc: 83.2746\n",
      "Train loss: 0.0002 | Test loss: 0.4744 | Test acc: 83.7724\n",
      "Train loss: 0.0001 | Test loss: 0.5122 | Test acc: 82.4561\n",
      "Train loss: 0.0002 | Test loss: 0.5292 | Test acc: 81.7231\n",
      "Train loss: 0.0003 | Test loss: 0.4752 | Test acc: 83.7775\n",
      "Train loss: 0.0004 | Test loss: 0.5098 | Test acc: 83.1451\n",
      "Train loss: 0.0002 | Test loss: 0.5380 | Test acc: 81.1562\n",
      "Train loss: 0.0002 | Test loss: 0.5065 | Test acc: 82.7074\n",
      "Train loss: 0.0004 | Test loss: 0.4980 | Test acc: 82.7123\n",
      "Train loss: 0.0002 | Test loss: 0.4812 | Test acc: 83.5210\n",
      "Train loss: 0.0002 | Test loss: 0.4941 | Test acc: 82.7848\n",
      "Train loss: 0.0001 | Test loss: 0.4799 | Test acc: 83.4614\n",
      "Train loss: 0.0002 | Test loss: 0.4848 | Test acc: 83.1640\n",
      "Train loss: 0.0001 | Test loss: 0.4701 | Test acc: 83.6024\n",
      "Train loss: 0.0002 | Test loss: 0.4788 | Test acc: 83.7136\n",
      "Train loss: 0.0003 | Test loss: 0.4935 | Test acc: 83.0750\n",
      "Train loss: 0.0004 | Test loss: 0.5099 | Test acc: 81.7251\n",
      "Train loss: 0.0002 | Test loss: 0.5241 | Test acc: 81.3713\n",
      "Train loss: 0.0004 | Test loss: 0.5160 | Test acc: 82.1789\n",
      "Train loss: 0.0004 | Test loss: 0.4758 | Test acc: 83.3296\n",
      "Train loss: 0.0002 | Test loss: 0.4745 | Test acc: 83.6328\n",
      "Train loss: 0.0002 | Test loss: 0.5056 | Test acc: 82.5855\n",
      "Train loss: 0.0003 | Test loss: 0.5032 | Test acc: 82.9815\n",
      "Train loss: 0.0003 | Test loss: 0.5041 | Test acc: 82.1840\n",
      "Train loss: 0.0002 | Test loss: 0.4794 | Test acc: 83.2797\n",
      "Train loss: 0.0001 | Test loss: 0.5130 | Test acc: 81.2565\n",
      "Train loss: 0.0002 | Test loss: 0.4823 | Test acc: 82.8375\n",
      "Train loss: 0.0002 | Test loss: 0.4761 | Test acc: 83.3118\n",
      "Train loss: 0.0002 | Test loss: 0.5845 | Test acc: 78.2714\n",
      "Train loss: 0.0002 | Test loss: 0.5055 | Test acc: 82.5983\n",
      "Train loss: 0.0002 | Test loss: 0.5361 | Test acc: 81.2443\n",
      "Train loss: 0.0002 | Test loss: 0.4897 | Test acc: 82.9173\n",
      "Train loss: 0.0001 | Test loss: 0.4750 | Test acc: 83.7413\n",
      "Train loss: 0.0003 | Test loss: 0.4749 | Test acc: 83.6441\n",
      "Train loss: 0.0002 | Test loss: 0.4713 | Test acc: 83.9833\n",
      "Train loss: 0.0002 | Test loss: 0.4782 | Test acc: 83.5950\n",
      "Train loss: 0.0001 | Test loss: 0.4993 | Test acc: 83.2443\n",
      "Train loss: 0.0002 | Test loss: 0.4929 | Test acc: 83.3630\n",
      "Train loss: 0.0001 | Test loss: 0.4934 | Test acc: 83.3434\n",
      "Train loss: 0.0004 | Test loss: 0.5782 | Test acc: 78.8605\n",
      "Train loss: 0.0002 | Test loss: 0.5263 | Test acc: 81.7815\n",
      "Train loss: 0.0005 | Test loss: 0.5273 | Test acc: 81.9306\n",
      "Train loss: 0.0002 | Test loss: 0.4801 | Test acc: 83.7282\n",
      "Train loss: 0.0003 | Test loss: 0.5036 | Test acc: 83.2048\n",
      "Train loss: 0.0003 | Test loss: 0.5088 | Test acc: 82.6540\n",
      "Train loss: 0.0003 | Test loss: 0.4989 | Test acc: 83.2413\n",
      "Train loss: 0.0003 | Test loss: 0.4902 | Test acc: 83.3530\n",
      "Train loss: 0.0002 | Test loss: 0.4871 | Test acc: 83.5231\n",
      "Train loss: 0.0003 | Test loss: 0.4921 | Test acc: 82.8946\n",
      "Train loss: 0.0003 | Test loss: 0.4944 | Test acc: 83.2021\n",
      "Train loss: 0.0002 | Test loss: 0.5072 | Test acc: 82.5941\n",
      "Train loss: 0.0003 | Test loss: 0.4896 | Test acc: 83.3110\n",
      "Train loss: 0.0002 | Test loss: 0.4877 | Test acc: 83.1935\n",
      "Train loss: 0.0001 | Test loss: 0.5214 | Test acc: 82.0649\n",
      "Train loss: 0.0001 | Test loss: 0.4958 | Test acc: 82.8600\n",
      "Train loss: 0.0002 | Test loss: 0.4960 | Test acc: 83.0323\n",
      "Train loss: 0.0002 | Test loss: 0.5543 | Test acc: 80.6267\n",
      "Train loss: 0.0002 | Test loss: 0.4808 | Test acc: 83.7240\n",
      "Train loss: 0.0002 | Test loss: 0.5125 | Test acc: 82.6557\n",
      "Train loss: 0.0003 | Test loss: 0.5307 | Test acc: 82.2629\n",
      "Train loss: 0.0002 | Test loss: 0.5154 | Test acc: 82.4314\n",
      "Train loss: 0.0003 | Test loss: 0.4829 | Test acc: 83.1907\n",
      "Train loss: 0.0002 | Test loss: 0.4999 | Test acc: 82.3145\n",
      "Train loss: 0.0002 | Test loss: 0.5307 | Test acc: 80.8940\n",
      "Train loss: 0.0004 | Test loss: 0.5476 | Test acc: 81.2588\n",
      "Train loss: 0.0002 | Test loss: 0.5151 | Test acc: 82.4481\n",
      "Train loss: 0.0002 | Test loss: 0.5499 | Test acc: 81.1640\n",
      "Train loss: 0.0003 | Test loss: 0.5223 | Test acc: 81.4694\n",
      "Train loss: 0.0001 | Test loss: 0.5181 | Test acc: 82.3090\n",
      "Train loss: 0.0004 | Test loss: 0.5416 | Test acc: 81.1835\n",
      "Train loss: 0.0003 | Test loss: 0.5042 | Test acc: 82.9670\n",
      "Train loss: 0.0003 | Test loss: 0.4908 | Test acc: 83.2423\n",
      "Train loss: 0.0002 | Test loss: 0.4748 | Test acc: 83.7923\n",
      "Train loss: 0.0003 | Test loss: 0.5015 | Test acc: 82.3763\n",
      "Train loss: 0.0002 | Test loss: 0.4776 | Test acc: 83.3502\n",
      "Train loss: 0.0004 | Test loss: 0.6279 | Test acc: 77.7024\n",
      "Train loss: 0.0003 | Test loss: 0.5202 | Test acc: 81.6081\n",
      "Train loss: 0.0003 | Test loss: 0.4916 | Test acc: 82.7687\n",
      "Train loss: 0.0002 | Test loss: 0.4893 | Test acc: 82.9122\n",
      "Train loss: 0.0003 | Test loss: 0.5448 | Test acc: 82.2537\n",
      "Train loss: 0.0002 | Test loss: 0.4935 | Test acc: 83.2500\n",
      "Train loss: 0.0003 | Test loss: 0.5279 | Test acc: 82.8139\n",
      "Train loss: 0.0003 | Test loss: 0.5221 | Test acc: 82.3632\n",
      "Train loss: 0.0002 | Test loss: 0.5137 | Test acc: 82.7112\n",
      "Train loss: 0.0002 | Test loss: 0.5103 | Test acc: 82.6424\n",
      "Train loss: 0.0005 | Test loss: 0.5128 | Test acc: 82.5723\n",
      "Train loss: 0.0003 | Test loss: 0.5411 | Test acc: 81.7834\n",
      "Train loss: 0.0002 | Test loss: 0.5046 | Test acc: 83.1487\n",
      "Train loss: 0.0002 | Test loss: 0.4744 | Test acc: 84.1315\n",
      "Train loss: 0.0003 | Test loss: 0.5241 | Test acc: 82.6869\n",
      "Train loss: 0.0003 | Test loss: 0.5281 | Test acc: 81.2147\n",
      "Train loss: 0.0001 | Test loss: 0.5053 | Test acc: 82.6077\n",
      "Train loss: 0.0001 | Test loss: 0.4987 | Test acc: 83.0614\n",
      "Train loss: 0.0003 | Test loss: 0.5103 | Test acc: 82.2143\n",
      "Train loss: 0.0003 | Test loss: 0.5012 | Test acc: 82.3014\n",
      "Train loss: 0.0004 | Test loss: 0.4932 | Test acc: 82.8308\n",
      "Train loss: 0.0003 | Test loss: 0.5160 | Test acc: 82.0837\n",
      "Train loss: 0.0002 | Test loss: 0.4888 | Test acc: 83.1896\n",
      "Train loss: 0.0003 | Test loss: 0.4856 | Test acc: 83.3828\n",
      "Train loss: 0.0002 | Test loss: 0.4820 | Test acc: 83.7329\n",
      "Train loss: 0.0002 | Test loss: 0.4972 | Test acc: 82.6856\n",
      "Train loss: 0.0002 | Test loss: 0.4812 | Test acc: 83.3013\n",
      "Train loss: 0.0002 | Test loss: 0.4690 | Test acc: 83.7526\n",
      "Train loss: 0.0002 | Test loss: 0.5047 | Test acc: 82.2364\n",
      "Train loss: 0.0001 | Test loss: 0.5070 | Test acc: 82.2216\n",
      "Train loss: 0.0002 | Test loss: 0.5043 | Test acc: 82.7807\n",
      "Train loss: 0.0002 | Test loss: 0.4680 | Test acc: 84.0105\n",
      "Train loss: 0.0002 | Test loss: 0.4801 | Test acc: 83.4054\n",
      "Train loss: 0.0003 | Test loss: 0.5145 | Test acc: 81.9558\n",
      "Train loss: 0.0005 | Test loss: 0.4717 | Test acc: 83.6983\n",
      "Train loss: 0.0003 | Test loss: 0.4767 | Test acc: 83.8637\n",
      "Train loss: 0.0003 | Test loss: 0.4850 | Test acc: 83.7544\n",
      "Train loss: 0.0002 | Test loss: 0.4791 | Test acc: 83.3646\n",
      "Train loss: 0.0002 | Test loss: 0.4745 | Test acc: 83.7328\n",
      "Train loss: 0.0002 | Test loss: 0.4725 | Test acc: 83.4644\n",
      "Train loss: 0.0001 | Test loss: 0.4892 | Test acc: 83.2439\n",
      "Train loss: 0.0001 | Test loss: 0.4850 | Test acc: 83.2931\n",
      "Train loss: 0.0001 | Test loss: 0.4681 | Test acc: 83.8723\n",
      "Train loss: 0.0004 | Test loss: 0.4989 | Test acc: 82.5563\n",
      "Train loss: 0.0003 | Test loss: 0.5269 | Test acc: 81.5637\n",
      "Train loss: 0.0003 | Test loss: 0.4992 | Test acc: 82.9683\n",
      "Train loss: 0.0002 | Test loss: 0.4877 | Test acc: 83.1824\n",
      "Train loss: 0.0002 | Test loss: 0.4874 | Test acc: 83.4826\n",
      "Train loss: 0.0001 | Test loss: 0.4933 | Test acc: 83.0543\n",
      "Train loss: 0.0001 | Test loss: 0.5062 | Test acc: 82.6136\n",
      "Train loss: 0.0002 | Test loss: 0.5236 | Test acc: 81.7236\n",
      "Train loss: 0.0002 | Test loss: 0.5144 | Test acc: 82.0602\n",
      "Train loss: 0.0004 | Test loss: 0.5092 | Test acc: 82.3908\n",
      "Train loss: 0.0002 | Test loss: 0.5119 | Test acc: 82.0823\n",
      "Train loss: 0.0001 | Test loss: 0.5022 | Test acc: 82.0114\n",
      "Train loss: 0.0002 | Test loss: 0.5067 | Test acc: 82.8199\n",
      "Train loss: 0.0001 | Test loss: 0.4970 | Test acc: 83.1021\n",
      "Train loss: 0.0002 | Test loss: 0.5381 | Test acc: 81.1661\n",
      "Train loss: 0.0003 | Test loss: 0.5009 | Test acc: 83.0469\n",
      "Train loss: 0.0002 | Test loss: 0.4969 | Test acc: 83.4922\n",
      "Train loss: 0.0002 | Test loss: 0.5366 | Test acc: 81.6765\n",
      "Train loss: 0.0003 | Test loss: 0.4832 | Test acc: 83.8871\n",
      "Train loss: 0.0002 | Test loss: 0.5063 | Test acc: 82.7860\n",
      "Train loss: 0.0002 | Test loss: 0.5495 | Test acc: 80.7258\n",
      "Train loss: 0.0005 | Test loss: 0.5191 | Test acc: 81.8574\n",
      "Train loss: 0.0004 | Test loss: 0.5353 | Test acc: 80.9225\n",
      "Train loss: 0.0005 | Test loss: 0.4782 | Test acc: 83.2857\n",
      "Train loss: 0.0002 | Test loss: 0.5112 | Test acc: 82.3348\n",
      "Train loss: 0.0002 | Test loss: 0.4966 | Test acc: 83.3401\n",
      "Train loss: 0.0003 | Test loss: 0.4946 | Test acc: 83.0638\n",
      "Train loss: 0.0003 | Test loss: 0.5542 | Test acc: 80.7865\n",
      "Train loss: 0.0001 | Test loss: 0.5114 | Test acc: 82.9758\n",
      "Train loss: 0.0001 | Test loss: 0.4804 | Test acc: 83.7915\n",
      "Train loss: 0.0001 | Test loss: 0.5172 | Test acc: 82.5061\n",
      "Train loss: 0.0002 | Test loss: 0.5084 | Test acc: 82.8515\n",
      "Train loss: 0.0002 | Test loss: 0.5227 | Test acc: 82.3833\n",
      "Train loss: 0.0003 | Test loss: 0.4927 | Test acc: 83.0408\n",
      "Train loss: 0.0002 | Test loss: 0.5030 | Test acc: 83.0828\n",
      "Train loss: 0.0003 | Test loss: 0.5000 | Test acc: 83.1928\n",
      "Train loss: 0.0001 | Test loss: 0.4992 | Test acc: 83.0833\n",
      "Train loss: 0.0003 | Test loss: 0.5190 | Test acc: 81.7850\n",
      "Train loss: 0.0002 | Test loss: 0.5466 | Test acc: 80.6826\n",
      "Train loss: 0.0003 | Test loss: 0.4715 | Test acc: 83.9738\n",
      "Train loss: 0.0002 | Test loss: 0.4754 | Test acc: 83.7048\n",
      "Train loss: 0.0001 | Test loss: 0.4969 | Test acc: 83.1249\n",
      "Train loss: 0.0003 | Test loss: 0.4874 | Test acc: 83.4026\n",
      "Train loss: 0.0001 | Test loss: 0.4739 | Test acc: 83.8427\n",
      "Train loss: 0.0004 | Test loss: 0.4775 | Test acc: 83.8342\n",
      "Train loss: 0.0004 | Test loss: 0.4790 | Test acc: 83.6345\n",
      "Train loss: 0.0003 | Test loss: 0.4783 | Test acc: 83.6138\n",
      "Train loss: 0.0002 | Test loss: 0.5198 | Test acc: 81.1278\n",
      "Train loss: 0.0002 | Test loss: 0.4891 | Test acc: 82.6873\n",
      "Train loss: 0.0003 | Test loss: 0.5008 | Test acc: 82.4028\n",
      "Train loss: 0.0003 | Test loss: 0.4708 | Test acc: 83.5800\n",
      "Train loss: 0.0002 | Test loss: 0.4865 | Test acc: 83.2542\n",
      "Train loss: 0.0003 | Test loss: 0.4822 | Test acc: 83.3930\n",
      "Train loss: 0.0003 | Test loss: 0.5068 | Test acc: 81.8359\n",
      "Train loss: 0.0003 | Test loss: 0.4964 | Test acc: 82.8893\n",
      "Train loss: 0.0002 | Test loss: 0.5214 | Test acc: 80.9557\n",
      "Train loss: 0.0003 | Test loss: 0.6188 | Test acc: 77.7746\n",
      "Train loss: 0.0003 | Test loss: 0.4980 | Test acc: 82.7665\n",
      "Train loss: 0.0001 | Test loss: 0.4794 | Test acc: 83.5612\n",
      "Train loss: 0.0003 | Test loss: 0.4694 | Test acc: 83.9032\n",
      "Train loss: 0.0001 | Test loss: 0.4787 | Test acc: 83.5548\n",
      "Train loss: 0.0003 | Test loss: 0.4662 | Test acc: 84.1028\n",
      "Train loss: 0.0002 | Test loss: 0.4764 | Test acc: 83.3258\n",
      "Train loss: 0.0003 | Test loss: 0.4724 | Test acc: 83.8924\n",
      "Train loss: 0.0001 | Test loss: 0.4705 | Test acc: 83.9841\n",
      "Train loss: 0.0002 | Test loss: 0.4716 | Test acc: 83.9145\n",
      "Train loss: 0.0001 | Test loss: 0.4783 | Test acc: 83.6746\n",
      "Train loss: 0.0002 | Test loss: 0.5135 | Test acc: 82.3760\n",
      "Train loss: 0.0002 | Test loss: 0.5385 | Test acc: 81.6030\n",
      "Train loss: 0.0003 | Test loss: 0.4908 | Test acc: 83.4676\n",
      "Looked at 12800 / 60000 samples\n",
      "Train loss: 0.0002 | Test loss: 0.5022 | Test acc: 83.1840\n",
      "Train loss: 0.0003 | Test loss: 0.4870 | Test acc: 83.2330\n",
      "Train loss: 0.0002 | Test loss: 0.4850 | Test acc: 83.2132\n",
      "Train loss: 0.0003 | Test loss: 0.4861 | Test acc: 83.3130\n",
      "Train loss: 0.0004 | Test loss: 0.4966 | Test acc: 82.6843\n",
      "Train loss: 0.0002 | Test loss: 0.4847 | Test acc: 82.8321\n",
      "Train loss: 0.0002 | Test loss: 0.5032 | Test acc: 82.0837\n",
      "Train loss: 0.0002 | Test loss: 0.5133 | Test acc: 82.2810\n",
      "Train loss: 0.0003 | Test loss: 0.5066 | Test acc: 82.7209\n",
      "Train loss: 0.0004 | Test loss: 0.4903 | Test acc: 83.0718\n",
      "Train loss: 0.0002 | Test loss: 0.4992 | Test acc: 82.8832\n",
      "Train loss: 0.0002 | Test loss: 0.4824 | Test acc: 83.2420\n",
      "Train loss: 0.0004 | Test loss: 0.5061 | Test acc: 83.0036\n",
      "Train loss: 0.0002 | Test loss: 0.5349 | Test acc: 81.9245\n",
      "Train loss: 0.0004 | Test loss: 0.4866 | Test acc: 83.6583\n",
      "Train loss: 0.0002 | Test loss: 0.5243 | Test acc: 81.5972\n",
      "Train loss: 0.0002 | Test loss: 0.4866 | Test acc: 83.1081\n",
      "Train loss: 0.0002 | Test loss: 0.4738 | Test acc: 83.8518\n",
      "Train loss: 0.0003 | Test loss: 0.4722 | Test acc: 83.9240\n",
      "Train loss: 0.0004 | Test loss: 0.4838 | Test acc: 82.9259\n",
      "Train loss: 0.0002 | Test loss: 0.4742 | Test acc: 83.3820\n",
      "Train loss: 0.0003 | Test loss: 0.4701 | Test acc: 83.6829\n",
      "Train loss: 0.0002 | Test loss: 0.4960 | Test acc: 82.4459\n",
      "Train loss: 0.0001 | Test loss: 0.4914 | Test acc: 82.9811\n",
      "Train loss: 0.0002 | Test loss: 0.4857 | Test acc: 83.6617\n",
      "Train loss: 0.0003 | Test loss: 0.4683 | Test acc: 83.6339\n",
      "Train loss: 0.0002 | Test loss: 0.4783 | Test acc: 83.7037\n",
      "Train loss: 0.0002 | Test loss: 0.4954 | Test acc: 82.9751\n",
      "Train loss: 0.0003 | Test loss: 0.5083 | Test acc: 82.0742\n",
      "Train loss: 0.0003 | Test loss: 0.5526 | Test acc: 79.9547\n",
      "Train loss: 0.0004 | Test loss: 0.4884 | Test acc: 83.2527\n",
      "Train loss: 0.0003 | Test loss: 0.4664 | Test acc: 83.8622\n",
      "Train loss: 0.0001 | Test loss: 0.4822 | Test acc: 82.9856\n",
      "Train loss: 0.0001 | Test loss: 0.4985 | Test acc: 82.2140\n",
      "Train loss: 0.0003 | Test loss: 0.5636 | Test acc: 79.3361\n",
      "Train loss: 0.0002 | Test loss: 0.5190 | Test acc: 81.2838\n",
      "Train loss: 0.0002 | Test loss: 0.4909 | Test acc: 82.6379\n",
      "Train loss: 0.0002 | Test loss: 0.5063 | Test acc: 82.1031\n",
      "Train loss: 0.0003 | Test loss: 0.5097 | Test acc: 82.1413\n",
      "Train loss: 0.0003 | Test loss: 0.4959 | Test acc: 83.1199\n",
      "Train loss: 0.0003 | Test loss: 0.5161 | Test acc: 82.3243\n",
      "Train loss: 0.0002 | Test loss: 0.5078 | Test acc: 82.6212\n",
      "Train loss: 0.0002 | Test loss: 0.4936 | Test acc: 82.5823\n",
      "Train loss: 0.0003 | Test loss: 0.4834 | Test acc: 83.1412\n",
      "Train loss: 0.0001 | Test loss: 0.4817 | Test acc: 83.3926\n",
      "Train loss: 0.0002 | Test loss: 0.4800 | Test acc: 83.2936\n",
      "Train loss: 0.0002 | Test loss: 0.4781 | Test acc: 83.4031\n",
      "Train loss: 0.0005 | Test loss: 0.5062 | Test acc: 82.8344\n",
      "Train loss: 0.0003 | Test loss: 0.5079 | Test acc: 82.3733\n",
      "Train loss: 0.0003 | Test loss: 0.4927 | Test acc: 82.8111\n",
      "Train loss: 0.0002 | Test loss: 0.4868 | Test acc: 82.8824\n",
      "Train loss: 0.0002 | Test loss: 0.5108 | Test acc: 82.2137\n",
      "Train loss: 0.0003 | Test loss: 0.4890 | Test acc: 82.9603\n",
      "Train loss: 0.0003 | Test loss: 0.4990 | Test acc: 82.0342\n",
      "Train loss: 0.0003 | Test loss: 0.5235 | Test acc: 81.1427\n",
      "Train loss: 0.0002 | Test loss: 0.5218 | Test acc: 81.1398\n",
      "Train loss: 0.0003 | Test loss: 0.5117 | Test acc: 81.5891\n",
      "Train loss: 0.0003 | Test loss: 0.4734 | Test acc: 83.6872\n",
      "Train loss: 0.0002 | Test loss: 0.4968 | Test acc: 82.6955\n",
      "Train loss: 0.0003 | Test loss: 0.5280 | Test acc: 81.9435\n",
      "Train loss: 0.0002 | Test loss: 0.4791 | Test acc: 83.8780\n",
      "Train loss: 0.0002 | Test loss: 0.5409 | Test acc: 82.3367\n",
      "Train loss: 0.0002 | Test loss: 0.5223 | Test acc: 82.3817\n",
      "Train loss: 0.0002 | Test loss: 0.5151 | Test acc: 82.5316\n",
      "Train loss: 0.0001 | Test loss: 0.5138 | Test acc: 82.5720\n",
      "Train loss: 0.0002 | Test loss: 0.4790 | Test acc: 83.6304\n",
      "Train loss: 0.0003 | Test loss: 0.4762 | Test acc: 83.4441\n",
      "Train loss: 0.0005 | Test loss: 0.4892 | Test acc: 83.0741\n",
      "Train loss: 0.0002 | Test loss: 0.4926 | Test acc: 82.2942\n",
      "Train loss: 0.0003 | Test loss: 0.4851 | Test acc: 83.0205\n",
      "Train loss: 0.0001 | Test loss: 0.4726 | Test acc: 83.8415\n",
      "Train loss: 0.0003 | Test loss: 0.5015 | Test acc: 82.6660\n",
      "Train loss: 0.0003 | Test loss: 0.4887 | Test acc: 83.4310\n",
      "Train loss: 0.0002 | Test loss: 0.5327 | Test acc: 82.2654\n",
      "Train loss: 0.0005 | Test loss: 0.5329 | Test acc: 81.9122\n",
      "Train loss: 0.0003 | Test loss: 0.4982 | Test acc: 82.9993\n",
      "Train loss: 0.0001 | Test loss: 0.4776 | Test acc: 83.6518\n",
      "Train loss: 0.0002 | Test loss: 0.5343 | Test acc: 81.4074\n",
      "Train loss: 0.0003 | Test loss: 0.4959 | Test acc: 82.9378\n",
      "Train loss: 0.0001 | Test loss: 0.4768 | Test acc: 83.6915\n",
      "Train loss: 0.0002 | Test loss: 0.4890 | Test acc: 82.6655\n",
      "Train loss: 0.0002 | Test loss: 0.4919 | Test acc: 83.0417\n",
      "Train loss: 0.0002 | Test loss: 0.4907 | Test acc: 83.2026\n",
      "Train loss: 0.0003 | Test loss: 0.4879 | Test acc: 82.9535\n",
      "Train loss: 0.0003 | Test loss: 0.4992 | Test acc: 82.6931\n",
      "Train loss: 0.0005 | Test loss: 0.4736 | Test acc: 83.8305\n",
      "Train loss: 0.0002 | Test loss: 0.5146 | Test acc: 81.9471\n",
      "Train loss: 0.0003 | Test loss: 0.5178 | Test acc: 81.0126\n",
      "Train loss: 0.0002 | Test loss: 0.5108 | Test acc: 81.9681\n",
      "Train loss: 0.0002 | Test loss: 0.4823 | Test acc: 83.7084\n",
      "Train loss: 0.0003 | Test loss: 0.4783 | Test acc: 83.5741\n",
      "Train loss: 0.0002 | Test loss: 0.5175 | Test acc: 82.0761\n",
      "Train loss: 0.0003 | Test loss: 0.5010 | Test acc: 81.7718\n",
      "Train loss: 0.0004 | Test loss: 0.4688 | Test acc: 83.7077\n",
      "Train loss: 0.0001 | Test loss: 0.4665 | Test acc: 83.9735\n",
      "Train loss: 0.0003 | Test loss: 0.4877 | Test acc: 82.7763\n",
      "Train loss: 0.0002 | Test loss: 0.4662 | Test acc: 83.8407\n",
      "Train loss: 0.0003 | Test loss: 0.4685 | Test acc: 83.7443\n",
      "Train loss: 0.0001 | Test loss: 0.4815 | Test acc: 83.1549\n",
      "Train loss: 0.0003 | Test loss: 0.5344 | Test acc: 80.8967\n",
      "Train loss: 0.0002 | Test loss: 0.5013 | Test acc: 82.4569\n",
      "Train loss: 0.0002 | Test loss: 0.5230 | Test acc: 80.7646\n",
      "Train loss: 0.0002 | Test loss: 0.5198 | Test acc: 81.0288\n",
      "Train loss: 0.0002 | Test loss: 0.5369 | Test acc: 81.0696\n",
      "Train loss: 0.0002 | Test loss: 0.4949 | Test acc: 82.2977\n",
      "Train loss: 0.0003 | Test loss: 0.4790 | Test acc: 82.9606\n",
      "Train loss: 0.0001 | Test loss: 0.5249 | Test acc: 81.0957\n",
      "Train loss: 0.0001 | Test loss: 0.5037 | Test acc: 82.1181\n",
      "Train loss: 0.0003 | Test loss: 0.5624 | Test acc: 79.8949\n",
      "Train loss: 0.0003 | Test loss: 0.4829 | Test acc: 83.4821\n",
      "Train loss: 0.0003 | Test loss: 0.4950 | Test acc: 82.6449\n",
      "Train loss: 0.0002 | Test loss: 0.4902 | Test acc: 82.8120\n",
      "Train loss: 0.0002 | Test loss: 0.4982 | Test acc: 83.1619\n",
      "Train loss: 0.0003 | Test loss: 0.4802 | Test acc: 83.3428\n",
      "Train loss: 0.0002 | Test loss: 0.4960 | Test acc: 81.8258\n",
      "Train loss: 0.0003 | Test loss: 0.4908 | Test acc: 82.3101\n",
      "Train loss: 0.0004 | Test loss: 0.5124 | Test acc: 81.1036\n",
      "Train loss: 0.0002 | Test loss: 0.4796 | Test acc: 82.7571\n",
      "Train loss: 0.0003 | Test loss: 0.5354 | Test acc: 80.4661\n",
      "Train loss: 0.0003 | Test loss: 0.4635 | Test acc: 83.9831\n",
      "Train loss: 0.0002 | Test loss: 0.5343 | Test acc: 81.6182\n",
      "Train loss: 0.0002 | Test loss: 0.5265 | Test acc: 81.7604\n",
      "Train loss: 0.0002 | Test loss: 0.4958 | Test acc: 82.6294\n",
      "Train loss: 0.0003 | Test loss: 0.4814 | Test acc: 83.6206\n",
      "Train loss: 0.0002 | Test loss: 0.4822 | Test acc: 83.5938\n",
      "Train loss: 0.0001 | Test loss: 0.4860 | Test acc: 83.2243\n",
      "Train loss: 0.0001 | Test loss: 0.4822 | Test acc: 83.6724\n",
      "Train loss: 0.0003 | Test loss: 0.4676 | Test acc: 83.6739\n",
      "Train loss: 0.0004 | Test loss: 0.5401 | Test acc: 80.0996\n",
      "Train loss: 0.0004 | Test loss: 0.5321 | Test acc: 81.8254\n",
      "Train loss: 0.0001 | Test loss: 0.5164 | Test acc: 82.2602\n",
      "Train loss: 0.0004 | Test loss: 0.4796 | Test acc: 83.3099\n",
      "Train loss: 0.0002 | Test loss: 0.4793 | Test acc: 82.9239\n",
      "Train loss: 0.0004 | Test loss: 0.5158 | Test acc: 82.8927\n",
      "Train loss: 0.0002 | Test loss: 0.5161 | Test acc: 82.5632\n",
      "Train loss: 0.0002 | Test loss: 0.4933 | Test acc: 83.3708\n",
      "Train loss: 0.0004 | Test loss: 0.5695 | Test acc: 80.1585\n",
      "Train loss: 0.0004 | Test loss: 0.5060 | Test acc: 82.3847\n",
      "Train loss: 0.0002 | Test loss: 0.5350 | Test acc: 80.8343\n",
      "Train loss: 0.0002 | Test loss: 0.5251 | Test acc: 81.6780\n",
      "Train loss: 0.0004 | Test loss: 0.5144 | Test acc: 82.4295\n",
      "Train loss: 0.0003 | Test loss: 0.5028 | Test acc: 82.2821\n",
      "Train loss: 0.0002 | Test loss: 0.4699 | Test acc: 83.6994\n",
      "Train loss: 0.0004 | Test loss: 0.4833 | Test acc: 83.3445\n",
      "Train loss: 0.0002 | Test loss: 0.4868 | Test acc: 83.1836\n",
      "Train loss: 0.0004 | Test loss: 0.5253 | Test acc: 81.3061\n",
      "Train loss: 0.0001 | Test loss: 0.4989 | Test acc: 82.6779\n",
      "Train loss: 0.0001 | Test loss: 0.4868 | Test acc: 83.1016\n",
      "Train loss: 0.0001 | Test loss: 0.4666 | Test acc: 83.9616\n",
      "Train loss: 0.0002 | Test loss: 0.4854 | Test acc: 83.0558\n",
      "Train loss: 0.0001 | Test loss: 0.4739 | Test acc: 83.7218\n",
      "Train loss: 0.0002 | Test loss: 0.4705 | Test acc: 83.9037\n",
      "Train loss: 0.0003 | Test loss: 0.5123 | Test acc: 81.8775\n",
      "Train loss: 0.0003 | Test loss: 0.4857 | Test acc: 82.8794\n",
      "Train loss: 0.0004 | Test loss: 0.5292 | Test acc: 80.9157\n",
      "Train loss: 0.0002 | Test loss: 0.5570 | Test acc: 80.2905\n",
      "Train loss: 0.0003 | Test loss: 0.5009 | Test acc: 82.5049\n",
      "Train loss: 0.0004 | Test loss: 0.4807 | Test acc: 83.6003\n",
      "Train loss: 0.0002 | Test loss: 0.4864 | Test acc: 83.7435\n",
      "Train loss: 0.0002 | Test loss: 0.4819 | Test acc: 83.5743\n",
      "Train loss: 0.0003 | Test loss: 0.4838 | Test acc: 83.3441\n",
      "Train loss: 0.0001 | Test loss: 0.4884 | Test acc: 83.2435\n",
      "Train loss: 0.0002 | Test loss: 0.5441 | Test acc: 80.4676\n",
      "Train loss: 0.0002 | Test loss: 0.4834 | Test acc: 83.0147\n",
      "Train loss: 0.0003 | Test loss: 0.4984 | Test acc: 82.2740\n",
      "Train loss: 0.0003 | Test loss: 0.4797 | Test acc: 83.2501\n",
      "Train loss: 0.0002 | Test loss: 0.4854 | Test acc: 83.1633\n",
      "Train loss: 0.0002 | Test loss: 0.5149 | Test acc: 81.9151\n",
      "Train loss: 0.0003 | Test loss: 0.5809 | Test acc: 80.4235\n",
      "Train loss: 0.0003 | Test loss: 0.4972 | Test acc: 82.8348\n",
      "Train loss: 0.0003 | Test loss: 0.5026 | Test acc: 82.7327\n",
      "Train loss: 0.0003 | Test loss: 0.4847 | Test acc: 83.1417\n",
      "Train loss: 0.0003 | Test loss: 0.4826 | Test acc: 83.2528\n",
      "Train loss: 0.0002 | Test loss: 0.4683 | Test acc: 83.9121\n",
      "Train loss: 0.0003 | Test loss: 0.5013 | Test acc: 83.0856\n",
      "Train loss: 0.0003 | Test loss: 0.4830 | Test acc: 83.3425\n",
      "Train loss: 0.0002 | Test loss: 0.4726 | Test acc: 83.7227\n",
      "Train loss: 0.0002 | Test loss: 0.5165 | Test acc: 83.0051\n",
      "Train loss: 0.0001 | Test loss: 0.5110 | Test acc: 82.7632\n",
      "Train loss: 0.0003 | Test loss: 0.4928 | Test acc: 83.3415\n",
      "Train loss: 0.0001 | Test loss: 0.4946 | Test acc: 82.8042\n",
      "Train loss: 0.0003 | Test loss: 0.4889 | Test acc: 83.8508\n",
      "Train loss: 0.0002 | Test loss: 0.5128 | Test acc: 82.9756\n",
      "Train loss: 0.0002 | Test loss: 0.4833 | Test acc: 83.5518\n",
      "Train loss: 0.0003 | Test loss: 0.4798 | Test acc: 83.1344\n",
      "Train loss: 0.0002 | Test loss: 0.4798 | Test acc: 83.0931\n",
      "Train loss: 0.0003 | Test loss: 0.4982 | Test acc: 82.8034\n",
      "Train loss: 0.0002 | Test loss: 0.5105 | Test acc: 82.1136\n",
      "Train loss: 0.0003 | Test loss: 0.4877 | Test acc: 83.1697\n",
      "Train loss: 0.0003 | Test loss: 0.4824 | Test acc: 83.3827\n",
      "Train loss: 0.0002 | Test loss: 0.4734 | Test acc: 84.0024\n",
      "Train loss: 0.0003 | Test loss: 0.4823 | Test acc: 83.0459\n",
      "Train loss: 0.0002 | Test loss: 0.4724 | Test acc: 83.7218\n",
      "Train loss: 0.0001 | Test loss: 0.4738 | Test acc: 83.6740\n",
      "Train loss: 0.0002 | Test loss: 0.4797 | Test acc: 83.7138\n",
      "Train loss: 0.0002 | Test loss: 0.4870 | Test acc: 83.6840\n",
      "Train loss: 0.0002 | Test loss: 0.5088 | Test acc: 82.6855\n",
      "Train loss: 0.0004 | Test loss: 0.4871 | Test acc: 83.5709\n",
      "Train loss: 0.0002 | Test loss: 0.4961 | Test acc: 82.4355\n",
      "Train loss: 0.0001 | Test loss: 0.4968 | Test acc: 82.3021\n",
      "Train loss: 0.0003 | Test loss: 0.5163 | Test acc: 81.8225\n",
      "Train loss: 0.0002 | Test loss: 0.5091 | Test acc: 82.1604\n",
      "Train loss: 0.0003 | Test loss: 0.4772 | Test acc: 83.4294\n",
      "Train loss: 0.0001 | Test loss: 0.4854 | Test acc: 83.2038\n",
      "Train loss: 0.0003 | Test loss: 0.4676 | Test acc: 83.5526\n",
      "Train loss: 0.0002 | Test loss: 0.4677 | Test acc: 83.5836\n",
      "Train loss: 0.0002 | Test loss: 0.4746 | Test acc: 83.4639\n",
      "Train loss: 0.0001 | Test loss: 0.4779 | Test acc: 83.6233\n",
      "Train loss: 0.0002 | Test loss: 0.4868 | Test acc: 83.2344\n",
      "Train loss: 0.0002 | Test loss: 0.4824 | Test acc: 83.3730\n",
      "Train loss: 0.0005 | Test loss: 0.4672 | Test acc: 83.9025\n",
      "Train loss: 0.0001 | Test loss: 0.4623 | Test acc: 84.0939\n",
      "Train loss: 0.0002 | Test loss: 0.4639 | Test acc: 83.9847\n",
      "Train loss: 0.0002 | Test loss: 0.4821 | Test acc: 83.2156\n",
      "Train loss: 0.0002 | Test loss: 0.5171 | Test acc: 81.7455\n",
      "Train loss: 0.0002 | Test loss: 0.4774 | Test acc: 83.2783\n",
      "Train loss: 0.0003 | Test loss: 0.4903 | Test acc: 82.8240\n",
      "Train loss: 0.0003 | Test loss: 0.4656 | Test acc: 83.8010\n",
      "Train loss: 0.0003 | Test loss: 0.4715 | Test acc: 83.6943\n",
      "Train loss: 0.0001 | Test loss: 0.4871 | Test acc: 83.7538\n",
      "Train loss: 0.0002 | Test loss: 0.4763 | Test acc: 83.6542\n",
      "Train loss: 0.0002 | Test loss: 0.4619 | Test acc: 84.1031\n",
      "Train loss: 0.0002 | Test loss: 0.5027 | Test acc: 82.8865\n",
      "Train loss: 0.0002 | Test loss: 0.4771 | Test acc: 83.7712\n",
      "Train loss: 0.0004 | Test loss: 0.4770 | Test acc: 83.2349\n",
      "Train loss: 0.0001 | Test loss: 0.4758 | Test acc: 83.4728\n",
      "Train loss: 0.0002 | Test loss: 0.4772 | Test acc: 83.7831\n",
      "Train loss: 0.0003 | Test loss: 0.4777 | Test acc: 83.6942\n",
      "Train loss: 0.0004 | Test loss: 0.5238 | Test acc: 82.1264\n",
      "Train loss: 0.0004 | Test loss: 0.4983 | Test acc: 83.0000\n",
      "Train loss: 0.0002 | Test loss: 0.4956 | Test acc: 82.7532\n",
      "Train loss: 0.0001 | Test loss: 0.4953 | Test acc: 82.6825\n",
      "Train loss: 0.0003 | Test loss: 0.4842 | Test acc: 83.5210\n",
      "Train loss: 0.0003 | Test loss: 0.4747 | Test acc: 83.7832\n",
      "Train loss: 0.0002 | Test loss: 0.4819 | Test acc: 83.4146\n",
      "Train loss: 0.0002 | Test loss: 0.4728 | Test acc: 83.5333\n",
      "Train loss: 0.0002 | Test loss: 0.4740 | Test acc: 83.5337\n",
      "Train loss: 0.0003 | Test loss: 0.4954 | Test acc: 82.7050\n",
      "Train loss: 0.0003 | Test loss: 0.4616 | Test acc: 83.9803\n",
      "Train loss: 0.0002 | Test loss: 0.4585 | Test acc: 84.2539\n",
      "Train loss: 0.0003 | Test loss: 0.4813 | Test acc: 83.0667\n",
      "Train loss: 0.0003 | Test loss: 0.4868 | Test acc: 82.6136\n",
      "Train loss: 0.0001 | Test loss: 0.4773 | Test acc: 83.5806\n",
      "Train loss: 0.0001 | Test loss: 0.4799 | Test acc: 83.1444\n",
      "Train loss: 0.0002 | Test loss: 0.4789 | Test acc: 83.7221\n",
      "Train loss: 0.0002 | Test loss: 0.4769 | Test acc: 83.7040\n",
      "Train loss: 0.0001 | Test loss: 0.4629 | Test acc: 84.3030\n",
      "Train loss: 0.0003 | Test loss: 0.5724 | Test acc: 78.4642\n",
      "Train loss: 0.0001 | Test loss: 0.4681 | Test acc: 83.8669\n",
      "Train loss: 0.0002 | Test loss: 0.4805 | Test acc: 83.3850\n",
      "Train loss: 0.0002 | Test loss: 0.4643 | Test acc: 83.9126\n",
      "Train loss: 0.0002 | Test loss: 0.4997 | Test acc: 82.9159\n",
      "Train loss: 0.0002 | Test loss: 0.4701 | Test acc: 83.9011\n",
      "Train loss: 0.0002 | Test loss: 0.4713 | Test acc: 83.7645\n",
      "Train loss: 0.0002 | Test loss: 0.4991 | Test acc: 83.1051\n",
      "Train loss: 0.0002 | Test loss: 0.5047 | Test acc: 82.5638\n",
      "Train loss: 0.0003 | Test loss: 0.5448 | Test acc: 81.0246\n",
      "Train loss: 0.0003 | Test loss: 0.5056 | Test acc: 82.4673\n",
      "Train loss: 0.0001 | Test loss: 0.4804 | Test acc: 83.4903\n",
      "Train loss: 0.0003 | Test loss: 0.5296 | Test acc: 81.5866\n",
      "Train loss: 0.0003 | Test loss: 0.4858 | Test acc: 83.0782\n",
      "Train loss: 0.0003 | Test loss: 0.4776 | Test acc: 83.6221\n",
      "Train loss: 0.0002 | Test loss: 0.4746 | Test acc: 83.8634\n",
      "Train loss: 0.0003 | Test loss: 0.4809 | Test acc: 83.7544\n",
      "Train loss: 0.0002 | Test loss: 0.4776 | Test acc: 83.5643\n",
      "Train loss: 0.0002 | Test loss: 0.4735 | Test acc: 83.8632\n",
      "Train loss: 0.0001 | Test loss: 0.4740 | Test acc: 83.9141\n",
      "Train loss: 0.0002 | Test loss: 0.4877 | Test acc: 83.3651\n",
      "Train loss: 0.0002 | Test loss: 0.4767 | Test acc: 83.5830\n",
      "Train loss: 0.0002 | Test loss: 0.4843 | Test acc: 83.2243\n",
      "Train loss: 0.0002 | Test loss: 0.5016 | Test acc: 82.1549\n",
      "Train loss: 0.0003 | Test loss: 0.4726 | Test acc: 83.7689\n",
      "Train loss: 0.0002 | Test loss: 0.4605 | Test acc: 84.0735\n",
      "Train loss: 0.0003 | Test loss: 0.4765 | Test acc: 83.4455\n",
      "Train loss: 0.0002 | Test loss: 0.5073 | Test acc: 82.1156\n",
      "Train loss: 0.0001 | Test loss: 0.4808 | Test acc: 83.1697\n",
      "Train loss: 0.0002 | Test loss: 0.4763 | Test acc: 83.4027\n",
      "Train loss: 0.0003 | Test loss: 0.5261 | Test acc: 82.2453\n",
      "Train loss: 0.0002 | Test loss: 0.4767 | Test acc: 83.7692\n",
      "Train loss: 0.0004 | Test loss: 0.5219 | Test acc: 81.2580\n",
      "Train loss: 0.0005 | Test loss: 0.5050 | Test acc: 83.0072\n",
      "Train loss: 0.0003 | Test loss: 0.4948 | Test acc: 82.9329\n",
      "Train loss: 0.0003 | Test loss: 0.5184 | Test acc: 82.3936\n",
      "Train loss: 0.0003 | Test loss: 0.5138 | Test acc: 81.9525\n",
      "Train loss: 0.0002 | Test loss: 0.5330 | Test acc: 80.9927\n",
      "Train loss: 0.0002 | Test loss: 0.5213 | Test acc: 81.7683\n",
      "Train loss: 0.0002 | Test loss: 0.5316 | Test acc: 81.5112\n",
      "Train loss: 0.0002 | Test loss: 0.4894 | Test acc: 82.9381\n",
      "Train loss: 0.0003 | Test loss: 0.4872 | Test acc: 82.8728\n",
      "Train loss: 0.0001 | Test loss: 0.4826 | Test acc: 83.0623\n",
      "Train loss: 0.0005 | Test loss: 0.4897 | Test acc: 83.4423\n",
      "Train loss: 0.0002 | Test loss: 0.4946 | Test acc: 83.0941\n",
      "Train loss: 0.0002 | Test loss: 0.4763 | Test acc: 83.8817\n",
      "Train loss: 0.0004 | Test loss: 0.4662 | Test acc: 83.7844\n",
      "Train loss: 0.0002 | Test loss: 0.4673 | Test acc: 83.8739\n",
      "Train loss: 0.0001 | Test loss: 0.4695 | Test acc: 84.0439\n",
      "Train loss: 0.0002 | Test loss: 0.4743 | Test acc: 83.7749\n",
      "Train loss: 0.0003 | Test loss: 0.4872 | Test acc: 83.1550\n",
      "Train loss: 0.0002 | Test loss: 0.4917 | Test acc: 83.1131\n",
      "Train loss: 0.0003 | Test loss: 0.4783 | Test acc: 83.4724\n",
      "Train loss: 0.0003 | Test loss: 0.4666 | Test acc: 83.6832\n",
      "Train loss: 0.0002 | Test loss: 0.4695 | Test acc: 83.7737\n",
      "Train loss: 0.0003 | Test loss: 0.4952 | Test acc: 82.7756\n",
      "Train loss: 0.0002 | Test loss: 0.5422 | Test acc: 81.0652\n",
      "Train loss: 0.0003 | Test loss: 0.4815 | Test acc: 83.3960\n",
      "Train loss: 0.0003 | Test loss: 0.4765 | Test acc: 83.2537\n",
      "Train loss: 0.0002 | Test loss: 0.5151 | Test acc: 81.4860\n",
      "Train loss: 0.0002 | Test loss: 0.4959 | Test acc: 82.1194\n",
      "Train loss: 0.0002 | Test loss: 0.4636 | Test acc: 84.0283\n",
      "Train loss: 0.0001 | Test loss: 0.4623 | Test acc: 83.8947\n",
      "Train loss: 0.0002 | Test loss: 0.4602 | Test acc: 84.1239\n",
      "Train loss: 0.0002 | Test loss: 0.5008 | Test acc: 81.8582\n",
      "Train loss: 0.0002 | Test loss: 0.4916 | Test acc: 82.2903\n",
      "Train loss: 0.0001 | Test loss: 0.4925 | Test acc: 82.1719\n",
      "Train loss: 0.0001 | Test loss: 0.5084 | Test acc: 82.0117\n",
      "Train loss: 0.0002 | Test loss: 0.4749 | Test acc: 83.4090\n",
      "Train loss: 0.0003 | Test loss: 0.4894 | Test acc: 82.8743\n",
      "Train loss: 0.0002 | Test loss: 0.4776 | Test acc: 83.2320\n",
      "Train loss: 0.0003 | Test loss: 0.5059 | Test acc: 81.2863\n",
      "Train loss: 0.0003 | Test loss: 0.5063 | Test acc: 82.0289\n",
      "Train loss: 0.0003 | Test loss: 0.4906 | Test acc: 83.2493\n",
      "Train loss: 0.0002 | Test loss: 0.4789 | Test acc: 83.2931\n",
      "Train loss: 0.0001 | Test loss: 0.4738 | Test acc: 83.6227\n",
      "Train loss: 0.0003 | Test loss: 0.5136 | Test acc: 81.6270\n",
      "Train loss: 0.0003 | Test loss: 0.4980 | Test acc: 82.5491\n",
      "Train loss: 0.0003 | Test loss: 0.4686 | Test acc: 83.7901\n",
      "Train loss: 0.0001 | Test loss: 0.4721 | Test acc: 83.7142\n",
      "Train loss: 0.0001 | Test loss: 0.4920 | Test acc: 82.7555\n",
      "Train loss: 0.0003 | Test loss: 0.4930 | Test acc: 82.7524\n",
      "Train loss: 0.0001 | Test loss: 0.5025 | Test acc: 82.5527\n",
      "Train loss: 0.0004 | Test loss: 0.4745 | Test acc: 83.5205\n",
      "Train loss: 0.0002 | Test loss: 0.4723 | Test acc: 83.7133\n",
      "Train loss: 0.0002 | Test loss: 0.4841 | Test acc: 82.7655\n",
      "Train loss: 0.0002 | Test loss: 0.4849 | Test acc: 82.8423\n",
      "Train loss: 0.0003 | Test loss: 0.5175 | Test acc: 81.1053\n",
      "Train loss: 0.0003 | Test loss: 0.5010 | Test acc: 83.4760\n",
      "Train loss: 0.0004 | Test loss: 0.4775 | Test acc: 83.5534\n",
      "Train loss: 0.0003 | Test loss: 0.4942 | Test acc: 82.2657\n",
      "Train loss: 0.0002 | Test loss: 0.4843 | Test acc: 82.9605\n",
      "Train loss: 0.0004 | Test loss: 0.4953 | Test acc: 82.6732\n",
      "Train loss: 0.0002 | Test loss: 0.4663 | Test acc: 83.6906\n",
      "Train loss: 0.0002 | Test loss: 0.4981 | Test acc: 82.2262\n",
      "Train loss: 0.0002 | Test loss: 0.4794 | Test acc: 82.9205\n",
      "Train loss: 0.0004 | Test loss: 0.4840 | Test acc: 83.4418\n",
      "Train loss: 0.0003 | Test loss: 0.5031 | Test acc: 82.4850\n",
      "Train loss: 0.0001 | Test loss: 0.5085 | Test acc: 82.6717\n",
      "Train loss: 0.0002 | Test loss: 0.4834 | Test acc: 83.1715\n",
      "Train loss: 0.0002 | Test loss: 0.4915 | Test acc: 83.1431\n",
      "Train loss: 0.0003 | Test loss: 0.5553 | Test acc: 80.6570\n",
      "Train loss: 0.0004 | Test loss: 0.4833 | Test acc: 83.2749\n",
      "Train loss: 0.0002 | Test loss: 0.4786 | Test acc: 83.3331\n",
      "Train loss: 0.0003 | Test loss: 0.5194 | Test acc: 81.5262\n",
      "Train loss: 0.0002 | Test loss: 0.5087 | Test acc: 82.5887\n",
      "Train loss: 0.0003 | Test loss: 0.6161 | Test acc: 78.8980\n",
      "Train loss: 0.0003 | Test loss: 0.5417 | Test acc: 80.5137\n",
      "Train loss: 0.0002 | Test loss: 0.4925 | Test acc: 82.9050\n",
      "Train loss: 0.0003 | Test loss: 0.5025 | Test acc: 82.1638\n",
      "Train loss: 0.0002 | Test loss: 0.4952 | Test acc: 82.8304\n",
      "Train loss: 0.0002 | Test loss: 0.4768 | Test acc: 83.3816\n",
      "Train loss: 0.0002 | Test loss: 0.4832 | Test acc: 83.1837\n",
      "Train loss: 0.0002 | Test loss: 0.4890 | Test acc: 83.0134\n",
      "Train loss: 0.0004 | Test loss: 0.4811 | Test acc: 83.3223\n",
      "Train loss: 0.0003 | Test loss: 0.5061 | Test acc: 82.1752\n",
      "Train loss: 0.0003 | Test loss: 0.4681 | Test acc: 83.7989\n",
      "Train loss: 0.0002 | Test loss: 0.5039 | Test acc: 82.2865\n",
      "Train loss: 0.0002 | Test loss: 0.4790 | Test acc: 83.3300\n",
      "Train loss: 0.0003 | Test loss: 0.4869 | Test acc: 82.9340\n",
      "Train loss: 0.0002 | Test loss: 0.4752 | Test acc: 83.6615\n",
      "Train loss: 0.0002 | Test loss: 0.5270 | Test acc: 81.6670\n",
      "Train loss: 0.0003 | Test loss: 0.5764 | Test acc: 80.2629\n",
      "Train loss: 0.0006 | Test loss: 0.4744 | Test acc: 83.4034\n",
      "Train loss: 0.0002 | Test loss: 0.4890 | Test acc: 83.2437\n",
      "Train loss: 0.0001 | Test loss: 0.4660 | Test acc: 84.2416\n",
      "Train loss: 0.0002 | Test loss: 0.4646 | Test acc: 84.3247\n",
      "Train loss: 0.0003 | Test loss: 0.4674 | Test acc: 83.7359\n",
      "Train loss: 0.0003 | Test loss: 0.5003 | Test acc: 82.0367\n",
      "Train loss: 0.0004 | Test loss: 0.4792 | Test acc: 83.4091\n",
      "Train loss: 0.0002 | Test loss: 0.4802 | Test acc: 83.3635\n",
      "Train loss: 0.0002 | Test loss: 0.4813 | Test acc: 83.2536\n",
      "Train loss: 0.0003 | Test loss: 0.4711 | Test acc: 83.9621\n",
      "Train loss: 0.0002 | Test loss: 0.4820 | Test acc: 83.1257\n",
      "Train loss: 0.0002 | Test loss: 0.4873 | Test acc: 83.2927\n",
      "Train loss: 0.0002 | Test loss: 0.4843 | Test acc: 83.1735\n",
      "Train loss: 0.0003 | Test loss: 0.4831 | Test acc: 83.3428\n",
      "Train loss: 0.0004 | Test loss: 0.4889 | Test acc: 83.1037\n",
      "Train loss: 0.0002 | Test loss: 0.4936 | Test acc: 83.3825\n",
      "Train loss: 0.0003 | Test loss: 0.4797 | Test acc: 83.6031\n",
      "Train loss: 0.0001 | Test loss: 0.4760 | Test acc: 83.6836\n",
      "Train loss: 0.0003 | Test loss: 0.5038 | Test acc: 82.2961\n",
      "Train loss: 0.0004 | Test loss: 0.4914 | Test acc: 83.3001\n",
      "Train loss: 0.0004 | Test loss: 0.4838 | Test acc: 82.9439\n",
      "Train loss: 0.0002 | Test loss: 0.4822 | Test acc: 83.2322\n",
      "Train loss: 0.0003 | Test loss: 0.5061 | Test acc: 82.2547\n",
      "Train loss: 0.0002 | Test loss: 0.4744 | Test acc: 83.3798\n",
      "Train loss: 0.0003 | Test loss: 0.5334 | Test acc: 81.4165\n",
      "Train loss: 0.0003 | Test loss: 0.4972 | Test acc: 82.9678\n",
      "Train loss: 0.0002 | Test loss: 0.4832 | Test acc: 83.4120\n",
      "Train loss: 0.0002 | Test loss: 0.4796 | Test acc: 83.4933\n",
      "Train loss: 0.0001 | Test loss: 0.5108 | Test acc: 82.6050\n",
      "Train loss: 0.0003 | Test loss: 0.5326 | Test acc: 81.1245\n",
      "Looked at 25600 / 60000 samples\n",
      "Train loss: 0.0001 | Test loss: 0.5020 | Test acc: 82.4776\n",
      "Train loss: 0.0003 | Test loss: 0.4837 | Test acc: 83.5502\n",
      "Train loss: 0.0003 | Test loss: 0.5699 | Test acc: 80.3488\n",
      "Train loss: 0.0002 | Test loss: 0.4907 | Test acc: 83.1441\n",
      "Train loss: 0.0003 | Test loss: 0.4960 | Test acc: 82.8235\n",
      "Train loss: 0.0005 | Test loss: 0.4831 | Test acc: 83.3117\n",
      "Train loss: 0.0001 | Test loss: 0.4802 | Test acc: 83.3532\n",
      "Train loss: 0.0003 | Test loss: 0.5086 | Test acc: 81.8258\n",
      "Train loss: 0.0001 | Test loss: 0.5260 | Test acc: 81.0222\n",
      "Train loss: 0.0003 | Test loss: 0.4728 | Test acc: 83.8351\n",
      "Train loss: 0.0002 | Test loss: 0.4984 | Test acc: 82.4663\n",
      "Train loss: 0.0002 | Test loss: 0.4719 | Test acc: 83.4903\n",
      "Train loss: 0.0001 | Test loss: 0.4794 | Test acc: 83.2939\n",
      "Train loss: 0.0002 | Test loss: 0.4872 | Test acc: 83.2234\n",
      "Train loss: 0.0002 | Test loss: 0.4710 | Test acc: 83.6724\n",
      "Train loss: 0.0002 | Test loss: 0.4843 | Test acc: 83.1547\n",
      "Train loss: 0.0003 | Test loss: 0.5270 | Test acc: 80.2477\n",
      "Train loss: 0.0002 | Test loss: 0.5113 | Test acc: 81.7660\n",
      "Train loss: 0.0002 | Test loss: 0.4796 | Test acc: 83.0088\n",
      "Train loss: 0.0002 | Test loss: 0.4898 | Test acc: 82.7832\n",
      "Train loss: 0.0003 | Test loss: 0.4944 | Test acc: 82.7625\n",
      "Train loss: 0.0002 | Test loss: 0.4993 | Test acc: 81.9138\n",
      "Train loss: 0.0003 | Test loss: 0.4792 | Test acc: 82.9095\n",
      "Train loss: 0.0004 | Test loss: 0.5415 | Test acc: 79.9075\n",
      "Train loss: 0.0002 | Test loss: 0.5117 | Test acc: 81.5253\n",
      "Train loss: 0.0002 | Test loss: 0.4751 | Test acc: 83.6071\n",
      "Train loss: 0.0003 | Test loss: 0.4860 | Test acc: 82.9748\n",
      "Train loss: 0.0004 | Test loss: 0.5245 | Test acc: 81.5450\n",
      "Train loss: 0.0002 | Test loss: 0.5469 | Test acc: 80.7118\n",
      "Train loss: 0.0002 | Test loss: 0.5015 | Test acc: 82.5063\n",
      "Train loss: 0.0003 | Test loss: 0.5098 | Test acc: 81.7432\n",
      "Train loss: 0.0003 | Test loss: 0.5007 | Test acc: 82.2799\n",
      "Train loss: 0.0004 | Test loss: 0.4932 | Test acc: 83.0504\n",
      "Train loss: 0.0002 | Test loss: 0.4922 | Test acc: 82.9530\n",
      "Train loss: 0.0002 | Test loss: 0.4783 | Test acc: 83.5418\n",
      "Train loss: 0.0003 | Test loss: 0.4813 | Test acc: 83.4638\n",
      "Train loss: 0.0003 | Test loss: 0.4922 | Test acc: 83.0941\n",
      "Train loss: 0.0004 | Test loss: 0.5039 | Test acc: 81.9448\n",
      "Train loss: 0.0003 | Test loss: 0.4703 | Test acc: 83.7482\n",
      "Train loss: 0.0002 | Test loss: 0.4832 | Test acc: 83.1050\n",
      "Train loss: 0.0003 | Test loss: 0.4797 | Test acc: 83.0331\n",
      "Train loss: 0.0003 | Test loss: 0.4815 | Test acc: 83.1227\n",
      "Train loss: 0.0003 | Test loss: 0.4798 | Test acc: 82.9033\n",
      "Train loss: 0.0003 | Test loss: 0.4718 | Test acc: 83.2621\n",
      "Train loss: 0.0001 | Test loss: 0.4596 | Test acc: 84.0420\n",
      "Train loss: 0.0002 | Test loss: 0.4850 | Test acc: 82.9562\n",
      "Train loss: 0.0003 | Test loss: 0.5077 | Test acc: 81.6648\n",
      "Train loss: 0.0002 | Test loss: 0.4974 | Test acc: 82.2597\n",
      "Train loss: 0.0003 | Test loss: 0.5021 | Test acc: 82.2516\n",
      "Train loss: 0.0001 | Test loss: 0.5187 | Test acc: 81.7025\n",
      "Train loss: 0.0003 | Test loss: 0.4895 | Test acc: 82.9587\n",
      "Train loss: 0.0003 | Test loss: 0.5140 | Test acc: 81.6848\n",
      "Train loss: 0.0003 | Test loss: 0.4967 | Test acc: 82.6591\n",
      "Train loss: 0.0001 | Test loss: 0.5123 | Test acc: 82.5225\n",
      "Train loss: 0.0003 | Test loss: 0.4735 | Test acc: 83.6003\n",
      "Train loss: 0.0001 | Test loss: 0.4706 | Test acc: 83.5638\n",
      "Train loss: 0.0003 | Test loss: 0.4701 | Test acc: 83.5837\n",
      "Train loss: 0.0002 | Test loss: 0.5060 | Test acc: 82.1660\n",
      "Train loss: 0.0002 | Test loss: 0.4869 | Test acc: 82.6008\n",
      "Train loss: 0.0002 | Test loss: 0.4790 | Test acc: 83.2411\n",
      "Train loss: 0.0003 | Test loss: 0.5112 | Test acc: 82.0850\n",
      "Train loss: 0.0002 | Test loss: 0.5048 | Test acc: 82.6105\n",
      "Train loss: 0.0002 | Test loss: 0.4670 | Test acc: 83.8502\n",
      "Train loss: 0.0002 | Test loss: 0.4798 | Test acc: 83.4149\n",
      "Train loss: 0.0002 | Test loss: 0.4776 | Test acc: 83.5033\n",
      "Train loss: 0.0002 | Test loss: 0.4698 | Test acc: 83.7332\n",
      "Train loss: 0.0003 | Test loss: 0.5211 | Test acc: 82.7156\n",
      "Train loss: 0.0003 | Test loss: 0.4766 | Test acc: 83.6508\n",
      "Train loss: 0.0002 | Test loss: 0.4672 | Test acc: 83.7537\n",
      "Train loss: 0.0002 | Test loss: 0.4749 | Test acc: 83.4545\n",
      "Train loss: 0.0001 | Test loss: 0.4775 | Test acc: 83.2538\n",
      "Train loss: 0.0002 | Test loss: 0.4704 | Test acc: 83.6426\n",
      "Train loss: 0.0001 | Test loss: 0.4637 | Test acc: 83.7137\n",
      "Train loss: 0.0001 | Test loss: 0.4664 | Test acc: 83.6840\n",
      "Train loss: 0.0002 | Test loss: 0.4675 | Test acc: 83.7338\n",
      "Train loss: 0.0003 | Test loss: 0.4653 | Test acc: 83.8039\n",
      "Train loss: 0.0002 | Test loss: 0.4873 | Test acc: 82.9455\n",
      "Train loss: 0.0002 | Test loss: 0.4888 | Test acc: 82.9926\n",
      "Train loss: 0.0001 | Test loss: 0.5037 | Test acc: 82.4137\n",
      "Train loss: 0.0004 | Test loss: 0.4939 | Test acc: 82.8412\n",
      "Train loss: 0.0005 | Test loss: 0.5128 | Test acc: 82.1137\n",
      "Train loss: 0.0001 | Test loss: 0.5003 | Test acc: 82.4109\n",
      "Train loss: 0.0002 | Test loss: 0.4874 | Test acc: 82.8312\n",
      "Train loss: 0.0004 | Test loss: 0.4991 | Test acc: 82.6528\n",
      "Train loss: 0.0002 | Test loss: 0.4838 | Test acc: 83.3312\n",
      "Train loss: 0.0002 | Test loss: 0.5057 | Test acc: 82.6444\n",
      "Train loss: 0.0005 | Test loss: 0.4882 | Test acc: 83.3311\n",
      "Train loss: 0.0002 | Test loss: 0.4941 | Test acc: 83.1935\n",
      "Train loss: 0.0002 | Test loss: 0.4915 | Test acc: 83.1532\n",
      "Train loss: 0.0002 | Test loss: 0.4978 | Test acc: 82.6239\n",
      "Train loss: 0.0002 | Test loss: 0.5356 | Test acc: 81.0447\n",
      "Train loss: 0.0002 | Test loss: 0.5139 | Test acc: 82.1579\n",
      "Train loss: 0.0002 | Test loss: 0.5012 | Test acc: 82.7106\n",
      "Train loss: 0.0003 | Test loss: 0.4649 | Test acc: 83.9004\n",
      "Train loss: 0.0001 | Test loss: 0.4624 | Test acc: 83.9042\n",
      "Train loss: 0.0002 | Test loss: 0.4871 | Test acc: 82.7361\n",
      "Train loss: 0.0004 | Test loss: 0.5092 | Test acc: 82.5427\n",
      "Train loss: 0.0003 | Test loss: 0.4940 | Test acc: 82.2326\n",
      "Train loss: 0.0001 | Test loss: 0.4659 | Test acc: 83.7192\n",
      "Train loss: 0.0001 | Test loss: 0.4689 | Test acc: 83.8737\n",
      "Train loss: 0.0002 | Test loss: 0.4998 | Test acc: 82.4964\n",
      "Train loss: 0.0003 | Test loss: 0.4799 | Test acc: 83.0611\n",
      "Train loss: 0.0004 | Test loss: 0.4716 | Test acc: 83.6120\n",
      "Train loss: 0.0003 | Test loss: 0.4785 | Test acc: 83.4241\n",
      "Train loss: 0.0002 | Test loss: 0.4850 | Test acc: 83.1839\n",
      "Train loss: 0.0003 | Test loss: 0.4647 | Test acc: 83.7921\n",
      "Train loss: 0.0002 | Test loss: 0.5332 | Test acc: 80.2897\n",
      "Train loss: 0.0002 | Test loss: 0.4770 | Test acc: 83.1040\n",
      "Train loss: 0.0003 | Test loss: 0.5125 | Test acc: 81.7651\n",
      "Train loss: 0.0002 | Test loss: 0.5423 | Test acc: 80.3431\n",
      "Train loss: 0.0004 | Test loss: 0.4841 | Test acc: 83.1341\n",
      "Train loss: 0.0002 | Test loss: 0.4924 | Test acc: 83.0332\n",
      "Train loss: 0.0002 | Test loss: 0.5027 | Test acc: 82.7433\n",
      "Train loss: 0.0002 | Test loss: 0.4670 | Test acc: 84.0004\n",
      "Train loss: 0.0002 | Test loss: 0.4779 | Test acc: 83.2556\n",
      "Train loss: 0.0002 | Test loss: 0.4873 | Test acc: 83.1334\n",
      "Train loss: 0.0002 | Test loss: 0.4687 | Test acc: 83.8019\n",
      "Train loss: 0.0003 | Test loss: 0.4832 | Test acc: 83.3548\n",
      "Train loss: 0.0002 | Test loss: 0.4941 | Test acc: 82.8542\n",
      "Train loss: 0.0002 | Test loss: 0.4774 | Test acc: 83.4316\n",
      "Train loss: 0.0002 | Test loss: 0.5371 | Test acc: 81.0872\n",
      "Train loss: 0.0003 | Test loss: 0.5096 | Test acc: 82.0881\n",
      "Train loss: 0.0001 | Test loss: 0.4760 | Test acc: 83.3893\n",
      "Train loss: 0.0002 | Test loss: 0.4760 | Test acc: 83.3036\n",
      "Train loss: 0.0001 | Test loss: 0.4893 | Test acc: 82.9638\n",
      "Train loss: 0.0002 | Test loss: 0.4728 | Test acc: 83.3921\n",
      "Train loss: 0.0002 | Test loss: 0.4759 | Test acc: 83.2836\n",
      "Train loss: 0.0002 | Test loss: 0.4741 | Test acc: 83.3132\n",
      "Train loss: 0.0003 | Test loss: 0.4689 | Test acc: 83.6428\n",
      "Train loss: 0.0001 | Test loss: 0.4550 | Test acc: 84.3327\n",
      "Train loss: 0.0003 | Test loss: 0.4846 | Test acc: 83.3066\n",
      "Train loss: 0.0002 | Test loss: 0.5198 | Test acc: 82.0653\n",
      "Train loss: 0.0002 | Test loss: 0.5046 | Test acc: 82.7702\n",
      "Train loss: 0.0001 | Test loss: 0.4928 | Test acc: 82.9921\n",
      "Train loss: 0.0002 | Test loss: 0.4888 | Test acc: 83.1226\n",
      "Train loss: 0.0004 | Test loss: 0.4942 | Test acc: 82.8035\n",
      "Train loss: 0.0001 | Test loss: 0.4903 | Test acc: 82.7725\n",
      "Train loss: 0.0004 | Test loss: 0.5319 | Test acc: 82.2932\n",
      "Train loss: 0.0001 | Test loss: 0.5068 | Test acc: 82.9406\n",
      "Train loss: 0.0002 | Test loss: 0.4882 | Test acc: 83.2522\n",
      "Train loss: 0.0001 | Test loss: 0.4760 | Test acc: 83.7324\n",
      "Train loss: 0.0001 | Test loss: 0.4839 | Test acc: 83.2148\n",
      "Train loss: 0.0002 | Test loss: 0.4707 | Test acc: 83.8721\n",
      "Train loss: 0.0001 | Test loss: 0.4704 | Test acc: 83.8842\n",
      "Train loss: 0.0004 | Test loss: 0.5081 | Test acc: 82.0671\n",
      "Train loss: 0.0002 | Test loss: 0.5227 | Test acc: 81.6919\n",
      "Train loss: 0.0002 | Test loss: 0.5263 | Test acc: 81.6108\n",
      "Train loss: 0.0003 | Test loss: 0.4873 | Test acc: 82.8087\n",
      "Train loss: 0.0003 | Test loss: 0.5305 | Test acc: 81.3648\n",
      "Train loss: 0.0002 | Test loss: 0.4867 | Test acc: 83.3071\n",
      "Train loss: 0.0002 | Test loss: 0.5042 | Test acc: 81.8856\n",
      "Train loss: 0.0003 | Test loss: 0.4752 | Test acc: 83.0691\n",
      "Train loss: 0.0002 | Test loss: 0.4778 | Test acc: 82.9531\n",
      "Train loss: 0.0003 | Test loss: 0.4718 | Test acc: 83.8413\n",
      "Train loss: 0.0001 | Test loss: 0.4757 | Test acc: 83.6644\n",
      "Train loss: 0.0002 | Test loss: 0.4852 | Test acc: 83.2745\n",
      "Train loss: 0.0002 | Test loss: 0.4727 | Test acc: 83.6526\n",
      "Train loss: 0.0002 | Test loss: 0.4835 | Test acc: 83.0848\n",
      "Train loss: 0.0002 | Test loss: 0.4879 | Test acc: 83.0031\n",
      "Train loss: 0.0002 | Test loss: 0.4670 | Test acc: 84.1010\n",
      "Train loss: 0.0001 | Test loss: 0.4768 | Test acc: 83.5754\n",
      "Train loss: 0.0001 | Test loss: 0.4755 | Test acc: 83.7934\n",
      "Train loss: 0.0002 | Test loss: 0.4871 | Test acc: 83.1950\n",
      "Train loss: 0.0004 | Test loss: 0.4787 | Test acc: 83.7522\n",
      "Train loss: 0.0002 | Test loss: 0.5216 | Test acc: 81.2780\n",
      "Train loss: 0.0005 | Test loss: 0.5042 | Test acc: 82.2784\n",
      "Train loss: 0.0003 | Test loss: 0.5138 | Test acc: 82.2517\n",
      "Train loss: 0.0003 | Test loss: 0.4713 | Test acc: 83.7792\n",
      "Train loss: 0.0002 | Test loss: 0.4967 | Test acc: 82.8156\n",
      "Train loss: 0.0003 | Test loss: 0.6198 | Test acc: 77.7606\n",
      "Train loss: 0.0003 | Test loss: 0.5386 | Test acc: 80.9693\n",
      "Train loss: 0.0002 | Test loss: 0.4840 | Test acc: 83.4755\n",
      "Train loss: 0.0002 | Test loss: 0.4980 | Test acc: 83.3637\n",
      "Train loss: 0.0001 | Test loss: 0.5096 | Test acc: 83.0539\n",
      "Train loss: 0.0004 | Test loss: 0.5168 | Test acc: 81.7450\n",
      "Train loss: 0.0003 | Test loss: 0.5255 | Test acc: 81.9105\n",
      "Train loss: 0.0004 | Test loss: 0.5277 | Test acc: 81.1623\n",
      "Train loss: 0.0002 | Test loss: 0.5343 | Test acc: 81.0800\n",
      "Train loss: 0.0002 | Test loss: 0.5543 | Test acc: 80.8201\n",
      "Train loss: 0.0003 | Test loss: 0.5003 | Test acc: 82.8660\n",
      "Train loss: 0.0001 | Test loss: 0.4981 | Test acc: 82.9025\n",
      "Train loss: 0.0002 | Test loss: 0.4901 | Test acc: 83.1622\n",
      "Train loss: 0.0002 | Test loss: 0.5185 | Test acc: 82.0748\n",
      "Train loss: 0.0003 | Test loss: 0.5230 | Test acc: 82.1113\n",
      "Train loss: 0.0001 | Test loss: 0.5122 | Test acc: 82.2312\n",
      "Train loss: 0.0003 | Test loss: 0.5031 | Test acc: 82.8106\n",
      "Train loss: 0.0006 | Test loss: 0.5840 | Test acc: 79.7474\n",
      "Train loss: 0.0007 | Test loss: 0.7373 | Test acc: 75.3147\n",
      "Train loss: 0.0003 | Test loss: 0.5293 | Test acc: 81.6903\n",
      "Train loss: 0.0002 | Test loss: 0.5414 | Test acc: 81.5709\n",
      "Train loss: 0.0002 | Test loss: 0.5114 | Test acc: 82.6089\n",
      "Train loss: 0.0002 | Test loss: 0.5712 | Test acc: 81.1046\n",
      "Train loss: 0.0002 | Test loss: 0.5393 | Test acc: 82.1581\n",
      "Train loss: 0.0003 | Test loss: 0.5283 | Test acc: 82.2114\n",
      "Train loss: 0.0004 | Test loss: 0.5135 | Test acc: 81.9520\n",
      "Train loss: 0.0002 | Test loss: 0.4985 | Test acc: 82.7199\n",
      "Train loss: 0.0004 | Test loss: 0.5243 | Test acc: 82.4128\n",
      "Train loss: 0.0002 | Test loss: 0.5043 | Test acc: 82.9909\n",
      "Train loss: 0.0002 | Test loss: 0.5241 | Test acc: 82.1741\n",
      "Train loss: 0.0002 | Test loss: 0.4952 | Test acc: 83.3795\n",
      "Train loss: 0.0002 | Test loss: 0.4966 | Test acc: 83.1338\n",
      "Train loss: 0.0003 | Test loss: 0.4934 | Test acc: 82.4741\n",
      "Train loss: 0.0002 | Test loss: 0.5132 | Test acc: 82.0327\n",
      "Train loss: 0.0004 | Test loss: 0.5146 | Test acc: 82.5105\n",
      "Train loss: 0.0002 | Test loss: 0.5328 | Test acc: 82.0827\n",
      "Train loss: 0.0003 | Test loss: 0.5550 | Test acc: 81.4124\n",
      "Train loss: 0.0001 | Test loss: 0.5182 | Test acc: 82.5684\n",
      "Train loss: 0.0002 | Test loss: 0.4976 | Test acc: 82.8916\n",
      "Train loss: 0.0003 | Test loss: 0.5524 | Test acc: 81.1953\n",
      "Train loss: 0.0002 | Test loss: 0.4841 | Test acc: 83.4962\n",
      "Train loss: 0.0002 | Test loss: 0.4826 | Test acc: 83.3139\n",
      "Train loss: 0.0002 | Test loss: 0.4740 | Test acc: 83.8225\n",
      "Train loss: 0.0001 | Test loss: 0.4727 | Test acc: 83.7942\n",
      "Train loss: 0.0004 | Test loss: 0.5003 | Test acc: 83.0553\n",
      "Train loss: 0.0002 | Test loss: 0.4986 | Test acc: 83.1028\n",
      "Train loss: 0.0003 | Test loss: 0.4921 | Test acc: 83.3725\n",
      "Train loss: 0.0002 | Test loss: 0.4959 | Test acc: 83.2336\n",
      "Train loss: 0.0002 | Test loss: 0.4831 | Test acc: 83.2531\n",
      "Train loss: 0.0002 | Test loss: 0.4821 | Test acc: 83.0935\n",
      "Train loss: 0.0002 | Test loss: 0.4879 | Test acc: 83.4424\n",
      "Train loss: 0.0003 | Test loss: 0.4847 | Test acc: 83.7730\n",
      "Train loss: 0.0003 | Test loss: 0.5162 | Test acc: 82.6159\n",
      "Train loss: 0.0003 | Test loss: 0.5206 | Test acc: 82.8318\n",
      "Train loss: 0.0002 | Test loss: 0.5235 | Test acc: 82.6628\n",
      "Train loss: 0.0003 | Test loss: 0.4656 | Test acc: 84.0201\n",
      "Train loss: 0.0003 | Test loss: 0.4702 | Test acc: 83.5851\n",
      "Train loss: 0.0001 | Test loss: 0.4726 | Test acc: 83.9232\n",
      "Train loss: 0.0001 | Test loss: 0.4746 | Test acc: 83.6547\n",
      "Train loss: 0.0003 | Test loss: 0.5089 | Test acc: 82.1562\n",
      "Train loss: 0.0003 | Test loss: 0.5055 | Test acc: 82.3212\n",
      "Train loss: 0.0003 | Test loss: 0.4988 | Test acc: 82.5114\n",
      "Train loss: 0.0002 | Test loss: 0.4958 | Test acc: 82.8016\n",
      "Train loss: 0.0003 | Test loss: 0.5015 | Test acc: 83.0022\n",
      "Train loss: 0.0002 | Test loss: 0.4724 | Test acc: 83.7616\n",
      "Train loss: 0.0002 | Test loss: 0.4772 | Test acc: 83.6442\n",
      "Train loss: 0.0005 | Test loss: 0.4910 | Test acc: 83.0148\n",
      "Train loss: 0.0004 | Test loss: 0.5281 | Test acc: 81.1957\n",
      "Train loss: 0.0002 | Test loss: 0.5200 | Test acc: 81.9088\n",
      "Train loss: 0.0006 | Test loss: 0.4937 | Test acc: 83.0093\n",
      "Train loss: 0.0002 | Test loss: 0.4834 | Test acc: 83.1027\n",
      "Train loss: 0.0002 | Test loss: 0.5051 | Test acc: 82.2044\n",
      "Train loss: 0.0002 | Test loss: 0.5322 | Test acc: 80.6840\n",
      "Train loss: 0.0005 | Test loss: 0.5266 | Test acc: 82.7258\n",
      "Train loss: 0.0001 | Test loss: 0.5212 | Test acc: 82.9820\n",
      "Train loss: 0.0003 | Test loss: 0.5153 | Test acc: 82.2240\n",
      "Train loss: 0.0003 | Test loss: 0.4652 | Test acc: 83.7791\n",
      "Train loss: 0.0002 | Test loss: 0.4657 | Test acc: 83.9937\n",
      "Train loss: 0.0003 | Test loss: 0.4884 | Test acc: 82.9461\n",
      "Train loss: 0.0002 | Test loss: 0.4786 | Test acc: 83.2822\n",
      "Train loss: 0.0002 | Test loss: 0.4808 | Test acc: 83.2433\n",
      "Train loss: 0.0003 | Test loss: 0.5251 | Test acc: 82.3047\n",
      "Train loss: 0.0003 | Test loss: 0.4934 | Test acc: 83.2302\n",
      "Train loss: 0.0002 | Test loss: 0.4935 | Test acc: 83.0435\n",
      "Train loss: 0.0002 | Test loss: 0.4718 | Test acc: 83.8416\n",
      "Train loss: 0.0002 | Test loss: 0.4726 | Test acc: 83.8042\n",
      "Train loss: 0.0001 | Test loss: 0.4935 | Test acc: 83.0753\n",
      "Train loss: 0.0005 | Test loss: 0.4893 | Test acc: 83.2826\n",
      "Train loss: 0.0002 | Test loss: 0.5045 | Test acc: 82.9837\n",
      "Train loss: 0.0003 | Test loss: 0.4723 | Test acc: 83.7815\n",
      "Train loss: 0.0003 | Test loss: 0.4867 | Test acc: 83.5444\n",
      "Train loss: 0.0002 | Test loss: 0.4767 | Test acc: 83.5337\n",
      "Train loss: 0.0003 | Test loss: 0.5100 | Test acc: 81.2473\n",
      "Train loss: 0.0002 | Test loss: 0.4715 | Test acc: 83.4664\n",
      "Train loss: 0.0002 | Test loss: 0.4746 | Test acc: 83.3937\n",
      "Train loss: 0.0001 | Test loss: 0.4693 | Test acc: 83.6330\n",
      "Train loss: 0.0002 | Test loss: 0.4742 | Test acc: 83.6837\n",
      "Train loss: 0.0002 | Test loss: 0.4817 | Test acc: 83.5741\n",
      "Train loss: 0.0003 | Test loss: 0.4825 | Test acc: 83.4938\n",
      "Train loss: 0.0003 | Test loss: 0.4755 | Test acc: 83.5834\n",
      "Train loss: 0.0004 | Test loss: 0.5361 | Test acc: 81.5869\n",
      "Train loss: 0.0003 | Test loss: 0.4666 | Test acc: 83.7671\n",
      "Train loss: 0.0004 | Test loss: 0.5150 | Test acc: 81.1782\n",
      "Train loss: 0.0001 | Test loss: 0.4683 | Test acc: 83.3764\n",
      "Train loss: 0.0002 | Test loss: 0.4643 | Test acc: 83.9425\n",
      "Train loss: 0.0002 | Test loss: 0.4883 | Test acc: 83.5549\n",
      "Train loss: 0.0002 | Test loss: 0.4722 | Test acc: 83.9131\n",
      "Train loss: 0.0001 | Test loss: 0.4787 | Test acc: 83.6946\n",
      "Train loss: 0.0002 | Test loss: 0.4749 | Test acc: 83.8237\n",
      "Train loss: 0.0004 | Test loss: 0.4867 | Test acc: 83.3649\n",
      "Train loss: 0.0001 | Test loss: 0.4806 | Test acc: 83.6230\n",
      "Train loss: 0.0002 | Test loss: 0.4653 | Test acc: 84.1230\n",
      "Train loss: 0.0003 | Test loss: 0.4640 | Test acc: 83.9449\n",
      "Train loss: 0.0003 | Test loss: 0.4777 | Test acc: 84.0741\n",
      "Train loss: 0.0003 | Test loss: 0.4910 | Test acc: 82.9164\n",
      "Train loss: 0.0002 | Test loss: 0.4983 | Test acc: 83.0225\n",
      "Train loss: 0.0002 | Test loss: 0.4810 | Test acc: 83.7317\n",
      "Train loss: 0.0002 | Test loss: 0.4750 | Test acc: 83.7839\n",
      "Train loss: 0.0002 | Test loss: 0.4773 | Test acc: 83.8240\n",
      "Train loss: 0.0001 | Test loss: 0.4870 | Test acc: 83.5745\n",
      "Train loss: 0.0002 | Test loss: 0.4893 | Test acc: 83.5737\n",
      "Train loss: 0.0003 | Test loss: 0.4873 | Test acc: 83.2243\n",
      "Train loss: 0.0002 | Test loss: 0.4766 | Test acc: 83.4528\n",
      "Train loss: 0.0003 | Test loss: 0.4896 | Test acc: 83.5534\n",
      "Train loss: 0.0002 | Test loss: 0.4860 | Test acc: 83.4838\n",
      "Train loss: 0.0002 | Test loss: 0.4856 | Test acc: 83.2140\n",
      "Train loss: 0.0004 | Test loss: 0.4662 | Test acc: 84.0418\n",
      "Train loss: 0.0004 | Test loss: 0.4895 | Test acc: 82.9762\n",
      "Train loss: 0.0002 | Test loss: 0.5004 | Test acc: 82.6034\n",
      "Train loss: 0.0005 | Test loss: 0.4999 | Test acc: 82.2228\n",
      "Train loss: 0.0001 | Test loss: 0.4761 | Test acc: 83.2799\n",
      "Train loss: 0.0003 | Test loss: 0.4718 | Test acc: 84.0520\n",
      "Train loss: 0.0002 | Test loss: 0.4856 | Test acc: 83.4455\n",
      "Train loss: 0.0003 | Test loss: 0.4825 | Test acc: 83.7630\n",
      "Train loss: 0.0003 | Test loss: 0.4665 | Test acc: 83.9138\n",
      "Train loss: 0.0002 | Test loss: 0.5002 | Test acc: 82.1171\n",
      "Train loss: 0.0003 | Test loss: 0.4771 | Test acc: 83.3594\n",
      "Train loss: 0.0003 | Test loss: 0.4949 | Test acc: 82.9241\n",
      "Train loss: 0.0002 | Test loss: 0.5179 | Test acc: 82.5732\n",
      "Train loss: 0.0005 | Test loss: 0.5785 | Test acc: 78.1592\n",
      "Train loss: 0.0003 | Test loss: 0.4796 | Test acc: 83.5664\n",
      "Train loss: 0.0003 | Test loss: 0.4770 | Test acc: 83.8033\n",
      "Train loss: 0.0003 | Test loss: 0.4640 | Test acc: 84.0437\n",
      "Train loss: 0.0004 | Test loss: 0.4642 | Test acc: 84.1942\n",
      "Train loss: 0.0002 | Test loss: 0.4816 | Test acc: 83.6755\n",
      "Train loss: 0.0003 | Test loss: 0.4768 | Test acc: 83.3444\n",
      "Train loss: 0.0002 | Test loss: 0.4679 | Test acc: 83.7028\n",
      "Train loss: 0.0002 | Test loss: 0.5057 | Test acc: 82.6157\n",
      "Train loss: 0.0002 | Test loss: 0.4914 | Test acc: 82.9716\n",
      "Train loss: 0.0002 | Test loss: 0.4603 | Test acc: 84.1409\n",
      "Train loss: 0.0002 | Test loss: 0.4570 | Test acc: 84.4042\n",
      "Train loss: 0.0003 | Test loss: 0.4618 | Test acc: 84.0556\n",
      "Train loss: 0.0002 | Test loss: 0.4939 | Test acc: 83.0162\n",
      "Train loss: 0.0002 | Test loss: 0.4843 | Test acc: 83.4621\n",
      "Train loss: 0.0002 | Test loss: 0.4904 | Test acc: 83.0342\n",
      "Train loss: 0.0002 | Test loss: 0.4807 | Test acc: 83.3923\n",
      "Train loss: 0.0003 | Test loss: 0.4858 | Test acc: 83.2237\n",
      "Train loss: 0.0001 | Test loss: 0.5124 | Test acc: 81.3561\n",
      "Train loss: 0.0002 | Test loss: 0.4858 | Test acc: 83.4169\n",
      "Train loss: 0.0002 | Test loss: 0.4839 | Test acc: 83.3136\n",
      "Train loss: 0.0002 | Test loss: 0.4854 | Test acc: 83.1935\n",
      "Train loss: 0.0002 | Test loss: 0.5016 | Test acc: 82.9136\n",
      "Train loss: 0.0004 | Test loss: 0.5126 | Test acc: 82.5632\n",
      "Train loss: 0.0003 | Test loss: 0.4661 | Test acc: 83.8101\n",
      "Train loss: 0.0002 | Test loss: 0.4597 | Test acc: 84.1835\n",
      "Train loss: 0.0002 | Test loss: 0.4612 | Test acc: 83.8452\n",
      "Train loss: 0.0003 | Test loss: 0.4910 | Test acc: 83.5746\n",
      "Train loss: 0.0002 | Test loss: 0.4911 | Test acc: 83.5238\n",
      "Train loss: 0.0002 | Test loss: 0.4805 | Test acc: 83.9629\n",
      "Train loss: 0.0003 | Test loss: 0.4900 | Test acc: 82.6864\n",
      "Train loss: 0.0003 | Test loss: 0.4619 | Test acc: 83.9303\n",
      "Train loss: 0.0001 | Test loss: 0.4642 | Test acc: 83.7546\n",
      "Train loss: 0.0002 | Test loss: 0.4927 | Test acc: 82.4161\n",
      "Train loss: 0.0005 | Test loss: 0.4907 | Test acc: 83.1008\n",
      "Train loss: 0.0003 | Test loss: 0.4879 | Test acc: 83.0630\n",
      "Train loss: 0.0003 | Test loss: 0.4883 | Test acc: 82.9531\n",
      "Train loss: 0.0003 | Test loss: 0.5096 | Test acc: 82.5134\n",
      "Train loss: 0.0005 | Test loss: 0.5179 | Test acc: 81.6833\n",
      "Train loss: 0.0002 | Test loss: 0.5131 | Test acc: 81.3812\n",
      "Train loss: 0.0003 | Test loss: 0.4740 | Test acc: 83.6666\n",
      "Train loss: 0.0003 | Test loss: 0.4877 | Test acc: 82.5856\n",
      "Train loss: 0.0001 | Test loss: 0.4913 | Test acc: 82.5422\n",
      "Train loss: 0.0003 | Test loss: 0.4662 | Test acc: 83.9298\n",
      "Train loss: 0.0002 | Test loss: 0.4702 | Test acc: 83.9243\n",
      "Train loss: 0.0002 | Test loss: 0.5110 | Test acc: 81.9674\n",
      "Train loss: 0.0001 | Test loss: 0.4717 | Test acc: 83.7982\n",
      "Train loss: 0.0001 | Test loss: 0.5266 | Test acc: 82.0169\n",
      "Train loss: 0.0002 | Test loss: 0.4957 | Test acc: 83.0596\n",
      "Train loss: 0.0003 | Test loss: 0.4823 | Test acc: 83.0030\n",
      "Train loss: 0.0004 | Test loss: 0.4754 | Test acc: 83.5719\n",
      "Train loss: 0.0003 | Test loss: 0.5392 | Test acc: 79.8097\n",
      "Train loss: 0.0002 | Test loss: 0.5234 | Test acc: 80.8061\n",
      "Train loss: 0.0005 | Test loss: 0.5129 | Test acc: 82.0273\n",
      "Train loss: 0.0003 | Test loss: 0.4904 | Test acc: 83.5388\n",
      "Train loss: 0.0002 | Test loss: 0.4780 | Test acc: 83.5936\n",
      "Train loss: 0.0002 | Test loss: 0.4920 | Test acc: 82.8549\n",
      "Train loss: 0.0003 | Test loss: 0.4961 | Test acc: 83.2120\n",
      "Train loss: 0.0003 | Test loss: 0.5188 | Test acc: 82.2746\n",
      "Train loss: 0.0002 | Test loss: 0.4751 | Test acc: 83.6095\n",
      "Train loss: 0.0002 | Test loss: 0.5148 | Test acc: 82.1861\n",
      "Train loss: 0.0003 | Test loss: 0.4922 | Test acc: 82.5110\n",
      "Train loss: 0.0003 | Test loss: 0.4795 | Test acc: 83.2309\n",
      "Train loss: 0.0003 | Test loss: 0.5090 | Test acc: 82.8937\n",
      "Train loss: 0.0004 | Test loss: 0.5007 | Test acc: 83.0923\n",
      "Train loss: 0.0003 | Test loss: 0.4868 | Test acc: 83.2227\n",
      "Train loss: 0.0003 | Test loss: 0.4650 | Test acc: 83.9620\n",
      "Train loss: 0.0002 | Test loss: 0.4684 | Test acc: 83.7247\n",
      "Train loss: 0.0002 | Test loss: 0.4673 | Test acc: 83.9736\n",
      "Train loss: 0.0002 | Test loss: 0.4649 | Test acc: 83.9145\n",
      "Train loss: 0.0003 | Test loss: 0.5160 | Test acc: 82.4766\n",
      "Train loss: 0.0003 | Test loss: 0.4862 | Test acc: 83.3406\n",
      "Train loss: 0.0002 | Test loss: 0.4910 | Test acc: 83.3933\n",
      "Train loss: 0.0002 | Test loss: 0.4756 | Test acc: 83.5532\n",
      "Train loss: 0.0002 | Test loss: 0.5128 | Test acc: 82.9247\n",
      "Train loss: 0.0003 | Test loss: 0.4798 | Test acc: 83.6216\n",
      "Train loss: 0.0002 | Test loss: 0.4978 | Test acc: 82.5156\n",
      "Train loss: 0.0004 | Test loss: 0.4752 | Test acc: 83.4206\n",
      "Train loss: 0.0002 | Test loss: 0.4790 | Test acc: 83.2038\n",
      "Train loss: 0.0004 | Test loss: 0.5090 | Test acc: 82.2646\n",
      "Train loss: 0.0002 | Test loss: 0.4801 | Test acc: 83.3199\n",
      "Train loss: 0.0002 | Test loss: 0.4774 | Test acc: 83.4431\n",
      "Train loss: 0.0004 | Test loss: 0.4925 | Test acc: 83.1939\n",
      "Train loss: 0.0003 | Test loss: 0.4756 | Test acc: 83.6324\n",
      "Train loss: 0.0002 | Test loss: 0.4919 | Test acc: 82.1861\n",
      "Train loss: 0.0003 | Test loss: 0.4671 | Test acc: 83.5992\n",
      "Train loss: 0.0003 | Test loss: 0.4813 | Test acc: 83.3042\n",
      "Train loss: 0.0001 | Test loss: 0.4753 | Test acc: 83.4331\n",
      "Train loss: 0.0001 | Test loss: 0.4687 | Test acc: 83.8928\n",
      "Train loss: 0.0004 | Test loss: 0.4673 | Test acc: 83.6047\n",
      "Train loss: 0.0002 | Test loss: 0.4706 | Test acc: 83.9532\n",
      "Train loss: 0.0002 | Test loss: 0.4691 | Test acc: 83.8445\n",
      "Looked at 38400 / 60000 samples\n",
      "Train loss: 0.0003 | Test loss: 0.5199 | Test acc: 82.1269\n",
      "Train loss: 0.0002 | Test loss: 0.5012 | Test acc: 82.9501\n",
      "Train loss: 0.0003 | Test loss: 0.4894 | Test acc: 83.5917\n",
      "Train loss: 0.0002 | Test loss: 0.4680 | Test acc: 83.9532\n",
      "Train loss: 0.0002 | Test loss: 0.4686 | Test acc: 83.8645\n",
      "Train loss: 0.0002 | Test loss: 0.4745 | Test acc: 83.7943\n",
      "Train loss: 0.0002 | Test loss: 0.4949 | Test acc: 83.3747\n",
      "Train loss: 0.0003 | Test loss: 0.4688 | Test acc: 83.7927\n",
      "Train loss: 0.0002 | Test loss: 0.4705 | Test acc: 83.9139\n",
      "Train loss: 0.0002 | Test loss: 0.4675 | Test acc: 83.6048\n",
      "Train loss: 0.0002 | Test loss: 0.4652 | Test acc: 84.0830\n",
      "Train loss: 0.0003 | Test loss: 0.5130 | Test acc: 82.5570\n",
      "Train loss: 0.0003 | Test loss: 0.4820 | Test acc: 83.5006\n",
      "Train loss: 0.0003 | Test loss: 0.4891 | Test acc: 83.4137\n",
      "Train loss: 0.0003 | Test loss: 0.4881 | Test acc: 83.4634\n",
      "Train loss: 0.0002 | Test loss: 0.4992 | Test acc: 83.0342\n",
      "Train loss: 0.0004 | Test loss: 0.5489 | Test acc: 81.9146\n",
      "Train loss: 0.0002 | Test loss: 0.4904 | Test acc: 83.0892\n",
      "Train loss: 0.0002 | Test loss: 0.4928 | Test acc: 82.8334\n",
      "Train loss: 0.0002 | Test loss: 0.4932 | Test acc: 82.3034\n",
      "Train loss: 0.0003 | Test loss: 0.5108 | Test acc: 82.1020\n",
      "Train loss: 0.0001 | Test loss: 0.4938 | Test acc: 83.0299\n",
      "Train loss: 0.0003 | Test loss: 0.5026 | Test acc: 83.1726\n",
      "Train loss: 0.0002 | Test loss: 0.4823 | Test acc: 83.7322\n",
      "Train loss: 0.0001 | Test loss: 0.4927 | Test acc: 83.2048\n",
      "Train loss: 0.0004 | Test loss: 0.4778 | Test acc: 83.5626\n",
      "Train loss: 0.0003 | Test loss: 0.4834 | Test acc: 83.2941\n",
      "Train loss: 0.0002 | Test loss: 0.4698 | Test acc: 83.6128\n",
      "Train loss: 0.0002 | Test loss: 0.4845 | Test acc: 83.1445\n",
      "Train loss: 0.0002 | Test loss: 0.4833 | Test acc: 83.1630\n",
      "Train loss: 0.0003 | Test loss: 0.4926 | Test acc: 82.1846\n",
      "Train loss: 0.0002 | Test loss: 0.4899 | Test acc: 82.1416\n",
      "Train loss: 0.0002 | Test loss: 0.5054 | Test acc: 81.7720\n",
      "Train loss: 0.0002 | Test loss: 0.4783 | Test acc: 83.2684\n",
      "Train loss: 0.0002 | Test loss: 0.4792 | Test acc: 83.2832\n",
      "Train loss: 0.0003 | Test loss: 0.4824 | Test acc: 83.4829\n",
      "Train loss: 0.0002 | Test loss: 0.4991 | Test acc: 82.6749\n",
      "Train loss: 0.0006 | Test loss: 0.4979 | Test acc: 83.1315\n",
      "Train loss: 0.0002 | Test loss: 0.5147 | Test acc: 81.7951\n",
      "Train loss: 0.0002 | Test loss: 0.4956 | Test acc: 82.6695\n",
      "Train loss: 0.0002 | Test loss: 0.5177 | Test acc: 81.9734\n",
      "Train loss: 0.0003 | Test loss: 0.4782 | Test acc: 83.1393\n",
      "Train loss: 0.0001 | Test loss: 0.4922 | Test acc: 82.7636\n",
      "Train loss: 0.0003 | Test loss: 0.4891 | Test acc: 83.1917\n",
      "Train loss: 0.0002 | Test loss: 0.4749 | Test acc: 83.4427\n",
      "Train loss: 0.0002 | Test loss: 0.4981 | Test acc: 82.5949\n",
      "Train loss: 0.0003 | Test loss: 0.4905 | Test acc: 82.7719\n",
      "Train loss: 0.0002 | Test loss: 0.5079 | Test acc: 81.6942\n",
      "Train loss: 0.0003 | Test loss: 0.5358 | Test acc: 79.9435\n",
      "Train loss: 0.0002 | Test loss: 0.4745 | Test acc: 83.2227\n",
      "Train loss: 0.0002 | Test loss: 0.4745 | Test acc: 83.5826\n",
      "Train loss: 0.0002 | Test loss: 0.4790 | Test acc: 83.7634\n",
      "Train loss: 0.0003 | Test loss: 0.4764 | Test acc: 83.2149\n",
      "Train loss: 0.0002 | Test loss: 0.5009 | Test acc: 82.2347\n",
      "Train loss: 0.0002 | Test loss: 0.4814 | Test acc: 83.1401\n",
      "Train loss: 0.0003 | Test loss: 0.4824 | Test acc: 82.7536\n",
      "Train loss: 0.0005 | Test loss: 0.4693 | Test acc: 83.3614\n",
      "Train loss: 0.0003 | Test loss: 0.4713 | Test acc: 83.7727\n",
      "Train loss: 0.0003 | Test loss: 0.4755 | Test acc: 83.7641\n",
      "Train loss: 0.0002 | Test loss: 0.5081 | Test acc: 82.5959\n",
      "Train loss: 0.0003 | Test loss: 0.4740 | Test acc: 83.8501\n",
      "Train loss: 0.0004 | Test loss: 0.4841 | Test acc: 83.1653\n",
      "Train loss: 0.0002 | Test loss: 0.4893 | Test acc: 83.0832\n",
      "Train loss: 0.0001 | Test loss: 0.4814 | Test acc: 83.2926\n",
      "Train loss: 0.0003 | Test loss: 0.4781 | Test acc: 83.4630\n",
      "Train loss: 0.0002 | Test loss: 0.4886 | Test acc: 82.7247\n",
      "Train loss: 0.0001 | Test loss: 0.4945 | Test acc: 82.9220\n",
      "Train loss: 0.0004 | Test loss: 0.5976 | Test acc: 77.9406\n",
      "Train loss: 0.0004 | Test loss: 0.4651 | Test acc: 83.8453\n",
      "Train loss: 0.0002 | Test loss: 0.4677 | Test acc: 83.6944\n",
      "Train loss: 0.0001 | Test loss: 0.4743 | Test acc: 83.3245\n",
      "Train loss: 0.0002 | Test loss: 0.4742 | Test acc: 83.6728\n",
      "Train loss: 0.0003 | Test loss: 0.4599 | Test acc: 83.9734\n",
      "Train loss: 0.0002 | Test loss: 0.4851 | Test acc: 82.9061\n",
      "Train loss: 0.0003 | Test loss: 0.4958 | Test acc: 82.8128\n",
      "Train loss: 0.0003 | Test loss: 0.5770 | Test acc: 78.9287\n",
      "Train loss: 0.0005 | Test loss: 0.5046 | Test acc: 82.5705\n",
      "Train loss: 0.0003 | Test loss: 0.5152 | Test acc: 82.4723\n",
      "Train loss: 0.0002 | Test loss: 0.5433 | Test acc: 81.2839\n",
      "Train loss: 0.0002 | Test loss: 0.5813 | Test acc: 79.8923\n",
      "Train loss: 0.0004 | Test loss: 0.5018 | Test acc: 82.4637\n",
      "Train loss: 0.0004 | Test loss: 0.4820 | Test acc: 83.5103\n",
      "Train loss: 0.0003 | Test loss: 0.5015 | Test acc: 82.7049\n",
      "Train loss: 0.0005 | Test loss: 0.4883 | Test acc: 82.6824\n",
      "Train loss: 0.0002 | Test loss: 0.4912 | Test acc: 82.8920\n",
      "Train loss: 0.0005 | Test loss: 0.4741 | Test acc: 83.8012\n",
      "Train loss: 0.0002 | Test loss: 0.4890 | Test acc: 83.0553\n",
      "Train loss: 0.0002 | Test loss: 0.5159 | Test acc: 81.9746\n",
      "Train loss: 0.0002 | Test loss: 0.4737 | Test acc: 83.4288\n",
      "Train loss: 0.0003 | Test loss: 0.4813 | Test acc: 83.3336\n",
      "Train loss: 0.0002 | Test loss: 0.5239 | Test acc: 81.4264\n",
      "Train loss: 0.0002 | Test loss: 0.4767 | Test acc: 83.6367\n",
      "Train loss: 0.0003 | Test loss: 0.4915 | Test acc: 83.1346\n",
      "Train loss: 0.0002 | Test loss: 0.5222 | Test acc: 81.8451\n",
      "Train loss: 0.0002 | Test loss: 0.5310 | Test acc: 81.5115\n",
      "Train loss: 0.0002 | Test loss: 0.4868 | Test acc: 83.3375\n",
      "Train loss: 0.0003 | Test loss: 0.4989 | Test acc: 82.8940\n",
      "Train loss: 0.0003 | Test loss: 0.4891 | Test acc: 82.9925\n",
      "Train loss: 0.0002 | Test loss: 0.4779 | Test acc: 83.5120\n",
      "Train loss: 0.0005 | Test loss: 0.4960 | Test acc: 82.5052\n",
      "Train loss: 0.0003 | Test loss: 0.4709 | Test acc: 83.5404\n",
      "Train loss: 0.0002 | Test loss: 0.4860 | Test acc: 82.9147\n",
      "Train loss: 0.0003 | Test loss: 0.5104 | Test acc: 81.3851\n",
      "Train loss: 0.0001 | Test loss: 0.4977 | Test acc: 83.0476\n",
      "Train loss: 0.0004 | Test loss: 0.4685 | Test acc: 83.9015\n",
      "Train loss: 0.0001 | Test loss: 0.4630 | Test acc: 84.2437\n",
      "Train loss: 0.0001 | Test loss: 0.4637 | Test acc: 84.1050\n",
      "Train loss: 0.0002 | Test loss: 0.5027 | Test acc: 82.7967\n",
      "Train loss: 0.0003 | Test loss: 0.5003 | Test acc: 81.9838\n",
      "Train loss: 0.0002 | Test loss: 0.4634 | Test acc: 83.8981\n",
      "Train loss: 0.0003 | Test loss: 0.4803 | Test acc: 83.4150\n",
      "Train loss: 0.0002 | Test loss: 0.5110 | Test acc: 82.9742\n",
      "Train loss: 0.0001 | Test loss: 0.4858 | Test acc: 83.4121\n",
      "Train loss: 0.0003 | Test loss: 0.5333 | Test acc: 81.2170\n",
      "Train loss: 0.0004 | Test loss: 0.4707 | Test acc: 83.7759\n",
      "Train loss: 0.0001 | Test loss: 0.4696 | Test acc: 83.7541\n",
      "Train loss: 0.0003 | Test loss: 0.5342 | Test acc: 81.5376\n",
      "Train loss: 0.0003 | Test loss: 0.4869 | Test acc: 83.3575\n",
      "Train loss: 0.0003 | Test loss: 0.4619 | Test acc: 83.8326\n",
      "Train loss: 0.0002 | Test loss: 0.4900 | Test acc: 82.8856\n",
      "Train loss: 0.0003 | Test loss: 0.5119 | Test acc: 81.9741\n",
      "Train loss: 0.0002 | Test loss: 0.5105 | Test acc: 81.8114\n",
      "Train loss: 0.0003 | Test loss: 0.4784 | Test acc: 83.1987\n",
      "Train loss: 0.0001 | Test loss: 0.4770 | Test acc: 83.1632\n",
      "Train loss: 0.0003 | Test loss: 0.4994 | Test acc: 82.4242\n",
      "Train loss: 0.0002 | Test loss: 0.4979 | Test acc: 82.1423\n",
      "Train loss: 0.0002 | Test loss: 0.4965 | Test acc: 82.5009\n",
      "Train loss: 0.0002 | Test loss: 0.4708 | Test acc: 83.2508\n",
      "Train loss: 0.0003 | Test loss: 0.4786 | Test acc: 83.1334\n",
      "Train loss: 0.0002 | Test loss: 0.5152 | Test acc: 81.2760\n",
      "Train loss: 0.0003 | Test loss: 0.4923 | Test acc: 82.7477\n",
      "Train loss: 0.0002 | Test loss: 0.4864 | Test acc: 83.2416\n",
      "Train loss: 0.0001 | Test loss: 0.4890 | Test acc: 83.0235\n",
      "Train loss: 0.0003 | Test loss: 0.4796 | Test acc: 83.6219\n",
      "Train loss: 0.0003 | Test loss: 0.4953 | Test acc: 82.5755\n",
      "Train loss: 0.0002 | Test loss: 0.4679 | Test acc: 83.8101\n",
      "Train loss: 0.0003 | Test loss: 0.4814 | Test acc: 83.2650\n",
      "Train loss: 0.0002 | Test loss: 0.4795 | Test acc: 82.5943\n",
      "Train loss: 0.0001 | Test loss: 0.5293 | Test acc: 79.8665\n",
      "Train loss: 0.0002 | Test loss: 0.4899 | Test acc: 82.2240\n",
      "Train loss: 0.0003 | Test loss: 0.5269 | Test acc: 81.0934\n",
      "Train loss: 0.0004 | Test loss: 0.4902 | Test acc: 82.4576\n",
      "Train loss: 0.0002 | Test loss: 0.4723 | Test acc: 83.5801\n",
      "Train loss: 0.0003 | Test loss: 0.4818 | Test acc: 82.9348\n",
      "Train loss: 0.0004 | Test loss: 0.5040 | Test acc: 81.8444\n",
      "Train loss: 0.0002 | Test loss: 0.5076 | Test acc: 81.3717\n",
      "Train loss: 0.0002 | Test loss: 0.4971 | Test acc: 82.1490\n",
      "Train loss: 0.0002 | Test loss: 0.4783 | Test acc: 83.2197\n",
      "Train loss: 0.0002 | Test loss: 0.4643 | Test acc: 83.8721\n",
      "Train loss: 0.0002 | Test loss: 0.4913 | Test acc: 82.6861\n",
      "Train loss: 0.0002 | Test loss: 0.5102 | Test acc: 81.7139\n",
      "Train loss: 0.0003 | Test loss: 0.4677 | Test acc: 83.6676\n",
      "Train loss: 0.0002 | Test loss: 0.4819 | Test acc: 82.9850\n",
      "Train loss: 0.0002 | Test loss: 0.4914 | Test acc: 82.5335\n",
      "Train loss: 0.0005 | Test loss: 0.4869 | Test acc: 83.2709\n",
      "Train loss: 0.0003 | Test loss: 0.4811 | Test acc: 83.3831\n",
      "Train loss: 0.0002 | Test loss: 0.4986 | Test acc: 82.5248\n",
      "Train loss: 0.0002 | Test loss: 0.4952 | Test acc: 82.7217\n",
      "Train loss: 0.0002 | Test loss: 0.4831 | Test acc: 83.0518\n",
      "Train loss: 0.0002 | Test loss: 0.4701 | Test acc: 83.8416\n",
      "Train loss: 0.0001 | Test loss: 0.4606 | Test acc: 84.1836\n",
      "Train loss: 0.0003 | Test loss: 0.4688 | Test acc: 83.7753\n",
      "Train loss: 0.0002 | Test loss: 0.4850 | Test acc: 83.5444\n",
      "Train loss: 0.0002 | Test loss: 0.4670 | Test acc: 83.8632\n",
      "Train loss: 0.0002 | Test loss: 0.4659 | Test acc: 83.7843\n",
      "Train loss: 0.0004 | Test loss: 0.5142 | Test acc: 82.0968\n",
      "Train loss: 0.0003 | Test loss: 0.4792 | Test acc: 83.4492\n",
      "Train loss: 0.0003 | Test loss: 0.4873 | Test acc: 83.1640\n",
      "Train loss: 0.0002 | Test loss: 0.5112 | Test acc: 82.0648\n",
      "Train loss: 0.0003 | Test loss: 0.4872 | Test acc: 83.0397\n",
      "Train loss: 0.0002 | Test loss: 0.4727 | Test acc: 83.6219\n",
      "Train loss: 0.0003 | Test loss: 0.4667 | Test acc: 83.7536\n",
      "Train loss: 0.0002 | Test loss: 0.4828 | Test acc: 83.3746\n",
      "Train loss: 0.0005 | Test loss: 0.4733 | Test acc: 83.9125\n",
      "Train loss: 0.0005 | Test loss: 0.4879 | Test acc: 82.7361\n",
      "Train loss: 0.0002 | Test loss: 0.5015 | Test acc: 82.1333\n",
      "Train loss: 0.0003 | Test loss: 0.5273 | Test acc: 80.7536\n",
      "Train loss: 0.0003 | Test loss: 0.5027 | Test acc: 82.4665\n",
      "Train loss: 0.0004 | Test loss: 0.4870 | Test acc: 83.0510\n",
      "Train loss: 0.0003 | Test loss: 0.4967 | Test acc: 81.6951\n",
      "Train loss: 0.0003 | Test loss: 0.4568 | Test acc: 83.9471\n",
      "Train loss: 0.0001 | Test loss: 0.4726 | Test acc: 83.4950\n",
      "Train loss: 0.0002 | Test loss: 0.4638 | Test acc: 83.8830\n",
      "Train loss: 0.0004 | Test loss: 0.4736 | Test acc: 83.8343\n",
      "Train loss: 0.0005 | Test loss: 0.4914 | Test acc: 82.6161\n",
      "Train loss: 0.0003 | Test loss: 0.4819 | Test acc: 82.8718\n",
      "Train loss: 0.0002 | Test loss: 0.4872 | Test acc: 82.7128\n",
      "Train loss: 0.0002 | Test loss: 0.4639 | Test acc: 83.6908\n",
      "Train loss: 0.0002 | Test loss: 0.4923 | Test acc: 82.5258\n",
      "Train loss: 0.0002 | Test loss: 0.4749 | Test acc: 83.2708\n",
      "Train loss: 0.0002 | Test loss: 0.4778 | Test acc: 83.4230\n",
      "Train loss: 0.0003 | Test loss: 0.4914 | Test acc: 82.8244\n",
      "Train loss: 0.0003 | Test loss: 0.4964 | Test acc: 82.8824\n",
      "Train loss: 0.0001 | Test loss: 0.4911 | Test acc: 83.0024\n",
      "Train loss: 0.0001 | Test loss: 0.5178 | Test acc: 82.2440\n",
      "Train loss: 0.0003 | Test loss: 0.5022 | Test acc: 82.1617\n",
      "Train loss: 0.0003 | Test loss: 0.4713 | Test acc: 83.3995\n",
      "Train loss: 0.0004 | Test loss: 0.4958 | Test acc: 82.5548\n",
      "Train loss: 0.0003 | Test loss: 0.4816 | Test acc: 83.2610\n",
      "Train loss: 0.0002 | Test loss: 0.4683 | Test acc: 83.7824\n",
      "Train loss: 0.0002 | Test loss: 0.5056 | Test acc: 82.5760\n",
      "Train loss: 0.0003 | Test loss: 0.4853 | Test acc: 83.2111\n",
      "Train loss: 0.0003 | Test loss: 0.4605 | Test acc: 84.0817\n",
      "Train loss: 0.0002 | Test loss: 0.4729 | Test acc: 83.6951\n",
      "Train loss: 0.0003 | Test loss: 0.4644 | Test acc: 83.9435\n",
      "Train loss: 0.0002 | Test loss: 0.4699 | Test acc: 83.7047\n",
      "Train loss: 0.0002 | Test loss: 0.5359 | Test acc: 80.8884\n",
      "Train loss: 0.0003 | Test loss: 0.5179 | Test acc: 82.0675\n",
      "Train loss: 0.0003 | Test loss: 0.4971 | Test acc: 82.6703\n",
      "Train loss: 0.0003 | Test loss: 0.4756 | Test acc: 83.3212\n",
      "Train loss: 0.0002 | Test loss: 0.5154 | Test acc: 80.9271\n",
      "Train loss: 0.0002 | Test loss: 0.4624 | Test acc: 83.9047\n",
      "Train loss: 0.0002 | Test loss: 0.4772 | Test acc: 83.2852\n",
      "Train loss: 0.0002 | Test loss: 0.4665 | Test acc: 83.9622\n",
      "Train loss: 0.0003 | Test loss: 0.4713 | Test acc: 84.0442\n",
      "Train loss: 0.0001 | Test loss: 0.4939 | Test acc: 83.3755\n",
      "Train loss: 0.0004 | Test loss: 0.4976 | Test acc: 83.0040\n",
      "Train loss: 0.0002 | Test loss: 0.4696 | Test acc: 84.1909\n",
      "Train loss: 0.0001 | Test loss: 0.4707 | Test acc: 84.0749\n",
      "Train loss: 0.0001 | Test loss: 0.4675 | Test acc: 84.1045\n",
      "Train loss: 0.0001 | Test loss: 0.4686 | Test acc: 83.7352\n",
      "Train loss: 0.0002 | Test loss: 0.4592 | Test acc: 84.0535\n",
      "Train loss: 0.0001 | Test loss: 0.4781 | Test acc: 83.4954\n",
      "Train loss: 0.0002 | Test loss: 0.4627 | Test acc: 84.0527\n",
      "Train loss: 0.0002 | Test loss: 0.4778 | Test acc: 83.4754\n",
      "Train loss: 0.0002 | Test loss: 0.4705 | Test acc: 83.7431\n",
      "Train loss: 0.0001 | Test loss: 0.4694 | Test acc: 83.9337\n",
      "Train loss: 0.0002 | Test loss: 0.4919 | Test acc: 82.8760\n",
      "Train loss: 0.0004 | Test loss: 0.5024 | Test acc: 82.8027\n",
      "Train loss: 0.0002 | Test loss: 0.4752 | Test acc: 83.7210\n",
      "Train loss: 0.0001 | Test loss: 0.4728 | Test acc: 83.6541\n",
      "Train loss: 0.0002 | Test loss: 0.4666 | Test acc: 83.7936\n",
      "Train loss: 0.0002 | Test loss: 0.4619 | Test acc: 83.9039\n",
      "Train loss: 0.0003 | Test loss: 0.4955 | Test acc: 83.1754\n",
      "Train loss: 0.0003 | Test loss: 0.4800 | Test acc: 83.4027\n",
      "Train loss: 0.0002 | Test loss: 0.4752 | Test acc: 83.8028\n",
      "Train loss: 0.0001 | Test loss: 0.4660 | Test acc: 83.7142\n",
      "Train loss: 0.0002 | Test loss: 0.4623 | Test acc: 83.9336\n",
      "Train loss: 0.0001 | Test loss: 0.4600 | Test acc: 84.0940\n",
      "Train loss: 0.0001 | Test loss: 0.4751 | Test acc: 83.3358\n",
      "Train loss: 0.0002 | Test loss: 0.4705 | Test acc: 83.3833\n",
      "Train loss: 0.0003 | Test loss: 0.4727 | Test acc: 83.7329\n",
      "Train loss: 0.0002 | Test loss: 0.4902 | Test acc: 82.5359\n",
      "Train loss: 0.0002 | Test loss: 0.4737 | Test acc: 83.2908\n",
      "Train loss: 0.0005 | Test loss: 0.4909 | Test acc: 82.7541\n",
      "Train loss: 0.0001 | Test loss: 0.5280 | Test acc: 80.5759\n",
      "Train loss: 0.0002 | Test loss: 0.5172 | Test acc: 81.3976\n",
      "Train loss: 0.0001 | Test loss: 0.4760 | Test acc: 83.2273\n",
      "Train loss: 0.0002 | Test loss: 0.4988 | Test acc: 82.2847\n",
      "Train loss: 0.0003 | Test loss: 0.4994 | Test acc: 82.9706\n",
      "Train loss: 0.0003 | Test loss: 0.4935 | Test acc: 83.1325\n",
      "Train loss: 0.0002 | Test loss: 0.4727 | Test acc: 83.7321\n",
      "Train loss: 0.0003 | Test loss: 0.5094 | Test acc: 82.2863\n",
      "Train loss: 0.0004 | Test loss: 0.4864 | Test acc: 83.3200\n",
      "Train loss: 0.0003 | Test loss: 0.5192 | Test acc: 81.0569\n",
      "Train loss: 0.0003 | Test loss: 0.5107 | Test acc: 81.2394\n",
      "Train loss: 0.0003 | Test loss: 0.5161 | Test acc: 80.7408\n",
      "Train loss: 0.0002 | Test loss: 0.4633 | Test acc: 83.8342\n",
      "Train loss: 0.0002 | Test loss: 0.4624 | Test acc: 83.9240\n",
      "Train loss: 0.0002 | Test loss: 0.4913 | Test acc: 83.0756\n",
      "Train loss: 0.0002 | Test loss: 0.4625 | Test acc: 83.9016\n",
      "Train loss: 0.0002 | Test loss: 0.4728 | Test acc: 83.7145\n",
      "Train loss: 0.0002 | Test loss: 0.4676 | Test acc: 84.0135\n",
      "Train loss: 0.0002 | Test loss: 0.4859 | Test acc: 83.5052\n",
      "Train loss: 0.0002 | Test loss: 0.4676 | Test acc: 83.8531\n",
      "Train loss: 0.0002 | Test loss: 0.4865 | Test acc: 83.0654\n",
      "Train loss: 0.0004 | Test loss: 0.4747 | Test acc: 83.6719\n",
      "Train loss: 0.0004 | Test loss: 0.4743 | Test acc: 83.4742\n",
      "Train loss: 0.0001 | Test loss: 0.4676 | Test acc: 83.9029\n",
      "Train loss: 0.0003 | Test loss: 0.4931 | Test acc: 82.7860\n",
      "Train loss: 0.0001 | Test loss: 0.4662 | Test acc: 83.8607\n",
      "Train loss: 0.0002 | Test loss: 0.4723 | Test acc: 83.5347\n",
      "Train loss: 0.0002 | Test loss: 0.4722 | Test acc: 83.5936\n",
      "Train loss: 0.0002 | Test loss: 0.4608 | Test acc: 84.0031\n",
      "Train loss: 0.0002 | Test loss: 0.5002 | Test acc: 82.2472\n",
      "Train loss: 0.0003 | Test loss: 0.4776 | Test acc: 83.5994\n",
      "Train loss: 0.0002 | Test loss: 0.4627 | Test acc: 84.0630\n",
      "Train loss: 0.0001 | Test loss: 0.4725 | Test acc: 83.5853\n",
      "Train loss: 0.0003 | Test loss: 0.5654 | Test acc: 79.1408\n",
      "Train loss: 0.0003 | Test loss: 0.5048 | Test acc: 82.2516\n",
      "Train loss: 0.0004 | Test loss: 0.4929 | Test acc: 83.2899\n",
      "Train loss: 0.0003 | Test loss: 0.4912 | Test acc: 83.0936\n",
      "Train loss: 0.0002 | Test loss: 0.4653 | Test acc: 83.8917\n",
      "Train loss: 0.0003 | Test loss: 0.4620 | Test acc: 83.9941\n",
      "Train loss: 0.0002 | Test loss: 0.4614 | Test acc: 84.0942\n",
      "Train loss: 0.0001 | Test loss: 0.4634 | Test acc: 83.9548\n",
      "Train loss: 0.0001 | Test loss: 0.4608 | Test acc: 84.1740\n",
      "Train loss: 0.0002 | Test loss: 0.4792 | Test acc: 83.5856\n",
      "Train loss: 0.0002 | Test loss: 0.4817 | Test acc: 83.0646\n",
      "Train loss: 0.0002 | Test loss: 0.5027 | Test acc: 82.1943\n",
      "Train loss: 0.0003 | Test loss: 0.4858 | Test acc: 82.8005\n",
      "Train loss: 0.0004 | Test loss: 0.7338 | Test acc: 75.5441\n",
      "Train loss: 0.0002 | Test loss: 0.5096 | Test acc: 82.9390\n",
      "Train loss: 0.0003 | Test loss: 0.4871 | Test acc: 82.8728\n",
      "Train loss: 0.0001 | Test loss: 0.4741 | Test acc: 83.9209\n",
      "Train loss: 0.0001 | Test loss: 0.4741 | Test acc: 84.0640\n",
      "Train loss: 0.0002 | Test loss: 0.4685 | Test acc: 83.7849\n",
      "Train loss: 0.0003 | Test loss: 0.4964 | Test acc: 82.1367\n",
      "Train loss: 0.0003 | Test loss: 0.4892 | Test acc: 83.1099\n",
      "Train loss: 0.0002 | Test loss: 0.4837 | Test acc: 83.4524\n",
      "Train loss: 0.0002 | Test loss: 0.4923 | Test acc: 83.3038\n",
      "Train loss: 0.0002 | Test loss: 0.4939 | Test acc: 83.4231\n",
      "Train loss: 0.0001 | Test loss: 0.4813 | Test acc: 83.4135\n",
      "Train loss: 0.0003 | Test loss: 0.4740 | Test acc: 83.2837\n",
      "Train loss: 0.0002 | Test loss: 0.4828 | Test acc: 83.1535\n",
      "Train loss: 0.0003 | Test loss: 0.5119 | Test acc: 81.1263\n",
      "Train loss: 0.0002 | Test loss: 0.5037 | Test acc: 81.8986\n",
      "Train loss: 0.0002 | Test loss: 0.5051 | Test acc: 82.4701\n",
      "Train loss: 0.0004 | Test loss: 0.4897 | Test acc: 83.3006\n",
      "Train loss: 0.0002 | Test loss: 0.4776 | Test acc: 83.4630\n",
      "Train loss: 0.0005 | Test loss: 0.4993 | Test acc: 82.9943\n",
      "Train loss: 0.0002 | Test loss: 0.5314 | Test acc: 82.3938\n",
      "Train loss: 0.0003 | Test loss: 0.5313 | Test acc: 81.1638\n",
      "Train loss: 0.0002 | Test loss: 0.4928 | Test acc: 83.0369\n",
      "Train loss: 0.0002 | Test loss: 0.4970 | Test acc: 82.4638\n",
      "Train loss: 0.0003 | Test loss: 0.5145 | Test acc: 82.0826\n",
      "Train loss: 0.0003 | Test loss: 0.5224 | Test acc: 81.9316\n",
      "Train loss: 0.0002 | Test loss: 0.5420 | Test acc: 81.6515\n",
      "Train loss: 0.0003 | Test loss: 0.5670 | Test acc: 80.5824\n",
      "Train loss: 0.0002 | Test loss: 0.4830 | Test acc: 83.2846\n",
      "Train loss: 0.0002 | Test loss: 0.4678 | Test acc: 83.9322\n",
      "Train loss: 0.0003 | Test loss: 0.4983 | Test acc: 82.4567\n",
      "Train loss: 0.0002 | Test loss: 0.4680 | Test acc: 83.9196\n",
      "Train loss: 0.0002 | Test loss: 0.4818 | Test acc: 83.3652\n",
      "Train loss: 0.0003 | Test loss: 0.4779 | Test acc: 83.6030\n",
      "Train loss: 0.0002 | Test loss: 0.4747 | Test acc: 83.2843\n",
      "Train loss: 0.0003 | Test loss: 0.5217 | Test acc: 82.1850\n",
      "Train loss: 0.0002 | Test loss: 0.5155 | Test acc: 82.2314\n",
      "Train loss: 0.0003 | Test loss: 0.4826 | Test acc: 82.8705\n",
      "Train loss: 0.0002 | Test loss: 0.4757 | Test acc: 83.4517\n",
      "Train loss: 0.0002 | Test loss: 0.4757 | Test acc: 83.3736\n",
      "Train loss: 0.0002 | Test loss: 0.4813 | Test acc: 83.0639\n",
      "Train loss: 0.0002 | Test loss: 0.5068 | Test acc: 82.0545\n",
      "Train loss: 0.0001 | Test loss: 0.5123 | Test acc: 81.9115\n",
      "Train loss: 0.0002 | Test loss: 0.4901 | Test acc: 82.5001\n",
      "Train loss: 0.0001 | Test loss: 0.5016 | Test acc: 82.3722\n",
      "Train loss: 0.0001 | Test loss: 0.4680 | Test acc: 83.9892\n",
      "Train loss: 0.0002 | Test loss: 0.4739 | Test acc: 83.6349\n",
      "Train loss: 0.0002 | Test loss: 0.4693 | Test acc: 84.1630\n",
      "Train loss: 0.0002 | Test loss: 0.4651 | Test acc: 83.9849\n",
      "Train loss: 0.0002 | Test loss: 0.4734 | Test acc: 83.5750\n",
      "Train loss: 0.0002 | Test loss: 0.4732 | Test acc: 83.6636\n",
      "Train loss: 0.0002 | Test loss: 0.4795 | Test acc: 83.3643\n",
      "Train loss: 0.0001 | Test loss: 0.4858 | Test acc: 82.7044\n",
      "Train loss: 0.0002 | Test loss: 0.4825 | Test acc: 83.2215\n",
      "Train loss: 0.0001 | Test loss: 0.4668 | Test acc: 83.7523\n",
      "Train loss: 0.0000 | Test loss: 0.4683 | Test acc: 83.7939\n",
      "Train loss: 0.0001 | Test loss: 0.4729 | Test acc: 83.8140\n",
      "Train loss: 0.0002 | Test loss: 0.4829 | Test acc: 83.4147\n",
      "Train loss: 0.0003 | Test loss: 0.4779 | Test acc: 83.3236\n",
      "Train loss: 0.0003 | Test loss: 0.4928 | Test acc: 83.0837\n",
      "Train loss: 0.0002 | Test loss: 0.4892 | Test acc: 83.1628\n",
      "Train loss: 0.0001 | Test loss: 0.4916 | Test acc: 83.2729\n",
      "Train loss: 0.0003 | Test loss: 0.4696 | Test acc: 83.9621\n",
      "Train loss: 0.0002 | Test loss: 0.4729 | Test acc: 84.0742\n",
      "Train loss: 0.0003 | Test loss: 0.5546 | Test acc: 79.8712\n",
      "Train loss: 0.0002 | Test loss: 0.4856 | Test acc: 82.5535\n",
      "Train loss: 0.0002 | Test loss: 0.5571 | Test acc: 79.5968\n",
      "Train loss: 0.0004 | Test loss: 0.6180 | Test acc: 79.5674\n",
      "Train loss: 0.0004 | Test loss: 0.4796 | Test acc: 83.7906\n",
      "Train loss: 0.0002 | Test loss: 0.4854 | Test acc: 83.4346\n",
      "Train loss: 0.0003 | Test loss: 0.5075 | Test acc: 82.0657\n",
      "Train loss: 0.0002 | Test loss: 0.4806 | Test acc: 83.0697\n",
      "Train loss: 0.0002 | Test loss: 0.4931 | Test acc: 83.2726\n",
      "Train loss: 0.0004 | Test loss: 0.4916 | Test acc: 83.1734\n",
      "Train loss: 0.0002 | Test loss: 0.4836 | Test acc: 83.5325\n",
      "Train loss: 0.0002 | Test loss: 0.5119 | Test acc: 82.5053\n",
      "Train loss: 0.0002 | Test loss: 0.4877 | Test acc: 82.9713\n",
      "Train loss: 0.0003 | Test loss: 0.5013 | Test acc: 82.5035\n",
      "Train loss: 0.0004 | Test loss: 0.4780 | Test acc: 83.4305\n",
      "Train loss: 0.0002 | Test loss: 0.4780 | Test acc: 83.5533\n",
      "Train loss: 0.0002 | Test loss: 0.5013 | Test acc: 83.3939\n",
      "Train loss: 0.0002 | Test loss: 0.4882 | Test acc: 83.5432\n",
      "Train loss: 0.0002 | Test loss: 0.4633 | Test acc: 84.2525\n",
      "Train loss: 0.0003 | Test loss: 0.5098 | Test acc: 82.3479\n",
      "Train loss: 0.0003 | Test loss: 0.4636 | Test acc: 84.0291\n",
      "Train loss: 0.0003 | Test loss: 0.4723 | Test acc: 83.3955\n",
      "Train loss: 0.0001 | Test loss: 0.4709 | Test acc: 83.3735\n",
      "Train loss: 0.0002 | Test loss: 0.4697 | Test acc: 83.4333\n",
      "Train loss: 0.0002 | Test loss: 0.4782 | Test acc: 83.0441\n",
      "Train loss: 0.0003 | Test loss: 0.5150 | Test acc: 82.1643\n",
      "Train loss: 0.0003 | Test loss: 0.4699 | Test acc: 84.0984\n",
      "Train loss: 0.0002 | Test loss: 0.4913 | Test acc: 83.3458\n",
      "Train loss: 0.0001 | Test loss: 0.4812 | Test acc: 83.6529\n",
      "Train loss: 0.0002 | Test loss: 0.4684 | Test acc: 84.3427\n",
      "Train loss: 0.0003 | Test loss: 0.5309 | Test acc: 82.9671\n",
      "Train loss: 0.0003 | Test loss: 0.4934 | Test acc: 83.6317\n",
      "Train loss: 0.0001 | Test loss: 0.5067 | Test acc: 82.7752\n",
      "Train loss: 0.0003 | Test loss: 0.5017 | Test acc: 82.0636\n",
      "Train loss: 0.0002 | Test loss: 0.4700 | Test acc: 83.9583\n",
      "Train loss: 0.0004 | Test loss: 0.4814 | Test acc: 83.4751\n",
      "Train loss: 0.0001 | Test loss: 0.4703 | Test acc: 83.8829\n",
      "Train loss: 0.0002 | Test loss: 0.4674 | Test acc: 83.7844\n",
      "Train loss: 0.0003 | Test loss: 0.4606 | Test acc: 83.9638\n",
      "Train loss: 0.0003 | Test loss: 0.4865 | Test acc: 83.1656\n",
      "Train loss: 0.0003 | Test loss: 0.4681 | Test acc: 83.7721\n",
      "Train loss: 0.0002 | Test loss: 0.4871 | Test acc: 82.9354\n",
      "Train loss: 0.0002 | Test loss: 0.4889 | Test acc: 83.3021\n",
      "Train loss: 0.0001 | Test loss: 0.4774 | Test acc: 83.5529\n",
      "Train loss: 0.0002 | Test loss: 0.4889 | Test acc: 83.3640\n",
      "Looked at 51200 / 60000 samples\n",
      "Train loss: 0.0003 | Test loss: 0.5011 | Test acc: 82.8143\n",
      "Train loss: 0.0002 | Test loss: 0.4703 | Test acc: 84.0505\n",
      "Train loss: 0.0002 | Test loss: 0.4633 | Test acc: 84.1044\n",
      "Train loss: 0.0002 | Test loss: 0.4626 | Test acc: 84.1345\n",
      "Train loss: 0.0001 | Test loss: 0.4643 | Test acc: 84.1246\n",
      "Train loss: 0.0003 | Test loss: 0.4704 | Test acc: 83.4856\n",
      "Train loss: 0.0002 | Test loss: 0.4825 | Test acc: 83.1641\n",
      "Train loss: 0.0004 | Test loss: 0.5157 | Test acc: 81.8751\n",
      "Train loss: 0.0002 | Test loss: 0.5044 | Test acc: 82.3902\n",
      "Train loss: 0.0002 | Test loss: 0.4950 | Test acc: 82.7812\n",
      "Train loss: 0.0002 | Test loss: 0.4726 | Test acc: 83.4913\n",
      "Train loss: 0.0002 | Test loss: 0.4965 | Test acc: 82.8147\n",
      "Train loss: 0.0005 | Test loss: 0.4933 | Test acc: 82.6927\n",
      "Train loss: 0.0001 | Test loss: 0.5047 | Test acc: 82.6524\n",
      "Train loss: 0.0003 | Test loss: 0.4640 | Test acc: 84.0899\n",
      "Train loss: 0.0002 | Test loss: 0.4840 | Test acc: 83.4855\n",
      "Train loss: 0.0003 | Test loss: 0.4710 | Test acc: 83.4636\n",
      "Train loss: 0.0002 | Test loss: 0.4845 | Test acc: 82.9344\n",
      "Train loss: 0.0002 | Test loss: 0.4689 | Test acc: 83.9411\n",
      "Train loss: 0.0003 | Test loss: 0.5285 | Test acc: 81.3684\n",
      "Train loss: 0.0003 | Test loss: 0.4976 | Test acc: 83.2372\n",
      "Train loss: 0.0002 | Test loss: 0.4792 | Test acc: 83.9920\n",
      "Train loss: 0.0002 | Test loss: 0.4697 | Test acc: 84.1042\n",
      "Train loss: 0.0002 | Test loss: 0.4800 | Test acc: 83.7651\n",
      "Train loss: 0.0003 | Test loss: 0.4872 | Test acc: 83.0851\n",
      "Train loss: 0.0004 | Test loss: 0.5124 | Test acc: 81.9048\n",
      "Train loss: 0.0003 | Test loss: 0.4902 | Test acc: 83.1491\n",
      "Train loss: 0.0002 | Test loss: 0.5047 | Test acc: 83.0133\n",
      "Train loss: 0.0004 | Test loss: 0.4717 | Test acc: 83.8615\n",
      "Train loss: 0.0003 | Test loss: 0.5068 | Test acc: 82.3965\n",
      "Train loss: 0.0002 | Test loss: 0.4816 | Test acc: 83.6498\n",
      "Train loss: 0.0003 | Test loss: 0.5148 | Test acc: 81.9366\n",
      "Train loss: 0.0002 | Test loss: 0.4713 | Test acc: 83.8580\n",
      "Train loss: 0.0002 | Test loss: 0.4690 | Test acc: 83.8342\n",
      "Train loss: 0.0003 | Test loss: 0.4737 | Test acc: 83.6744\n",
      "Train loss: 0.0001 | Test loss: 0.4755 | Test acc: 83.6639\n",
      "Train loss: 0.0002 | Test loss: 0.4758 | Test acc: 83.3344\n",
      "Train loss: 0.0003 | Test loss: 0.4681 | Test acc: 83.5230\n",
      "Train loss: 0.0004 | Test loss: 0.4707 | Test acc: 83.6434\n",
      "Train loss: 0.0003 | Test loss: 0.4820 | Test acc: 83.3243\n",
      "Train loss: 0.0002 | Test loss: 0.4643 | Test acc: 83.9823\n",
      "Train loss: 0.0002 | Test loss: 0.4742 | Test acc: 83.3254\n",
      "Train loss: 0.0003 | Test loss: 0.4750 | Test acc: 83.2834\n",
      "Train loss: 0.0002 | Test loss: 0.4706 | Test acc: 83.7525\n",
      "Train loss: 0.0002 | Test loss: 0.4857 | Test acc: 83.3047\n",
      "Train loss: 0.0002 | Test loss: 0.4900 | Test acc: 83.0737\n",
      "Train loss: 0.0002 | Test loss: 0.4811 | Test acc: 83.4922\n",
      "Train loss: 0.0002 | Test loss: 0.4974 | Test acc: 82.4253\n",
      "Train loss: 0.0003 | Test loss: 0.5186 | Test acc: 82.6016\n",
      "Train loss: 0.0003 | Test loss: 0.4842 | Test acc: 83.7204\n",
      "Train loss: 0.0003 | Test loss: 0.4911 | Test acc: 82.7355\n",
      "Train loss: 0.0002 | Test loss: 0.4878 | Test acc: 83.3913\n",
      "Train loss: 0.0002 | Test loss: 0.5249 | Test acc: 82.8044\n",
      "Train loss: 0.0003 | Test loss: 0.4631 | Test acc: 84.1403\n",
      "Train loss: 0.0002 | Test loss: 0.4704 | Test acc: 83.6854\n",
      "Train loss: 0.0003 | Test loss: 0.4853 | Test acc: 83.1947\n",
      "Train loss: 0.0002 | Test loss: 0.4730 | Test acc: 83.8920\n",
      "Train loss: 0.0002 | Test loss: 0.4653 | Test acc: 83.7744\n",
      "Train loss: 0.0003 | Test loss: 0.4982 | Test acc: 82.0867\n",
      "Train loss: 0.0003 | Test loss: 0.4814 | Test acc: 83.6289\n",
      "Train loss: 0.0001 | Test loss: 0.5077 | Test acc: 82.9449\n",
      "Train loss: 0.0002 | Test loss: 0.4822 | Test acc: 83.6616\n",
      "Train loss: 0.0002 | Test loss: 0.4796 | Test acc: 83.4642\n",
      "Train loss: 0.0002 | Test loss: 0.4776 | Test acc: 83.3238\n",
      "Train loss: 0.0002 | Test loss: 0.4696 | Test acc: 84.1220\n",
      "Train loss: 0.0003 | Test loss: 0.4748 | Test acc: 83.8950\n",
      "Train loss: 0.0001 | Test loss: 0.4814 | Test acc: 83.3950\n",
      "Train loss: 0.0003 | Test loss: 0.4837 | Test acc: 83.9625\n",
      "Train loss: 0.0003 | Test loss: 0.4981 | Test acc: 83.2355\n",
      "Train loss: 0.0002 | Test loss: 0.5364 | Test acc: 82.1150\n",
      "Train loss: 0.0001 | Test loss: 0.5038 | Test acc: 83.1298\n",
      "Train loss: 0.0004 | Test loss: 0.4752 | Test acc: 83.3527\n",
      "Train loss: 0.0001 | Test loss: 0.4751 | Test acc: 83.6129\n",
      "Train loss: 0.0001 | Test loss: 0.4685 | Test acc: 83.8734\n",
      "Train loss: 0.0002 | Test loss: 0.5072 | Test acc: 82.7859\n",
      "Train loss: 0.0002 | Test loss: 0.4908 | Test acc: 83.1818\n",
      "Train loss: 0.0003 | Test loss: 0.5034 | Test acc: 82.4543\n",
      "Train loss: 0.0004 | Test loss: 0.5018 | Test acc: 81.4036\n",
      "Train loss: 0.0002 | Test loss: 0.5019 | Test acc: 82.3487\n",
      "Train loss: 0.0003 | Test loss: 0.4826 | Test acc: 83.4200\n",
      "Train loss: 0.0004 | Test loss: 0.5302 | Test acc: 80.0588\n",
      "Train loss: 0.0002 | Test loss: 0.4713 | Test acc: 83.6324\n",
      "Train loss: 0.0001 | Test loss: 0.4695 | Test acc: 83.7936\n",
      "Train loss: 0.0002 | Test loss: 0.5053 | Test acc: 82.9854\n",
      "Train loss: 0.0002 | Test loss: 0.4910 | Test acc: 83.3722\n",
      "Train loss: 0.0003 | Test loss: 0.4949 | Test acc: 83.1837\n",
      "Train loss: 0.0003 | Test loss: 0.4890 | Test acc: 83.3129\n",
      "Train loss: 0.0002 | Test loss: 0.4775 | Test acc: 83.5030\n",
      "Train loss: 0.0002 | Test loss: 0.4738 | Test acc: 83.5535\n",
      "Train loss: 0.0003 | Test loss: 0.4921 | Test acc: 83.0944\n",
      "Train loss: 0.0002 | Test loss: 0.5117 | Test acc: 82.0646\n",
      "Train loss: 0.0003 | Test loss: 0.4766 | Test acc: 83.5190\n",
      "Train loss: 0.0004 | Test loss: 0.4689 | Test acc: 83.9929\n",
      "Train loss: 0.0001 | Test loss: 0.4677 | Test acc: 83.7348\n",
      "Train loss: 0.0001 | Test loss: 0.4795 | Test acc: 83.3845\n",
      "Train loss: 0.0002 | Test loss: 0.4805 | Test acc: 83.2936\n",
      "Train loss: 0.0003 | Test loss: 0.4617 | Test acc: 84.0321\n",
      "Train loss: 0.0002 | Test loss: 0.4739 | Test acc: 83.7549\n",
      "Train loss: 0.0002 | Test loss: 0.4766 | Test acc: 83.3646\n",
      "Train loss: 0.0001 | Test loss: 0.4734 | Test acc: 83.6130\n",
      "Train loss: 0.0002 | Test loss: 0.4798 | Test acc: 82.9548\n",
      "Train loss: 0.0001 | Test loss: 0.4784 | Test acc: 83.1225\n",
      "Train loss: 0.0002 | Test loss: 0.5049 | Test acc: 82.0248\n",
      "Train loss: 0.0003 | Test loss: 0.4968 | Test acc: 83.0895\n",
      "Train loss: 0.0002 | Test loss: 0.4673 | Test acc: 84.1113\n",
      "Train loss: 0.0002 | Test loss: 0.4761 | Test acc: 83.5655\n",
      "Train loss: 0.0002 | Test loss: 0.4749 | Test acc: 83.4439\n",
      "Train loss: 0.0002 | Test loss: 0.4922 | Test acc: 82.3053\n",
      "Train loss: 0.0002 | Test loss: 0.4897 | Test acc: 82.8308\n",
      "Train loss: 0.0003 | Test loss: 0.4924 | Test acc: 82.9923\n",
      "Train loss: 0.0002 | Test loss: 0.4969 | Test acc: 81.7348\n",
      "Train loss: 0.0001 | Test loss: 0.4635 | Test acc: 83.7875\n",
      "Train loss: 0.0002 | Test loss: 0.5030 | Test acc: 82.7956\n",
      "Train loss: 0.0004 | Test loss: 0.4934 | Test acc: 82.8624\n",
      "Train loss: 0.0003 | Test loss: 0.4784 | Test acc: 82.9025\n",
      "Train loss: 0.0002 | Test loss: 0.5024 | Test acc: 82.5033\n",
      "Train loss: 0.0003 | Test loss: 0.5243 | Test acc: 82.0028\n",
      "Train loss: 0.0002 | Test loss: 0.5070 | Test acc: 82.5703\n",
      "Train loss: 0.0002 | Test loss: 0.5223 | Test acc: 81.9431\n",
      "Train loss: 0.0002 | Test loss: 0.4992 | Test acc: 82.7099\n",
      "Train loss: 0.0003 | Test loss: 0.5035 | Test acc: 82.4527\n",
      "Train loss: 0.0002 | Test loss: 0.4750 | Test acc: 83.4403\n",
      "Train loss: 0.0002 | Test loss: 0.4737 | Test acc: 83.8528\n",
      "Train loss: 0.0002 | Test loss: 0.4972 | Test acc: 83.2252\n",
      "Train loss: 0.0001 | Test loss: 0.4924 | Test acc: 83.1333\n",
      "Train loss: 0.0003 | Test loss: 0.4730 | Test acc: 83.5124\n",
      "Train loss: 0.0003 | Test loss: 0.4921 | Test acc: 83.0943\n",
      "Train loss: 0.0003 | Test loss: 0.5292 | Test acc: 82.0446\n",
      "Train loss: 0.0003 | Test loss: 0.5119 | Test acc: 82.7501\n",
      "Train loss: 0.0003 | Test loss: 0.4903 | Test acc: 83.4213\n",
      "Train loss: 0.0001 | Test loss: 0.4921 | Test acc: 82.5149\n",
      "Train loss: 0.0004 | Test loss: 0.4983 | Test acc: 82.8215\n",
      "Train loss: 0.0002 | Test loss: 0.5047 | Test acc: 82.0837\n",
      "Train loss: 0.0004 | Test loss: 0.4988 | Test acc: 82.4208\n",
      "Train loss: 0.0001 | Test loss: 0.4846 | Test acc: 83.1307\n",
      "Train loss: 0.0005 | Test loss: 0.4872 | Test acc: 83.3127\n",
      "Train loss: 0.0001 | Test loss: 0.4768 | Test acc: 83.6627\n",
      "Train loss: 0.0003 | Test loss: 0.4688 | Test acc: 83.8835\n",
      "Train loss: 0.0003 | Test loss: 0.4803 | Test acc: 83.4150\n",
      "Train loss: 0.0002 | Test loss: 0.4900 | Test acc: 82.9442\n",
      "Train loss: 0.0002 | Test loss: 0.4899 | Test acc: 83.0525\n",
      "Train loss: 0.0003 | Test loss: 0.4750 | Test acc: 83.3624\n",
      "Train loss: 0.0003 | Test loss: 0.4736 | Test acc: 83.5131\n",
      "Train loss: 0.0001 | Test loss: 0.4708 | Test acc: 83.7333\n",
      "Train loss: 0.0001 | Test loss: 0.4784 | Test acc: 83.2448\n",
      "Train loss: 0.0002 | Test loss: 0.4883 | Test acc: 83.1134\n",
      "Train loss: 0.0001 | Test loss: 0.4764 | Test acc: 83.6821\n",
      "Train loss: 0.0002 | Test loss: 0.4679 | Test acc: 83.8237\n",
      "Train loss: 0.0002 | Test loss: 0.4803 | Test acc: 83.0354\n",
      "Train loss: 0.0002 | Test loss: 0.4767 | Test acc: 83.5720\n",
      "Train loss: 0.0002 | Test loss: 0.4805 | Test acc: 83.5637\n",
      "Train loss: 0.0001 | Test loss: 0.4964 | Test acc: 83.2941\n",
      "Train loss: 0.0004 | Test loss: 0.4977 | Test acc: 83.3931\n",
      "Train loss: 0.0002 | Test loss: 0.5185 | Test acc: 82.4649\n",
      "Train loss: 0.0003 | Test loss: 0.5292 | Test acc: 82.4420\n",
      "Train loss: 0.0004 | Test loss: 0.4922 | Test acc: 82.9910\n",
      "Train loss: 0.0005 | Test loss: 0.4987 | Test acc: 83.2823\n",
      "Train loss: 0.0001 | Test loss: 0.4798 | Test acc: 83.7725\n",
      "Train loss: 0.0004 | Test loss: 0.5165 | Test acc: 82.5959\n",
      "Train loss: 0.0002 | Test loss: 0.4844 | Test acc: 83.7603\n",
      "Train loss: 0.0002 | Test loss: 0.4802 | Test acc: 83.8139\n",
      "Train loss: 0.0002 | Test loss: 0.4962 | Test acc: 83.7043\n",
      "Train loss: 0.0003 | Test loss: 0.4929 | Test acc: 83.7638\n",
      "Train loss: 0.0002 | Test loss: 0.4819 | Test acc: 83.4046\n",
      "Train loss: 0.0002 | Test loss: 0.4804 | Test acc: 83.5532\n",
      "Train loss: 0.0002 | Test loss: 0.4857 | Test acc: 83.3540\n",
      "Train loss: 0.0005 | Test loss: 0.5210 | Test acc: 81.6461\n",
      "Train loss: 0.0004 | Test loss: 0.5162 | Test acc: 83.3479\n",
      "Train loss: 0.0002 | Test loss: 0.4937 | Test acc: 83.2735\n",
      "Train loss: 0.0002 | Test loss: 0.4715 | Test acc: 83.8922\n",
      "Train loss: 0.0002 | Test loss: 0.4818 | Test acc: 83.2952\n",
      "Train loss: 0.0001 | Test loss: 0.5241 | Test acc: 81.0668\n",
      "Train loss: 0.0004 | Test loss: 0.5205 | Test acc: 81.7486\n",
      "Train loss: 0.0002 | Test loss: 0.4833 | Test acc: 83.1685\n",
      "Train loss: 0.0002 | Test loss: 0.4652 | Test acc: 83.8520\n",
      "Train loss: 0.0002 | Test loss: 0.5511 | Test acc: 79.7407\n",
      "Train loss: 0.0001 | Test loss: 0.5788 | Test acc: 78.3897\n",
      "Train loss: 0.0005 | Test loss: 0.5193 | Test acc: 82.2393\n",
      "Train loss: 0.0002 | Test loss: 0.5162 | Test acc: 82.8306\n",
      "Train loss: 0.0003 | Test loss: 0.5244 | Test acc: 82.1336\n",
      "Train loss: 0.0004 | Test loss: 0.6331 | Test acc: 77.1694\n",
      "Train loss: 0.0002 | Test loss: 0.5048 | Test acc: 83.5133\n",
      "Train loss: 0.0003 | Test loss: 0.4779 | Test acc: 83.7033\n",
      "Train loss: 0.0001 | Test loss: 0.4931 | Test acc: 82.9451\n",
      "Train loss: 0.0003 | Test loss: 0.4644 | Test acc: 83.7115\n",
      "Train loss: 0.0002 | Test loss: 0.4919 | Test acc: 82.9551\n",
      "Train loss: 0.0004 | Test loss: 0.4963 | Test acc: 82.0941\n",
      "Train loss: 0.0003 | Test loss: 0.4861 | Test acc: 83.1896\n",
      "Train loss: 0.0003 | Test loss: 0.4860 | Test acc: 82.8636\n",
      "Train loss: 0.0003 | Test loss: 0.4877 | Test acc: 82.3135\n",
      "Train loss: 0.0001 | Test loss: 0.4585 | Test acc: 84.1687\n",
      "Train loss: 0.0003 | Test loss: 0.4799 | Test acc: 83.4458\n",
      "Train loss: 0.0003 | Test loss: 0.4920 | Test acc: 83.4235\n",
      "Train loss: 0.0002 | Test loss: 0.4736 | Test acc: 83.8328\n",
      "Train loss: 0.0003 | Test loss: 0.5508 | Test acc: 79.7407\n",
      "Train loss: 0.0002 | Test loss: 0.4834 | Test acc: 83.2320\n",
      "Train loss: 0.0002 | Test loss: 0.4612 | Test acc: 83.8522\n",
      "Train loss: 0.0002 | Test loss: 0.4851 | Test acc: 82.8058\n",
      "Train loss: 0.0002 | Test loss: 0.4851 | Test acc: 82.6727\n",
      "Train loss: 0.0002 | Test loss: 0.4726 | Test acc: 83.2813\n",
      "Train loss: 0.0003 | Test loss: 0.4658 | Test acc: 83.9122\n",
      "Train loss: 0.0001 | Test loss: 0.4701 | Test acc: 83.9342\n",
      "Train loss: 0.0002 | Test loss: 0.4704 | Test acc: 83.9343\n",
      "Train loss: 0.0001 | Test loss: 0.4840 | Test acc: 83.2654\n",
      "Train loss: 0.0001 | Test loss: 0.4749 | Test acc: 83.5927\n",
      "Train loss: 0.0003 | Test loss: 0.4868 | Test acc: 83.2144\n",
      "Train loss: 0.0001 | Test loss: 0.4912 | Test acc: 82.8937\n",
      "Train loss: 0.0003 | Test loss: 0.4862 | Test acc: 83.2920\n",
      "Train loss: 0.0003 | Test loss: 0.5144 | Test acc: 82.4546\n",
      "Train loss: 0.0002 | Test loss: 0.4892 | Test acc: 83.2007\n",
      "Train loss: 0.0002 | Test loss: 0.4719 | Test acc: 83.8022\n",
      "Train loss: 0.0003 | Test loss: 0.4848 | Test acc: 83.1751\n",
      "Train loss: 0.0002 | Test loss: 0.4881 | Test acc: 82.9834\n",
      "Train loss: 0.0003 | Test loss: 0.5286 | Test acc: 81.6549\n",
      "Train loss: 0.0004 | Test loss: 0.5097 | Test acc: 82.0999\n",
      "Train loss: 0.0002 | Test loss: 0.4798 | Test acc: 83.5291\n",
      "Train loss: 0.0002 | Test loss: 0.4928 | Test acc: 82.9546\n",
      "Train loss: 0.0002 | Test loss: 0.5212 | Test acc: 81.6448\n",
      "Train loss: 0.0001 | Test loss: 0.5293 | Test acc: 81.5208\n",
      "Train loss: 0.0002 | Test loss: 0.4843 | Test acc: 83.5971\n",
      "Train loss: 0.0002 | Test loss: 0.4722 | Test acc: 83.7735\n",
      "Train loss: 0.0002 | Test loss: 0.4842 | Test acc: 83.1151\n",
      "Train loss: 0.0001 | Test loss: 0.4695 | Test acc: 83.9017\n",
      "Train loss: 0.0001 | Test loss: 0.4713 | Test acc: 83.9042\n",
      "Train loss: 0.0003 | Test loss: 0.4852 | Test acc: 83.3951\n",
      "Train loss: 0.0001 | Test loss: 0.4857 | Test acc: 83.5432\n",
      "Train loss: 0.0002 | Test loss: 0.5216 | Test acc: 81.8364\n",
      "Train loss: 0.0002 | Test loss: 0.4651 | Test acc: 83.9176\n",
      "Train loss: 0.0003 | Test loss: 0.4738 | Test acc: 83.7346\n",
      "Train loss: 0.0004 | Test loss: 0.4749 | Test acc: 83.3246\n",
      "Train loss: 0.0003 | Test loss: 0.4639 | Test acc: 83.8924\n",
      "Train loss: 0.0001 | Test loss: 0.4656 | Test acc: 83.7345\n",
      "Train loss: 0.0003 | Test loss: 0.5625 | Test acc: 79.3310\n",
      "Train loss: 0.0003 | Test loss: 0.4684 | Test acc: 83.7199\n",
      "Train loss: 0.0002 | Test loss: 0.4726 | Test acc: 83.8537\n",
      "Train loss: 0.0001 | Test loss: 0.4694 | Test acc: 84.0638\n",
      "Train loss: 0.0002 | Test loss: 0.4872 | Test acc: 83.3157\n",
      "Train loss: 0.0003 | Test loss: 0.4685 | Test acc: 83.6528\n",
      "Train loss: 0.0002 | Test loss: 0.4883 | Test acc: 82.4857\n",
      "Train loss: 0.0003 | Test loss: 0.4602 | Test acc: 84.1194\n",
      "Train loss: 0.0003 | Test loss: 0.4762 | Test acc: 83.4057\n",
      "Train loss: 0.0001 | Test loss: 0.4777 | Test acc: 83.4035\n",
      "Train loss: 0.0004 | Test loss: 0.5087 | Test acc: 82.1554\n",
      "Train loss: 0.0004 | Test loss: 0.4913 | Test acc: 82.5608\n",
      "Train loss: 0.0001 | Test loss: 0.5086 | Test acc: 81.9631\n",
      "Train loss: 0.0002 | Test loss: 0.4642 | Test acc: 83.9879\n",
      "Train loss: 0.0002 | Test loss: 0.4635 | Test acc: 84.0543\n",
      "Train loss: 0.0002 | Test loss: 0.4708 | Test acc: 83.6352\n",
      "Train loss: 0.0002 | Test loss: 0.4868 | Test acc: 83.1945\n",
      "Train loss: 0.0002 | Test loss: 0.4993 | Test acc: 82.7438\n",
      "Train loss: 0.0002 | Test loss: 0.4857 | Test acc: 82.7923\n",
      "Train loss: 0.0002 | Test loss: 0.4806 | Test acc: 83.4015\n",
      "Train loss: 0.0002 | Test loss: 0.4860 | Test acc: 82.9542\n",
      "Train loss: 0.0003 | Test loss: 0.5162 | Test acc: 81.0158\n",
      "Train loss: 0.0003 | Test loss: 0.5383 | Test acc: 80.7401\n",
      "Train loss: 0.0002 | Test loss: 0.5215 | Test acc: 81.6377\n",
      "Train loss: 0.0003 | Test loss: 0.5123 | Test acc: 81.5208\n",
      "Train loss: 0.0004 | Test loss: 0.5204 | Test acc: 81.7601\n",
      "Train loss: 0.0003 | Test loss: 0.4663 | Test acc: 83.9174\n",
      "Train loss: 0.0001 | Test loss: 0.4671 | Test acc: 83.7146\n",
      "Train loss: 0.0001 | Test loss: 0.4624 | Test acc: 84.1632\n",
      "Train loss: 0.0002 | Test loss: 0.4845 | Test acc: 83.5556\n",
      "Train loss: 0.0002 | Test loss: 0.4752 | Test acc: 83.7933\n",
      "Train loss: 0.0002 | Test loss: 0.4658 | Test acc: 84.2034\n",
      "Train loss: 0.0004 | Test loss: 0.5244 | Test acc: 81.1396\n",
      "Train loss: 0.0004 | Test loss: 0.5929 | Test acc: 78.2445\n",
      "Train loss: 0.0003 | Test loss: 0.5341 | Test acc: 82.1290\n",
      "Train loss: 0.0003 | Test loss: 0.5230 | Test acc: 82.2911\n",
      "Train loss: 0.0002 | Test loss: 0.4953 | Test acc: 83.0604\n",
      "Train loss: 0.0004 | Test loss: 0.4739 | Test acc: 83.5920\n",
      "Train loss: 0.0002 | Test loss: 0.4782 | Test acc: 83.5438\n",
      "Train loss: 0.0003 | Test loss: 0.4729 | Test acc: 83.6735\n",
      "Train loss: 0.0001 | Test loss: 0.4883 | Test acc: 83.1946\n",
      "Train loss: 0.0003 | Test loss: 0.4712 | Test acc: 83.7422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3/3 [1:26:20<00:00, 1726.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0002 | Test loss: 0.4709 | Test acc: 83.5343\n",
      "Train time on cpu: 5180.05 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "train_time_start = timer() # cpu\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-----\")\n",
    "\n",
    "    train_loss = 0\n",
    "    test_loss, test_acc = 0, 0\n",
    "    for batch, (image, label) in enumerate(train_dataloader):\n",
    "        model_0.train()\n",
    "        y_pred = model_0(image)\n",
    "\n",
    "        loss = loss_fn(y_pred, label)\n",
    "        train_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print out what't happening\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {(batch * len(image))} / {len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "        # Divide the total train loss by len of train_dataloader\n",
    "        train_loss /= len(train_dataloader)\n",
    "\n",
    "        ## Testing\n",
    "    \n",
    "        model_0.eval()\n",
    "        with torch.inference_mode():\n",
    "            for X_test, y_test in test_dataloader:\n",
    "                test_pred = model_0(X_test)\n",
    "                test_loss += loss_fn(test_pred, y_test)\n",
    "                test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "            \n",
    "            # test loss average per batch \n",
    "            test_loss /= len(test_dataloader)\n",
    "            test_acc /= len(test_dataloader)\n",
    "        print(f\"Train loss: {train_loss:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n",
    "    # calculate training time\n",
    "    train_time_end = timer()\n",
    "    total_train_time = print_train_time(start=train_time_start, end=train_time_end, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab7f75d-1f33-4967-9605-fac1bd42aaef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
